#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœºæ”¶æ•›å™¨ (Contextual MAB Converger)
Contextual Multi-Armed Bandit Converger for intelligent strategy selection

æ ¸å¿ƒå‡çº§ï¼š
1. ä»ä¼ ç»ŸMABå‡çº§ä¸ºä¸Šä¸‹æ–‡Bandit (LinUCB, Contextual Thompson Sampling)
2. é›†æˆå¯éªŒè¯æ¨ç†ç³»ç»Ÿ (Claim â†’ Evidence â†’ ActionContract)
3. åŸºäºä»»åŠ¡ä¸Šä¸‹æ–‡ç‰¹å¾çš„æ™ºèƒ½ç­–ç•¥é€‰æ‹©
4. æŒä¹…åŒ–å­¦ä¹ å‚æ•°å­˜å‚¨å’Œå·¥å…·å¥åº·ç›‘æ§
5. å¯éªŒè¯çš„æˆåŠŸä¿¡å·å®šä¹‰å’Œé¢„ç®—ç®¡ç†
"""

import time
import logging
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from collections import defaultdict
from dataclasses import dataclass

from .data_structures import EnhancedDecisionArm, ReasoningPath
from .contextual_bandit import (
    ContextualBanditManager, ContextFeatures, ActionOutcome, SuccessMetric
)
from .verified_reasoning import (
    VerifiedReasoningEngine, ClaimType, EvidenceType, ContractStatus
)
from .semantic_analyzer import SemanticAnalyzer, AnalysisTaskType

try:
    from neogenesis_system.config import MAB_CONFIG
except ImportError:
    try:
        from ..config import MAB_CONFIG
    except ImportError:
        MAB_CONFIG = {
            "convergence_threshold": 0.05,
            "min_samples": 10,
            "cold_start_threshold": {
                "min_usage_count": 5,
                "min_reliability_score": 0.6,
                "max_idle_hours": 24,
                "min_sample_size": 10,
                "exploration_trigger_threshold": 0.7,
                "detection_weights": {
                    "usage_frequency": 0.3,
                    "reliability": 0.3,
                    "recency": 0.2,
                    "sample_sufficiency": 0.2
                }
            }
        }

logger = logging.getLogger(__name__)


class ContextualMABConverger:
    """ä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœºæ”¶æ•›å™¨ - å‡çº§ç‰ˆæ€ç»´è·¯å¾„é€‰æ‹©å™¨"""
    
    def __init__(self, tool_registry=None, algorithm: str = "linucb", 
                 storage_path: str = "contextual_bandit.db",
                 global_budget: Dict[str, float] = None):
        """
        åˆå§‹åŒ–ä¸Šä¸‹æ–‡MABæ”¶æ•›å™¨
        
        Args:
            tool_registry: å·¥å…·æ³¨å†Œè¡¨
            algorithm: ä½¿ç”¨çš„ç®—æ³• ("linucb" æˆ– "thompson")
            storage_path: æŒä¹…åŒ–å­˜å‚¨è·¯å¾„
            global_budget: å…¨å±€é¢„ç®—é…ç½®
        """
        # ğŸ¯ ä¸Šä¸‹æ–‡Banditç³»ç»Ÿ
        self.contextual_bandit = ContextualBanditManager(
            feature_dim=8,
            algorithm=algorithm,
            storage_path=storage_path
        )
        
        # ğŸ”¬ å¯éªŒè¯æ¨ç†å¼•æ“
        self.reasoning_engine = VerifiedReasoningEngine(
            tool_registry=tool_registry,
            global_budget=global_budget
        )
        
        # ğŸ§  è¯­ä¹‰åˆ†æå™¨
        self.semantic_analyzer = SemanticAnalyzer()
        logger.info("ğŸ§  è¯­ä¹‰åˆ†æå™¨å·²åˆå§‹åŒ–")
        
        # ğŸ† ä¿ç•™é»„é‡‘æ¨¡æ¿ç³»ç»Ÿï¼ˆå‡çº§ç‰ˆï¼‰
        self.golden_templates: Dict[str, Dict[str, Any]] = {}
        self.golden_template_config = {
            'success_rate_threshold': 0.90,
            'min_samples_required': 20,
            'confidence_threshold': 0.95,
            'max_golden_templates': 50
        }
        self.template_usage_stats = defaultdict(int)
        
        # ğŸ“Š æ€§èƒ½ç»Ÿè®¡
        self.selection_history = []
        self.total_selections = 0
        self.context_feature_stats = defaultdict(list)
        
        # ğŸ­ è¯•ç‚¼åœºç³»ç»Ÿï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        self.trial_ground = {
            "learned_paths": {},
            "exploration_boost_active": {},
            "culling_candidates": set(),
            "promotion_candidates": set(),
            "performance_watch_list": {},
            "trial_history": [],
            "culled_paths": []
        }
        
        self.trial_config = {
            "exploration_boost_rounds": 10,
            "learned_path_bonus": 0.2,
            "culling_threshold": 0.3,
            "culling_min_samples": 15,
            "max_culled_history": 100
        }
        
        logger.info("ğŸ­ [è¯•ç‚¼åœº] è¯•ç‚¼åœºç³»ç»Ÿå·²åˆå§‹åŒ–")
        logger.info(f"ğŸ­ [è¯•ç‚¼åœº] é…ç½®: æ¢ç´¢å¢å¼º{self.trial_config['exploration_boost_rounds']}è½®, å­¦ä¹ è·¯å¾„å¥–åŠ±{self.trial_config['learned_path_bonus']:.1%}")
        
        # ğŸ† é»„é‡‘æ¨¡æ¿ç³»ç»Ÿï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        self.template_match_history = []
        
        # ğŸ“Š åé¦ˆæ¥æºè¿½è¸ª
        self.feedback_source_tracking = defaultdict(lambda: {
            "count": 0,
            "success_rate": 0.0,
            "avg_reward": 0.0
        })
        
        self.source_weight_config = {
            "user_feedback": 1.0,
            "retrospection": 1.2,
            "auto_evaluation": 0.8,
            "tool_verification": 1.1,
            "contextual_bandit": 1.0
        }
        
        # ğŸ”§ ä¼ ç»ŸMABå…¼å®¹æ€§
        self.path_arms = {}  # è·¯å¾„å†³ç­–è‡‚
        self.tool_arms = {}  # å·¥å…·å†³ç­–è‡‚
        self.path_selection_history = []
        self.total_path_selections = 0
        self.tool_selection_history = []
        self.total_tool_selections = 0
        self.algorithm_performance = defaultdict(lambda: {'successes': 0, 'total': 0})
        self.tool_algorithm_performance = defaultdict(lambda: {'successes': 0, 'total': 0})
        
        # ğŸ”§ å·¥å…·å¥åº·ç›‘æ§
        self.tool_health_cache = {}
        self.health_check_interval = 300  # 5åˆ†é’Ÿ
        
        # é…ç½®å‚æ•°
        self.convergence_threshold = MAB_CONFIG.get("convergence_threshold", 0.05)
        self.min_samples = MAB_CONFIG.get("min_samples", 10)
        
        logger.info("ğŸ¯ ContextualMABConverger å·²åˆå§‹åŒ–")
        logger.info(f"   ç®—æ³•: {algorithm}")
        logger.info(f"   å­˜å‚¨è·¯å¾„: {storage_path}")
        logger.info("ğŸ”¬ å¯éªŒè¯æ¨ç†å¼•æ“å·²å¯ç”¨")
        logger.info("ğŸ† é»„é‡‘æ¨¡æ¿ç³»ç»Ÿå·²å‡çº§")
    
    def extract_context_features(self, user_query: str, execution_context: Optional[Dict] = None,
                                available_tools: List[str] = None) -> ContextFeatures:
        """
        ğŸ¯ æå–ä¸Šä¸‹æ–‡ç‰¹å¾å‘é‡
        
        æ„é€ ä¸Šä¸‹æ–‡ç‰¹å¾å‘é‡ xï¼š
        - ä»»åŠ¡ç­¾åï¼ˆæ„å›¾ã€é¢†åŸŸã€å¤æ‚åº¦ï¼‰
        - å·¥å…·å¯è¾¾æ€§ï¼ˆå¥åº·æ£€æŸ¥/å»¶è¿Ÿ/é€Ÿç‡é™åˆ¶ï¼‰
        - è¾“å…¥ç»Ÿè®¡ï¼ˆé•¿åº¦ã€ç»“æ„ï¼‰
        - å†å²ç»©æ•ˆï¼ˆè¯¥æ„å›¾ä¸‹æŸå·¥å…·/ç­–ç•¥çš„æˆåŠŸç‡ï¼‰
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            
        Returns:
            ä¸Šä¸‹æ–‡ç‰¹å¾å¯¹è±¡
        """
        # 1. ä»»åŠ¡ç­¾åç‰¹å¾
        task_features = self._extract_task_signature(user_query)
        
        # 2. å·¥å…·å¯è¾¾æ€§ç‰¹å¾
        tool_features = self._extract_tool_availability(available_tools or [])
        
        # 3. è¾“å…¥ç»Ÿè®¡ç‰¹å¾
        input_features = self._extract_input_statistics(user_query, execution_context)
        
        # 4. å†å²ç»©æ•ˆç‰¹å¾
        history_features = self._extract_historical_performance(user_query, execution_context)
        
        # 5. ç¯å¢ƒç‰¹å¾
        env_features = self._extract_environment_features(execution_context)
        
        # æ„é€ å®Œæ•´çš„ä¸Šä¸‹æ–‡ç‰¹å¾å‘é‡
        context_features = ContextFeatures(
            task_intent=task_features['intent'],
            task_domain=task_features['domain'],
            task_complexity=task_features['complexity'],
            input_length=input_features['length'],
            input_structure_score=input_features['structure'],  # ä¿®å¤å‚æ•°å
            # å·¥å…·ç‰¹å¾æ˜ å°„åˆ°æ­£ç¡®çš„å­—æ®µ
            tool_health_scores={tool: tool_features['health_score'] for tool in (available_tools or [])},
            # å†å²ç‰¹å¾æ˜ å°„åˆ°æ­£ç¡®çš„å­—æ®µ
            historical_success_rates={path: history_features['success_rate'] for path in ['default']},
            # ç¯å¢ƒç‰¹å¾æ˜ å°„åˆ°æ­£ç¡®çš„å­—æ®µ
            network_quality=min(1.0, max(0.0, 1.0 - env_features['network_latency'] / 1000.0)),  # è½¬æ¢å»¶è¿Ÿä¸ºè´¨é‡åˆ†æ•°
            system_load=env_features['resource_usage'],
            time_budget=env_features.get('time_pressure', 30.0)
        )
        
        logger.debug(f"ğŸ¯ æå–ä¸Šä¸‹æ–‡ç‰¹å¾: {context_features}")
        return context_features
    
    def _extract_task_signature(self, user_query: str) -> Dict[str, Any]:
        """
        åŸºäºLLMçš„æ™ºèƒ½ä»»åŠ¡ç­¾åæå–
        
        ä½¿ç”¨è¯­ä¹‰åˆ†æå™¨è¿›è¡Œæ·±åº¦ç†è§£ï¼Œæ›¿ä»£ç®€å•çš„å…³é”®è¯åŒ¹é…
        """
        try:
            # è¿™é‡Œä½¿ç”¨è¯­ä¹‰åˆ†æå™¨è¿›è¡Œå¤šç»´åº¦åˆ†æ
            analysis_tasks = ['intent_detection', 'domain_classification', 'complexity_assessment']
            semantic_response = self.semantic_analyzer.analyze(user_query, analysis_tasks)
            
            # æå–åˆ†æç»“æœ
            intent = 'general'
            domain = 'general'
            complexity = 0.5
            
            if semantic_response.overall_success:
                # è¿™é‡Œæ˜¯æ„å›¾è¯†åˆ«ç»“æœ
                intent_result = semantic_response.analysis_results.get('intent_detection')
                if intent_result and intent_result.success and intent_result.confidence > 0.6:
                    primary_intent = intent_result.result.get('primary_intent', '')
                    intent = self._map_semantic_intent_to_category(primary_intent)
                    logger.debug(f"ğŸ§  è¯­ä¹‰æ„å›¾è¯†åˆ«: {primary_intent} -> {intent} (ç½®ä¿¡åº¦: {intent_result.confidence:.3f})")
                
                # è¿™é‡Œæ˜¯é¢†åŸŸåˆ†ç±»ç»“æœ
                domain_result = semantic_response.analysis_results.get('domain_classification')
                if domain_result and domain_result.success and domain_result.confidence > 0.6:
                    primary_domain = domain_result.result.get('primary_domain', '')
                    domain = self._map_semantic_domain_to_category(primary_domain)
                    logger.debug(f"ğŸ§  è¯­ä¹‰é¢†åŸŸåˆ†ç±»: {primary_domain} -> {domain} (ç½®ä¿¡åº¦: {domain_result.confidence:.3f})")
                
                # è¿™é‡Œæ˜¯å¤æ‚åº¦è¯„ä¼°ç»“æœ
                complexity_result = semantic_response.analysis_results.get('complexity_assessment')
                if complexity_result and complexity_result.success and complexity_result.confidence > 0.6:
                    complexity_score = complexity_result.result.get('complexity_score', 0.5)
                    complexity = float(complexity_score)
                    logger.debug(f"ğŸ§  è¯­ä¹‰å¤æ‚åº¦è¯„ä¼°: {complexity:.3f} (ç½®ä¿¡åº¦: {complexity_result.confidence:.3f})")
                
                logger.info(f"ğŸ§  è¯­ä¹‰åˆ†ææˆåŠŸ: æ„å›¾={intent}, é¢†åŸŸ={domain}, å¤æ‚åº¦={complexity:.3f}")
            else:
                logger.warning("âš ï¸ è¯­ä¹‰åˆ†ææœªå®Œå…¨æˆåŠŸï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ")
                # å›é€€åˆ°ç®€åŒ–çš„å…³é”®è¯åŒ¹é…
                intent, domain, complexity = self._fallback_keyword_analysis(user_query)
                
        except Exception as e:
            logger.error(f"âŒ è¯­ä¹‰åˆ†æå¼‚å¸¸: {e}")
            # å¼‚å¸¸æƒ…å†µä¸‹ä½¿ç”¨å›é€€æ–¹æ¡ˆ
            intent, domain, complexity = self._fallback_keyword_analysis(user_query)
        
        return {
            'intent': intent,
            'domain': domain,
            'complexity': complexity
        }
    
    def _map_semantic_intent_to_category(self, semantic_intent: str) -> str:
        """å°†è¯­ä¹‰åˆ†æçš„æ„å›¾æ˜ å°„åˆ°æ ‡å‡†ç±»åˆ«"""
        intent_mapping = {
            # æœç´¢ç›¸å…³
            'ä¿¡æ¯æŸ¥è¯¢': 'search',
            'æœç´¢': 'search',
            'æŸ¥æ‰¾': 'search',
            'å¯»æ‰¾': 'search',
            'information_seeking': 'search',
            'search': 'search',
            
            # åˆ†æç›¸å…³
            'åˆ†æ': 'analysis',
            'ç ”ç©¶': 'analysis',
            'è§£æ': 'analysis',
            'è¯„ä¼°': 'analysis',
            'analysis': 'analysis',
            'research': 'analysis',
            
            # åˆ›å»ºç›¸å…³
            'åˆ›å»º': 'creation',
            'ç”Ÿæˆ': 'creation',
            'åˆ¶ä½œ': 'creation',
            'è®¾è®¡': 'creation',
            'creation': 'creation',
            'generation': 'creation',
            
            # ä¿®æ”¹ç›¸å…³
            'ä¿®æ”¹': 'modification',
            'æ›´æ–°': 'modification',
            'ç¼–è¾‘': 'modification',
            'æ”¹è¿›': 'modification',
            'modification': 'modification',
            'update': 'modification',
            
            # è§£é‡Šç›¸å…³
            'è§£é‡Š': 'explanation',
            'è¯´æ˜': 'explanation',
            'é˜è¿°': 'explanation',
            'æ•™å­¦': 'explanation',
            'explanation': 'explanation',
            'clarification': 'explanation'
        }
        
        # æ¨¡ç³ŠåŒ¹é…
        semantic_lower = semantic_intent.lower()
        for key, category in intent_mapping.items():
            if key.lower() in semantic_lower or semantic_lower in key.lower():
                return category
        
        return 'general'
    
    def _map_semantic_domain_to_category(self, semantic_domain: str) -> str:
        """å°†è¯­ä¹‰åˆ†æçš„é¢†åŸŸæ˜ å°„åˆ°æ ‡å‡†ç±»åˆ«"""
        domain_mapping = {
            # æŠ€æœ¯ç›¸å…³
            'æŠ€æœ¯': 'technical',
            'ç¼–ç¨‹': 'technical',
            'å¼€å‘': 'technical',
            'è®¡ç®—æœº': 'technical',
            'è½¯ä»¶': 'technical',
            'programming': 'technical',
            'technology': 'technical',
            'software': 'technical',
            'ai': 'technical',
            
            # å•†ä¸šç›¸å…³
            'å•†ä¸š': 'business',
            'ä¸šåŠ¡': 'business',
            'ç®¡ç†': 'business',
            'è¥é”€': 'business',
            'é‡‘è': 'business',
            'business': 'business',
            'management': 'business',
            'marketing': 'business',
            'finance': 'business',
            
            # å­¦æœ¯ç›¸å…³
            'å­¦æœ¯': 'academic',
            'ç ”ç©¶': 'academic',
            'ç§‘å­¦': 'academic',
            'ç†è®º': 'academic',
            'academic': 'academic',
            'research': 'academic',
            'science': 'academic',
            
            # åˆ›æ„ç›¸å…³
            'åˆ›æ„': 'creative',
            'è®¾è®¡': 'creative',
            'è‰ºæœ¯': 'creative',
            'å†™ä½œ': 'creative',
            'creative': 'creative',
            'design': 'creative',
            'art': 'creative',
            'writing': 'creative'
        }
        
        # æ¨¡ç³ŠåŒ¹é…
        domain_lower = semantic_domain.lower()
        for key, category in domain_mapping.items():
            if key.lower() in domain_lower or domain_lower in key.lower():
                return category
        
        return 'general'
    
    def _fallback_keyword_analysis(self, user_query: str) -> Tuple[str, str, float]:
        """å›é€€çš„å…³é”®è¯åˆ†ææ–¹æ³•"""
        logger.debug("ğŸ”„ ä½¿ç”¨å›é€€å…³é”®è¯åˆ†æ")
        
        query_lower = user_query.lower()
        
        # ç®€åŒ–çš„æ„å›¾è¯†åˆ«
        if any(word in query_lower for word in ['æœç´¢', 'æŸ¥æ‰¾', 'å¯»æ‰¾', 'search', 'find']):
            intent = 'search'
        elif any(word in query_lower for word in ['åˆ†æ', 'ç ”ç©¶', 'analyze', 'study']):
            intent = 'analysis'
        elif any(word in query_lower for word in ['åˆ›å»º', 'ç”Ÿæˆ', 'create', 'generate']):
            intent = 'creation'
        elif any(word in query_lower for word in ['ä¿®æ”¹', 'æ›´æ–°', 'modify', 'update']):
            intent = 'modification'
        elif any(word in query_lower for word in ['è§£é‡Š', 'è¯´æ˜', 'explain', 'describe']):
            intent = 'explanation'
        else:
            intent = 'general'
        
        # ç®€åŒ–çš„é¢†åŸŸè¯†åˆ«
        if any(word in query_lower for word in ['ä»£ç ', 'ç¼–ç¨‹', 'code', 'programming']):
            domain = 'technical'
        elif any(word in query_lower for word in ['ä¸šåŠ¡', 'å•†ä¸š', 'business']):
            domain = 'business'
        elif any(word in query_lower for word in ['å­¦æœ¯', 'ç ”ç©¶', 'academic', 'research']):
            domain = 'academic'
        elif any(word in query_lower for word in ['åˆ›æ„', 'è®¾è®¡', 'creative', 'design']):
            domain = 'creative'
        else:
            domain = 'general'
        
        # ç®€åŒ–çš„å¤æ‚åº¦è¯„ä¼°
        complexity_factors = [
            len(user_query) > 200,
            '?' in user_query and user_query.count('?') > 1,
            any(word in query_lower for word in ['å¤æ‚', 'è¯¦ç»†', 'complex', 'detailed']),
            any(word in query_lower for word in ['æ­¥éª¤', 'æµç¨‹', 'steps', 'process'])
        ]
        complexity = sum(complexity_factors) / len(complexity_factors)
        
        return intent, domain, complexity
    
    def _extract_tool_availability(self, available_tools: List[str]) -> Dict[str, float]:
        """æå–å·¥å…·å¯è¾¾æ€§ç‰¹å¾"""
        if not available_tools:
            return {'availability_score': 0.0, 'health_score': 0.0}
        
        # æ£€æŸ¥å·¥å…·å¥åº·çŠ¶æ€
        healthy_tools = 0
        total_health_score = 0.0
        
        for tool in available_tools:
            health_status = self._check_tool_health(tool)
            if health_status['is_healthy']:
                healthy_tools += 1
            total_health_score += health_status['health_score']
        
        availability_score = len(available_tools) / 10.0  # å‡è®¾10ä¸ªå·¥å…·ä¸ºæ»¡åˆ†
        health_score = total_health_score / len(available_tools) if available_tools else 0.0
        
        return {
            'availability_score': min(availability_score, 1.0),
            'health_score': health_score
        }
    
    def _check_tool_health(self, tool_name: str) -> Dict[str, Any]:
        """æ£€æŸ¥å·¥å…·å¥åº·çŠ¶æ€"""
        current_time = time.time()
        
        # ä»ç¼“å­˜ä¸­è·å–å¥åº·çŠ¶æ€
        if tool_name in self.tool_health_cache:
            cached_data = self.tool_health_cache[tool_name]
            if current_time - cached_data['timestamp'] < self.health_check_interval:
                return cached_data['status']
        
        # æ‰§è¡Œå¥åº·æ£€æŸ¥
        health_status = {
            'is_healthy': True,
            'health_score': 1.0,
            'latency': 0.0,
            'error_rate': 0.0
        }
        
        # åŸºäºå·¥å…·ä½¿ç”¨å†å²è¯„ä¼°å¥åº·çŠ¶æ€
        if tool_name in self.tool_arms:
            arm = self.tool_arms[tool_name]
            if arm.activation_count > 0:
                health_status['health_score'] = arm.success_rate
                health_status['is_healthy'] = arm.success_rate > 0.5
                
                # åŸºäºæœ€è¿‘å¤±è´¥ç‡è°ƒæ•´
                if arm.recent_results:
                    recent_failures = sum(1 for r in arm.recent_results[-10:] if not r)
                    health_status['error_rate'] = recent_failures / min(len(arm.recent_results), 10)
        
        # ç¼“å­˜ç»“æœ
        self.tool_health_cache[tool_name] = {
            'timestamp': current_time,
            'status': health_status
        }
        
        return health_status
    
    def _extract_input_statistics(self, user_query: str, execution_context: Optional[Dict]) -> Dict[str, Any]:
        """æå–è¾“å…¥ç»Ÿè®¡ç‰¹å¾"""
        # æŸ¥è¯¢é•¿åº¦ç‰¹å¾
        length_score = min(len(user_query) / 500.0, 1.0)  # 500å­—ç¬¦ä¸ºæ»¡åˆ†
        
        # ç»“æ„å¤æ‚åº¦
        structure_factors = [
            user_query.count('\n') > 0,  # å¤šè¡Œ
            user_query.count('.') > 2,   # å¤šå¥
            user_query.count(',') > 3,   # å¤æ‚å¥å¼
            bool(execution_context and len(execution_context) > 3)  # ä¸°å¯Œä¸Šä¸‹æ–‡
        ]
        
        structure_score = sum(structure_factors) / len(structure_factors)
        
        return {
            'length': length_score,
            'structure': structure_score
        }
    
    def _extract_historical_performance(self, user_query: str, execution_context: Optional[Dict]) -> Dict[str, float]:
        """æå–å†å²ç»©æ•ˆç‰¹å¾"""
        # åŸºäºæŸ¥è¯¢ç›¸ä¼¼æ€§è®¡ç®—å†å²æˆåŠŸç‡
        if not self.path_arms:
            return {'success_rate': 0.5}  # é»˜è®¤ä¸­ç­‰æˆåŠŸç‡
        
        # ç®€å•çš„ç›¸ä¼¼æ€§åŒ¹é…
        query_words = set(user_query.lower().split())
        similar_paths = []
        
        for path_id, arm in self.path_arms.items():
            # åŸºäºè·¯å¾„ç±»å‹åŒ¹é…
            path_words = set(arm.option.lower().split())
            similarity = len(query_words.intersection(path_words)) / len(query_words.union(path_words)) if query_words.union(path_words) else 0
            
            if similarity > 0.1:  # æœ‰ä¸€å®šç›¸ä¼¼æ€§
                similar_paths.append((similarity, arm.success_rate))
        
        if similar_paths:
            # åŠ æƒå¹³å‡æˆåŠŸç‡
            weighted_success = sum(sim * rate for sim, rate in similar_paths)
            total_weight = sum(sim for sim, _ in similar_paths)
            return {'success_rate': weighted_success / total_weight}
        
        return {'success_rate': 0.5}
    
    def _extract_environment_features(self, execution_context: Optional[Dict]) -> Dict[str, float]:
        """æå–ç¯å¢ƒç‰¹å¾"""
        if not execution_context:
            return {
                'network_latency': 0.5,
                'resource_usage': 0.5,
                'time_pressure': 0.5
            }
        
        # ä»æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­æå–ç¯å¢ƒä¿¡æ¯
        network_latency = execution_context.get('network_latency', 0.5)
        resource_usage = execution_context.get('resource_usage', 0.5)
        time_pressure = execution_context.get('time_pressure', 0.5)
        
        return {
            'network_latency': network_latency,
            'resource_usage': resource_usage,
            'time_pressure': time_pressure
        }

    def _create_strategy_arm_if_missing(self, strategy_id: str, path_type: str = None, 
                                       path_source: str = "unknown", reasoning_path: 'ReasoningPath' = None) -> EnhancedDecisionArm:
        if strategy_id not in self.path_arms:
            if path_type is None:
                # è‡ªåŠ¨æ¨æ–­è·¯å¾„ç±»å‹
                path_type = self._infer_path_type_from_strategy_id(strategy_id)
            
            # ğŸ¯ æ ¹æ®è·¯å¾„æ¥æºæ¨æ–­ç±»å‹å’Œåˆå§‹åŒ–å‚æ•°
            detected_source = self._detect_path_source(strategy_id, path_type, reasoning_path)
            effective_source = path_source if path_source != "unknown" else detected_source
            
            # åˆ›å»ºå†³ç­–è‡‚
            new_arm = EnhancedDecisionArm(
                path_id=strategy_id,
                option=path_type
            )
            
            # ğŸŒ± æ–°æ€æƒ³ç‰¹æ®Šåˆå§‹åŒ–ï¼šä¸ºå­¦ä¹ è·¯å¾„æä¾›æ¢ç´¢ä¼˜åŠ¿
            if effective_source == "learned_exploration":
                # å­¦ä¹ è·¯å¾„è·å¾—åˆå§‹æ¢ç´¢å¥–åŠ±
                new_arm.success_count = 1  # ç»™äºˆåˆå§‹æ­£å‘ä¿¡å·
                new_arm.total_reward = 0.3  # ç»™äºˆé€‚ä¸­çš„åˆå§‹å¥–åŠ±
                new_arm.rl_reward_history = [0.3]  # è®°å½•åˆå§‹å¥–åŠ±
                
                # æ ‡è®°ä¸ºæ–°å­¦ä¹ è·¯å¾„
                self._mark_as_learned_path(strategy_id, reasoning_path)
                
                logger.info(f"ğŸŒ± æ–°å­¦ä¹ è·¯å¾„è¿›å…¥è¯•ç‚¼åœº: {strategy_id} ({path_type})")
                logger.info(f"   è·å¾—æ¢ç´¢å¢å¼º: åˆå§‹æˆåŠŸä¿¡å· + 0.3å¥–åŠ±")
                
            elif effective_source == "manual_addition":
                # æ‰‹åŠ¨æ·»åŠ çš„è·¯å¾„è·å¾—ä¸­ç­‰æ¢ç´¢ä¼˜åŠ¿
                new_arm.success_count = 1
                new_arm.total_reward = 0.2
                new_arm.rl_reward_history = [0.2]
                
                logger.info(f"â• æ‰‹åŠ¨è·¯å¾„è¿›å…¥è¯•ç‚¼åœº: {strategy_id} ({path_type})")
                
            else:
                # é™æ€æ¨¡æ¿æˆ–æœªçŸ¥æ¥æºä¿æŒé»˜è®¤åˆå§‹åŒ–
                logger.info(f"ğŸ†• [MAB] åˆ›å»ºç­–ç•¥å†³ç­–è‡‚: {strategy_id} ({path_type}) [æ¥æº: {effective_source}]")
                if effective_source in ["static_template", "unknown"]:
                    logger.info(f"â„¹ï¸  [è¯•ç‚¼åœº] é™æ€æ¨¡æ¿è·¯å¾„ä¸è¿›å…¥æ¢ç´¢å¢å¼ºæœŸï¼Œç›´æ¥å‚ä¸æ­£å¸¸ç«äº‰")
            
            self.path_arms[strategy_id] = new_arm
            
            # è®°å½•åˆ°è¯•ç‚¼åœºå†å²ï¼ˆæ‰€æœ‰è·¯å¾„éƒ½ä¼šè®°å½•ï¼‰
            self._record_trial_entry(strategy_id, path_type, effective_source)
        
        return self.path_arms[strategy_id]
    
    def contextual_select_best_path(self, paths: List[ReasoningPath], user_query: str, 
                                   execution_context: Optional[Dict] = None,
                                   available_tools: List[str] = None) -> ReasoningPath:
        """
        ğŸ¯ ä¸Šä¸‹æ–‡Banditè·¯å¾„é€‰æ‹© - æ ¸å¿ƒå‡çº§æ–¹æ³•
        
        ä½¿ç”¨ä¸Šä¸‹æ–‡ç‰¹å¾è¿›è¡Œæ™ºèƒ½è·¯å¾„é€‰æ‹©ï¼Œæ”¯æŒLinUCBå’ŒContextual Thompson Sampling
        
        Args:
            paths: å€™é€‰æ€ç»´è·¯å¾„åˆ—è¡¨
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            
        Returns:
            é€‰æ‹©çš„æœ€ä¼˜æ€ç»´è·¯å¾„
        """
        if not paths:
            raise ValueError("è·¯å¾„åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        if len(paths) == 1:
            logger.info(f"ğŸ¯ åªæœ‰ä¸€ä¸ªè·¯å¾„ï¼Œç›´æ¥é€‰æ‹©: {paths[0].path_type}")
            return paths[0]
        
        # ğŸ¯ æå–ä¸Šä¸‹æ–‡ç‰¹å¾
        context_features = self.extract_context_features(user_query, execution_context, available_tools)
        
        # ğŸ”¬ å¯éªŒè¯æ¨ç†é¢„æ£€æŸ¥
        verified_paths = self._verify_paths_preconditions(paths, context_features)
        if not verified_paths:
            logger.warning("âš ï¸ æ‰€æœ‰è·¯å¾„éƒ½æœªé€šè¿‡é¢„æ¡ä»¶æ£€æŸ¥ï¼Œä½¿ç”¨åŸå§‹è·¯å¾„åˆ—è¡¨")
            verified_paths = paths
        
        # ğŸ† é»„é‡‘æ¨¡æ¿ä¼˜å…ˆæ£€æŸ¥
        golden_match = self._check_golden_template_match(verified_paths)
        if golden_match:
            selected_path = golden_match['path']
            template_id = golden_match['template_id']
            
            logger.info(f"ğŸ† é»„é‡‘æ¨¡æ¿åŒ¹é…æˆåŠŸ: {template_id} -> {selected_path.path_type}")
            return selected_path
        
        # ğŸ¯ ä¸Šä¸‹æ–‡Bandité€‰æ‹©
        try:
            # å‡†å¤‡åŠ¨ä½œåˆ—è¡¨ï¼ˆè·¯å¾„ç­–ç•¥IDï¼‰
            actions = [path.strategy_id for path in verified_paths]
            strategy_to_path_mapping = {path.strategy_id: path for path in verified_paths}
            
            # ä½¿ç”¨ä¸Šä¸‹æ–‡Banditè¿›è¡Œé€‰æ‹© - ä¿®å¤è¿”å›å€¼è§£åŒ…é—®é¢˜
            selected_action, confidence, selection_info = self.contextual_bandit.select_action(context_features, actions)
            selected_path = strategy_to_path_mapping[selected_action]
            
            # æ›´æ–°é€‰æ‹©ç»Ÿè®¡
            self.total_selections += 1
            self.selection_history.append({
                'path_id': selected_action,
                'path_type': selected_path.path_type,
                'algorithm': 'contextual_bandit',
                'context_features': context_features.to_dict(),
                'timestamp': time.time(),
                'selection_round': self.total_selections
            })
            
            logger.info(f"ğŸ¯ ä¸Šä¸‹æ–‡Bandité€‰æ‹©: {selected_path.path_type} (ç­–ç•¥ID: {selected_action})")
            logger.debug(f"   ä¸Šä¸‹æ–‡ç‰¹å¾: æ„å›¾={context_features.task_intent}, é¢†åŸŸ={context_features.task_domain}")
            
            return selected_path
            
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¸‹æ–‡Bandité€‰æ‹©å¤±è´¥: {e}")
            # å›é€€åˆ°ä¼ ç»ŸMABé€‰æ‹©
            return self.select_best_path(verified_paths, 'auto')
    
    def _verify_paths_preconditions(self, paths: List[ReasoningPath], 
                                   context_features: ContextFeatures) -> List[ReasoningPath]:
        """
        ğŸ”¬ å¯éªŒè¯æ¨ç†ï¼šé¢„æ¡ä»¶æ£€æŸ¥
        
        Args:
            paths: å€™é€‰è·¯å¾„åˆ—è¡¨
            context_features: ä¸Šä¸‹æ–‡ç‰¹å¾
            
        Returns:
            é€šè¿‡é¢„æ¡ä»¶æ£€æŸ¥çš„è·¯å¾„åˆ—è¡¨
        """
        verified_paths = []
        
        for path in paths:
            try:
                # åˆ›å»ºæ¨ç†å£°æ˜ - ä¿®å¤æ–¹æ³•åé”™è¯¯
                if not hasattr(self.reasoning_engine, 'reasoning_chains'):
                    # å¦‚æœæ²¡æœ‰æ¨ç†é“¾ï¼Œå…ˆåˆ›å»ºä¸€ä¸ª
                    chain_id = self.reasoning_engine.create_reasoning_chain(f"è·¯å¾„éªŒè¯_{int(time.time())}")
                else:
                    # ä½¿ç”¨å·²æœ‰çš„æ¨ç†é“¾æˆ–åˆ›å»ºæ–°çš„
                    chain_id = f"path_verification_{int(time.time())}"
                    if chain_id not in self.reasoning_engine.reasoning_chains:
                        chain_id = self.reasoning_engine.create_reasoning_chain(f"è·¯å¾„éªŒè¯_{int(time.time())}")
                
                # ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•åadd_claim
                from neogenesis_system.cognitive_engine.verified_reasoning import ClaimType
                claim_id = self.reasoning_engine.add_claim(
                    chain_id=chain_id,
                    claim_type=ClaimType.PROCEDURAL,
                    statement=f"è·¯å¾„ {path.path_type} é€‚ç”¨äºå½“å‰ä»»åŠ¡",
                    confidence=0.8
                )
                
                # æ”¶é›†è¯æ® - ä¿®å¤æ–¹æ³•åé”™è¯¯å’Œæšä¸¾å€¼é”™è¯¯
                evidence_id = self.reasoning_engine.add_evidence(
                    chain_id=chain_id,
                    claim_id=claim_id,
                    evidence_type=EvidenceType.TOOL_OUTPUT,  # ä¿®å¤ï¼šä½¿ç”¨å­˜åœ¨çš„æšä¸¾å€¼
                    verification_method="historical_performance_analysis",
                    verification_target=f"path_{path.strategy_id}_performance",
                    expected_result={
                        'path_success_rate': self.path_arms.get(path.strategy_id, EnhancedDecisionArm('', '')).success_rate,
                        'context_match': self._calculate_context_match(path, context_features),
                        'tool_compatibility': self._check_tool_compatibility(path, context_features)
                    }
                )
                
                # åˆ›å»ºè¡ŒåŠ¨åˆçº¦ - ä¿®å¤æ–¹æ³•åé”™è¯¯
                # è·å–è·¯å¾„æ€§èƒ½æ•°æ®ç”¨äºåˆçº¦å‚æ•°
                path_success_rate = self.path_arms.get(path.strategy_id, EnhancedDecisionArm('', '')).success_rate
                context_match = self._calculate_context_match(path, context_features)
                tool_compatibility = self._check_tool_compatibility(path, context_features)
                
                contract_id = self.reasoning_engine.add_action_contract(
                    chain_id=chain_id,
                    action_name="path_execution",
                    tool_name=f"path_executor_{path.strategy_id}",
                    arguments={
                        'path_id': path.strategy_id,
                        'path_type': path.path_type,
                        'expected_success_rate': path_success_rate
                    },
                    preconditions=[
                        f"å·¥å…·å…¼å®¹æ€§ >= 0.5: {tool_compatibility:.2f}",
                        f"ä¸Šä¸‹æ–‡åŒ¹é…åº¦ >= 0.3: {context_match:.2f}"
                    ],
                    expected_outcomes=["ä»»åŠ¡æˆåŠŸå®Œæˆ", "ç”¨æˆ·æ»¡æ„åº¦æå‡"]
                )
                
                # éªŒè¯æ¨ç†é“¾ - ä¿®å¤æ–¹æ³•åé”™è¯¯
                chain_valid, validation_summary = self.reasoning_engine.validate_reasoning_chain(chain_id)
                
                if chain_valid:
                    verified_paths.append(path)
                    logger.debug(f"âœ… è·¯å¾„ {path.path_type} é€šè¿‡é¢„æ¡ä»¶æ£€æŸ¥")
                else:
                    logger.debug(f"âŒ è·¯å¾„ {path.path_type} æœªé€šè¿‡é¢„æ¡ä»¶æ£€æŸ¥: {validation_summary}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ è·¯å¾„ {path.path_type} é¢„æ¡ä»¶æ£€æŸ¥å¼‚å¸¸: {e}")
                # å¼‚å¸¸æƒ…å†µä¸‹ä»ç„¶åŒ…å«è¯¥è·¯å¾„
                verified_paths.append(path)
        
        return verified_paths
    
    def _calculate_context_match(self, path: ReasoningPath, context_features: ContextFeatures) -> float:
        """è®¡ç®—è·¯å¾„ä¸ä¸Šä¸‹æ–‡çš„åŒ¹é…åº¦"""
        # åŸºäºè·¯å¾„ç±»å‹å’Œä»»åŠ¡æ„å›¾çš„åŒ¹é…
        path_type_lower = path.path_type.lower()
        intent = context_features.task_intent
        
        # æ„å›¾-è·¯å¾„ç±»å‹åŒ¹é…è§„åˆ™
        intent_path_match = {
            'search': ['æ¢ç´¢', 'è°ƒç ”', 'investigative', 'exploratory'],
            'analysis': ['åˆ†æ', 'ç³»ç»Ÿ', 'analytical', 'systematic'],
            'creation': ['åˆ›æ–°', 'åˆ›é€ ', 'creative', 'innovative'],
            'modification': ['é€‚åº”', 'çµæ´»', 'adaptive', 'flexible'],
            'explanation': ['æ•´ä½“', 'ç»¼åˆ', 'comprehensive', 'holistic']
        }
        
        match_score = 0.0
        if intent in intent_path_match:
            keywords = intent_path_match[intent]
            for keyword in keywords:
                if keyword in path_type_lower:
                    match_score += 0.3
                    break
        
        # å¤æ‚åº¦åŒ¹é…
        if context_features.task_complexity > 0.7 and 'ç³»ç»Ÿ' in path_type_lower:
            match_score += 0.2
        elif context_features.task_complexity < 0.3 and 'å®ç”¨' in path_type_lower:
            match_score += 0.2
        
        # å†å²æˆåŠŸç‡åŠ æƒ
        if path.strategy_id in self.path_arms:
            historical_success = self.path_arms[path.strategy_id].success_rate
            match_score += historical_success * 0.3
        
        return min(match_score, 1.0)
    
    def _check_tool_compatibility(self, path: ReasoningPath, context_features: ContextFeatures) -> float:
        """æ£€æŸ¥è·¯å¾„ä¸å¯ç”¨å·¥å…·çš„å…¼å®¹æ€§"""
        # åŸºäºè·¯å¾„ç±»å‹æ¨æ–­æ‰€éœ€å·¥å…·ç±»å‹
        path_tool_requirements = {
            'æ¢ç´¢è°ƒç ”å‹': ['search', 'web', 'database'],
            'ç³»ç»Ÿåˆ†æå‹': ['analysis', 'data', 'statistics'],
            'åˆ›æ–°çªç ´å‹': ['generation', 'creative', 'brainstorm'],
            'å®ç”¨åŠ¡å®å‹': ['execution', 'automation', 'workflow'],
            'æ•´ä½“ç»¼åˆå‹': ['integration', 'synthesis', 'summary']
        }
        
        required_tools = path_tool_requirements.get(path.path_type, [])
        if not required_tools:
            return 0.8  # é»˜è®¤å…¼å®¹æ€§
        
        # æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
        available_score = context_features.tool_availability
        health_score = context_features.tool_health_score
        
        # ç»¼åˆå…¼å®¹æ€§è¯„åˆ†
        compatibility = (available_score * 0.6 + health_score * 0.4)
        
        return compatibility
    
    def update_contextual_feedback(self, path_id: str, context_features: ContextFeatures, 
                                  success: bool, reward: float = 0.0, 
                                  execution_result: Optional[Dict] = None):
        """
        ğŸ¯ æ›´æ–°ä¸Šä¸‹æ–‡Banditçš„åé¦ˆ
        
        Args:
            path_id: è·¯å¾„ID
            context_features: ä¸Šä¸‹æ–‡ç‰¹å¾
            success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            reward: å¥–åŠ±å€¼
            execution_result: æ‰§è¡Œç»“æœè¯¦æƒ…
        """
        try:
            # ğŸ”¬ å¯éªŒè¯æ¨ç†ï¼šæˆåŠŸä¿¡å·å®šä¹‰
            verified_success = self._verify_success_signal(success, execution_result)
            adjusted_reward = self._calculate_verified_reward(success, reward, execution_result)
            
            # åˆ›å»ºè¡ŒåŠ¨ç»“æœ
            outcome = ActionOutcome(
                action_id=path_id,  # ä¿®å¤å‚æ•°åï¼šaction -> action_id
                context_features=context_features,
                success_metrics={SuccessMetric.EXECUTION_SUCCESS: adjusted_reward},  # ä¿®å¤å‚æ•°ç»“æ„
                execution_time=execution_result.get('execution_time', 0.0) if execution_result else 0.0,
                cost=execution_result.get('cost', 0.0) if execution_result else 0.0,  # æ·»åŠ å¿…éœ€çš„costå‚æ•°
                timestamp=time.time(),  # æ·»åŠ å¿…éœ€çš„timestampå‚æ•°
                additional_info=execution_result or {}  # æ·»åŠ é¢å¤–ä¿¡æ¯
            )
            
            # æ›´æ–°ä¸Šä¸‹æ–‡Banditï¼ˆæ–¹æ³•æ›´åï¼šupdate_rewardï¼‰
            if hasattr(self.contextual_bandit, 'update_reward'):
                self.contextual_bandit.update_reward(context_features, path_id, outcome)
            else:
                # å…¼å®¹æ—§æ¥å£
                self.contextual_bandit.update_feedback(outcome)
            
            # åŒæ—¶æ›´æ–°ä¼ ç»ŸMABç³»ç»Ÿï¼ˆå‘åå…¼å®¹ï¼‰
            self.update_path_performance(path_id, verified_success, adjusted_reward, "contextual_bandit")
            
            logger.info(f"ğŸ¯ ä¸Šä¸‹æ–‡åé¦ˆæ›´æ–°: {path_id} -> æˆåŠŸ={verified_success}, å¥–åŠ±={adjusted_reward:.3f}")
            
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¸‹æ–‡åé¦ˆæ›´æ–°å¤±è´¥: {e}")
            # å›é€€åˆ°ä¼ ç»Ÿæ›´æ–°
            self.update_path_performance(path_id, success, reward, "fallback")
    
    def _verify_success_signal(self, raw_success: bool, execution_result: Optional[Dict]) -> bool:
        """
        ğŸ”¬ å¯éªŒè¯çš„æˆåŠŸä¿¡å·å®šä¹‰
        
        ä¸ä¾èµ–LLMè‡ªè¯„ï¼Œè€Œæ˜¯åŸºäºå®¢è§‚æŒ‡æ ‡åˆ¤æ–­æˆåŠŸ
        """
        if not execution_result:
            return raw_success
        
        # å¤šç»´åº¦æˆåŠŸéªŒè¯
        success_indicators = []
        
        # 1. æ‰§è¡Œå®Œæˆåº¦
        completion_rate = execution_result.get('completion_rate', 1.0 if raw_success else 0.0)
        success_indicators.append(completion_rate > 0.8)
        
        # 2. é”™è¯¯ç‡
        error_rate = execution_result.get('error_rate', 0.0)
        success_indicators.append(error_rate < 0.1)
        
        # 3. ç”¨æˆ·æ»¡æ„åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
        user_satisfaction = execution_result.get('user_satisfaction')
        if user_satisfaction is not None:
            success_indicators.append(user_satisfaction > 0.7)
        
        # 4. æ—¶é—´æ•ˆç‡
        execution_time = execution_result.get('execution_time', 0.0)
        expected_time = execution_result.get('expected_time', execution_time)
        if expected_time > 0:
            time_efficiency = min(expected_time / max(execution_time, 0.1), 1.0)
            success_indicators.append(time_efficiency > 0.5)
        
        # 5. èµ„æºä½¿ç”¨æ•ˆç‡
        resource_usage = execution_result.get('resource_usage', 0.5)
        success_indicators.append(resource_usage < 0.8)
        
        # ç»¼åˆåˆ¤æ–­ï¼šè‡³å°‘70%çš„æŒ‡æ ‡ä¸ºæ­£é¢
        verified_success = sum(success_indicators) / len(success_indicators) >= 0.7
        
        if verified_success != raw_success:
            logger.info(f"ğŸ”¬ æˆåŠŸä¿¡å·ä¿®æ­£: åŸå§‹={raw_success} -> éªŒè¯å={verified_success}")
        
        return verified_success
    
    def _calculate_verified_reward(self, success: bool, raw_reward: float, 
                                  execution_result: Optional[Dict]) -> float:
        """è®¡ç®—éªŒè¯åçš„å¥–åŠ±å€¼"""
        if not execution_result:
            return raw_reward
        
        # åŸºç¡€å¥–åŠ±
        base_reward = 1.0 if success else -0.5
        
        # æ•ˆç‡å¥–åŠ±
        efficiency_bonus = 0.0
        execution_time = execution_result.get('execution_time', 0.0)
        expected_time = execution_result.get('expected_time', execution_time)
        if expected_time > 0 and execution_time > 0:
            time_ratio = expected_time / execution_time
            if time_ratio > 1.2:  # æ¯”é¢„æœŸå¿«20%ä»¥ä¸Š
                efficiency_bonus += 0.3
            elif time_ratio < 0.8:  # æ¯”é¢„æœŸæ…¢20%ä»¥ä¸Š
                efficiency_bonus -= 0.2
        
        # è´¨é‡å¥–åŠ±
        quality_bonus = 0.0
        completion_rate = execution_result.get('completion_rate', 1.0 if success else 0.0)
        quality_bonus += (completion_rate - 0.8) * 0.5  # è¶…è¿‡80%å®Œæˆåº¦çš„éƒ¨åˆ†ç»™å¥–åŠ±
        
        # æˆæœ¬æƒ©ç½š
        cost_penalty = 0.0
        cost = execution_result.get('cost', 0.0)
        budget = execution_result.get('budget', cost)
        if budget > 0 and cost > budget:
            cost_penalty = -min((cost - budget) / budget, 0.5)  # æœ€å¤šæ‰£0.5åˆ†
        
        # ç»¼åˆå¥–åŠ±
        final_reward = base_reward + efficiency_bonus + quality_bonus + cost_penalty
        
        return max(-1.0, min(final_reward, 2.0))  # é™åˆ¶åœ¨[-1, 2]èŒƒå›´å†…
    
    def get_contextual_bandit_stats(self) -> Dict[str, Any]:
        """
        ğŸ¯ è·å–ä¸Šä¸‹æ–‡Banditç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ä¸Šä¸‹æ–‡Banditçš„è¯¦ç»†ç»Ÿè®¡æ•°æ®
        """
        try:
            bandit_stats = self.contextual_bandit.get_statistics()
            
            # æ·»åŠ é›†æˆç»Ÿè®¡
            integration_stats = {
                'total_contextual_selections': len([h for h in self.selection_history if h.get('algorithm') == 'contextual_bandit']),
                'contextual_success_rate': self._calculate_contextual_success_rate(),
                'feature_importance': self._analyze_feature_importance(),
                'context_distribution': self._analyze_context_distribution()
            }
            
            return {
                'bandit_core_stats': bandit_stats,
                'integration_stats': integration_stats,
                'verified_reasoning_stats': self.reasoning_engine.get_statistics() if hasattr(self.reasoning_engine, 'get_statistics') else {}
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä¸Šä¸‹æ–‡Banditç»Ÿè®¡å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _calculate_contextual_success_rate(self) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡Banditçš„æˆåŠŸç‡"""
        contextual_selections = [h for h in self.selection_history if h.get('algorithm') == 'contextual_bandit']
        if not contextual_selections:
            return 0.0
        
        # åŸºäºè·¯å¾„IDæŸ¥æ‰¾å¯¹åº”çš„æˆåŠŸç‡
        success_rates = []
        for selection in contextual_selections:
            path_id = selection.get('path_id')
            if path_id in self.path_arms:
                success_rates.append(self.path_arms[path_id].success_rate)
        
        return sum(success_rates) / len(success_rates) if success_rates else 0.0
    
    def _analyze_feature_importance(self) -> Dict[str, float]:
        """åˆ†æä¸Šä¸‹æ–‡ç‰¹å¾çš„é‡è¦æ€§"""
        # ç®€åŒ–çš„ç‰¹å¾é‡è¦æ€§åˆ†æ
        feature_impact = {
            'task_intent': 0.0,
            'task_domain': 0.0,
            'task_complexity': 0.0,
            'tool_availability': 0.0,
            'historical_success_rate': 0.0
        }
        
        # åŸºäºé€‰æ‹©å†å²åˆ†æç‰¹å¾å½±å“
        contextual_selections = [h for h in self.selection_history if h.get('context_features')]
        
        if contextual_selections:
            # ç®€å•çš„ç›¸å…³æ€§åˆ†æ
            for selection in contextual_selections:
                features = selection.get('context_features', {})
                path_id = selection.get('path_id')
                
                if path_id in self.path_arms:
                    success_rate = self.path_arms[path_id].success_rate
                    
                    # ç´¯ç§¯ç‰¹å¾ä¸æˆåŠŸç‡çš„ç›¸å…³æ€§
                    for feature_name in feature_impact.keys():
                        feature_value = features.get(feature_name, 0.0)
                        if isinstance(feature_value, (int, float)):
                            feature_impact[feature_name] += feature_value * success_rate
            
            # å½’ä¸€åŒ–
            total_impact = sum(feature_impact.values())
            if total_impact > 0:
                feature_impact = {k: v / total_impact for k, v in feature_impact.items()}
        
        return feature_impact
    
    def _analyze_context_distribution(self) -> Dict[str, Any]:
        """åˆ†æä¸Šä¸‹æ–‡ç‰¹å¾åˆ†å¸ƒ"""
        contextual_selections = [h for h in self.selection_history if h.get('context_features')]
        
        if not contextual_selections:
            return {}
        
        # ç»Ÿè®¡å„ä¸ªç‰¹å¾çš„åˆ†å¸ƒ
        intent_dist = defaultdict(int)
        domain_dist = defaultdict(int)
        complexity_dist = {'low': 0, 'medium': 0, 'high': 0}
        
        for selection in contextual_selections:
            features = selection.get('context_features', {})
            
            # æ„å›¾åˆ†å¸ƒ
            intent = features.get('task_intent', 'unknown')
            intent_dist[intent] += 1
            
            # é¢†åŸŸåˆ†å¸ƒ
            domain = features.get('task_domain', 'unknown')
            domain_dist[domain] += 1
            
            # å¤æ‚åº¦åˆ†å¸ƒ
            complexity = features.get('task_complexity', 0.5)
            if complexity < 0.3:
                complexity_dist['low'] += 1
            elif complexity < 0.7:
                complexity_dist['medium'] += 1
            else:
                complexity_dist['high'] += 1
        
        return {
            'intent_distribution': dict(intent_dist),
            'domain_distribution': dict(domain_dist),
            'complexity_distribution': dict(complexity_dist),
            'total_samples': len(contextual_selections)
        }
    
    def get_verified_reasoning_report(self) -> Dict[str, Any]:
        """
        ğŸ”¬ è·å–å¯éªŒè¯æ¨ç†æŠ¥å‘Š
        
        Returns:
            å¯éªŒè¯æ¨ç†ç³»ç»Ÿçš„è¯¦ç»†æŠ¥å‘Š
        """
        try:
            # ç»Ÿè®¡é¢„æ¡ä»¶æ£€æŸ¥ç»“æœ
            verification_stats = {
                'total_verifications': 0,
                'passed_verifications': 0,
                'failed_verifications': 0,
                'verification_success_rate': 0.0,
                'common_failure_reasons': defaultdict(int),
                'success_signal_corrections': 0
            }
            
            # ä»é€‰æ‹©å†å²ä¸­ç»Ÿè®¡éªŒè¯æ•°æ®
            for selection in self.selection_history:
                if 'verification_result' in selection:
                    verification_stats['total_verifications'] += 1
                    if selection['verification_result'].get('passed', False):
                        verification_stats['passed_verifications'] += 1
                    else:
                        verification_stats['failed_verifications'] += 1
                        reason = selection['verification_result'].get('reason', 'unknown')
                        verification_stats['common_failure_reasons'][reason] += 1
            
            if verification_stats['total_verifications'] > 0:
                verification_stats['verification_success_rate'] = (
                    verification_stats['passed_verifications'] / verification_stats['total_verifications']
                )
            
            # è·å–æ¨ç†å¼•æ“ç»Ÿè®¡
            reasoning_engine_stats = {}
            if hasattr(self.reasoning_engine, 'get_statistics'):
                reasoning_engine_stats = self.reasoning_engine.get_statistics()
            
            return {
                'verification_stats': verification_stats,
                'reasoning_engine_stats': reasoning_engine_stats,
                'contract_validation_enabled': True,
                'success_signal_verification_enabled': True
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–å¯éªŒè¯æ¨ç†æŠ¥å‘Šå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def get_comprehensive_system_status(self) -> Dict[str, Any]:
        """
        ğŸ¯ è·å–ç»¼åˆç³»ç»ŸçŠ¶æ€
        
        Returns:
            åŒ…å«æ‰€æœ‰å­ç³»ç»ŸçŠ¶æ€çš„ç»¼åˆæŠ¥å‘Š
        """
        try:
            return {
                'timestamp': time.time(),
                'system_mode': 'contextual_bandit_with_verified_reasoning',
                
                # ğŸ¯ ä¸Šä¸‹æ–‡BanditçŠ¶æ€
                'contextual_bandit': self.get_contextual_bandit_stats(),
                
                # ğŸ”¬ å¯éªŒè¯æ¨ç†çŠ¶æ€
                'verified_reasoning': self.get_verified_reasoning_report(),
                
                # ğŸ† é»„é‡‘æ¨¡æ¿çŠ¶æ€
                'golden_templates': self.get_golden_template_stats(),
                
                # ğŸ­ è¯•ç‚¼åœºçŠ¶æ€
                'trial_ground': self.get_trial_ground_analytics(),
                
                # ğŸ“Š ä¼ ç»ŸMABçŠ¶æ€ï¼ˆå‘åå…¼å®¹ï¼‰
                'traditional_mab': self.get_system_status(),
                
                # ğŸ”§ å·¥å…·å¥åº·çŠ¶æ€
                'tool_health': self._get_tool_health_summary(),
                
                # ğŸ“ˆ æ€§èƒ½è¶‹åŠ¿
                'performance_trends': self._get_performance_trends()
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»¼åˆç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {'error': str(e), 'timestamp': time.time()}
    
    def _get_tool_health_summary(self) -> Dict[str, Any]:
        """è·å–å·¥å…·å¥åº·çŠ¶æ€æ‘˜è¦"""
        if not self.tool_health_cache:
            return {'total_tools': 0, 'healthy_tools': 0, 'health_rate': 0.0}
        
        healthy_count = 0
        total_count = len(self.tool_health_cache)
        
        for tool_name, cached_data in self.tool_health_cache.items():
            if cached_data['status']['is_healthy']:
                healthy_count += 1
        
        return {
            'total_tools': total_count,
            'healthy_tools': healthy_count,
            'health_rate': healthy_count / total_count if total_count > 0 else 0.0,
            'last_check_time': max(
                (data['timestamp'] for data in self.tool_health_cache.values()),
                default=0.0
            )
        }
    
    def _get_performance_trends(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½è¶‹åŠ¿åˆ†æ"""
        recent_selections = self.selection_history[-50:] if len(self.selection_history) > 50 else self.selection_history
        
        if not recent_selections:
            return {'trend': 'insufficient_data'}
        
        # åˆ†ææœ€è¿‘çš„æˆåŠŸç‡è¶‹åŠ¿
        success_rates = []
        for selection in recent_selections:
            path_id = selection.get('path_id')
            if path_id in self.path_arms:
                success_rates.append(self.path_arms[path_id].success_rate)
        
        if len(success_rates) < 10:
            return {'trend': 'insufficient_data'}
        
        # ç®€å•çš„è¶‹åŠ¿åˆ†æ
        first_half = success_rates[:len(success_rates)//2]
        second_half = success_rates[len(success_rates)//2:]
        
        first_avg = sum(first_half) / len(first_half)
        second_avg = sum(second_half) / len(second_half)
        
        if second_avg > first_avg + 0.05:
            trend = 'improving'
        elif second_avg < first_avg - 0.05:
            trend = 'declining'
        else:
            trend = 'stable'
        
        return {
            'trend': trend,
            'recent_avg_success_rate': second_avg,
            'improvement': second_avg - first_avg,
            'sample_size': len(success_rates)
        }
    
    def export_system_configuration(self) -> Dict[str, Any]:
        """
        ğŸ”§ å¯¼å‡ºç³»ç»Ÿé…ç½®
        
        Returns:
            å®Œæ•´çš„ç³»ç»Ÿé…ç½®æ•°æ®
        """
        return {
            'contextual_bandit_config': {
                'algorithm': self.contextual_bandit.algorithm if hasattr(self.contextual_bandit, 'algorithm') else 'unknown',
                'feature_dim': self.contextual_bandit.feature_dim if hasattr(self.contextual_bandit, 'feature_dim') else 8,
                'storage_path': self.contextual_bandit.storage_path if hasattr(self.contextual_bandit, 'storage_path') else 'unknown'
            },
            'golden_template_config': self.golden_template_config,
            'trial_config': self.trial_config,
            'source_weight_config': self.source_weight_config,
            'health_check_interval': self.health_check_interval,
            'mab_config': MAB_CONFIG
        }
    
    def demo_contextual_bandit_workflow(self, demo_query: str = "è¯·åˆ†æä¸€ä¸‹äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨å‰æ™¯"):
        """
        ğŸ¯ æ¼”ç¤ºä¸Šä¸‹æ–‡Bandit + å¯éªŒè¯æ¨ç†çš„å®Œæ•´å·¥ä½œæµç¨‹
        
        Args:
            demo_query: æ¼”ç¤ºç”¨çš„æŸ¥è¯¢
        """
        logger.info("ğŸ¯ å¼€å§‹ä¸Šä¸‹æ–‡Bandit + å¯éªŒè¯æ¨ç†æ¼”ç¤º")
        logger.info(f"ğŸ“ æ¼”ç¤ºæŸ¥è¯¢: {demo_query}")
        
        print("\n" + "="*80)
        print("ğŸ¯ ä¸Šä¸‹æ–‡å¤šè‡‚è€è™æœº + å¯éªŒè¯æ¨ç†ç³»ç»Ÿæ¼”ç¤º")
        print("="*80)
        
        # 1. å±•ç¤ºè¯­ä¹‰åˆ†æèƒ½åŠ›
        print("\nğŸ§  ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½è¯­ä¹‰åˆ†æ")
        print("-" * 40)
        
        context_features = self.extract_context_features(demo_query)
        print(f"âœ… ä»»åŠ¡æ„å›¾: {context_features.task_intent}")
        print(f"âœ… ä»»åŠ¡é¢†åŸŸ: {context_features.task_domain}")
        print(f"âœ… å¤æ‚åº¦è¯„åˆ†: {context_features.task_complexity:.3f}")
        print(f"âœ… è¾“å…¥é•¿åº¦è¯„åˆ†: {context_features.input_length:.3f}")
        
        # 2. å±•ç¤ºä¸Šä¸‹æ–‡Banditç»Ÿè®¡
        print("\nğŸ¯ ç¬¬äºŒæ­¥ï¼šä¸Šä¸‹æ–‡BanditçŠ¶æ€")
        print("-" * 40)
        
        bandit_stats = self.get_contextual_bandit_stats()
        print(f"âœ… ä¸Šä¸‹æ–‡é€‰æ‹©æ¬¡æ•°: {bandit_stats['integration_stats']['total_contextual_selections']}")
        print(f"âœ… ä¸Šä¸‹æ–‡æˆåŠŸç‡: {bandit_stats['integration_stats']['contextual_success_rate']:.3f}")
        
        feature_importance = bandit_stats['integration_stats']['feature_importance']
        print("âœ… ç‰¹å¾é‡è¦æ€§åˆ†æ:")
        for feature, importance in feature_importance.items():
            print(f"   - {feature}: {importance:.3f}")
        
        # 3. å±•ç¤ºå¯éªŒè¯æ¨ç†èƒ½åŠ›
        print("\nğŸ”¬ ç¬¬ä¸‰æ­¥ï¼šå¯éªŒè¯æ¨ç†æŠ¥å‘Š")
        print("-" * 40)
        
        reasoning_report = self.get_verified_reasoning_report()
        print(f"âœ… éªŒè¯æˆåŠŸç‡: {reasoning_report['verification_stats']['verification_success_rate']:.3f}")
        print(f"âœ… æ€»éªŒè¯æ¬¡æ•°: {reasoning_report['verification_stats']['total_verifications']}")
        print("âœ… åˆçº¦éªŒè¯: å·²å¯ç”¨")
        print("âœ… æˆåŠŸä¿¡å·éªŒè¯: å·²å¯ç”¨")
        
        # 4. å±•ç¤ºç³»ç»Ÿç»¼åˆçŠ¶æ€
        print("\nğŸ“Š ç¬¬å››æ­¥ï¼šç³»ç»Ÿç»¼åˆçŠ¶æ€")
        print("-" * 40)
        
        system_status = self.get_comprehensive_system_status()
        print(f"âœ… ç³»ç»Ÿæ¨¡å¼: {system_status['system_mode']}")
        print(f"âœ… å·¥å…·å¥åº·ç‡: {system_status['tool_health']['health_rate']:.1%}")
        print(f"âœ… æ€§èƒ½è¶‹åŠ¿: {system_status['performance_trends']['trend']}")
        print(f"âœ… é»„é‡‘æ¨¡æ¿æ•°é‡: {system_status['golden_templates']['total_templates']}")
        
        # 5. å±•ç¤ºé…ç½®å¯¼å‡º
        print("\nğŸ”§ ç¬¬äº”æ­¥ï¼šç³»ç»Ÿé…ç½®")
        print("-" * 40)
        
        config = self.export_system_configuration()
        print(f"âœ… ä¸Šä¸‹æ–‡Banditç®—æ³•: {config['contextual_bandit_config']['algorithm']}")
        print(f"âœ… ç‰¹å¾ç»´åº¦: {config['contextual_bandit_config']['feature_dim']}")
        print(f"âœ… è¯­ä¹‰åˆ†æ: å·²é›†æˆ")
        print(f"âœ… å¯éªŒè¯æ¨ç†: å·²é›†æˆ")
        
        print("\n" + "="*80)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼ç³»ç»Ÿå·²æˆåŠŸå‡çº§ä¸ºä¸Šä¸‹æ–‡Bandit + å¯éªŒè¯æ¨ç†")
        print("="*80)
        
        return {
            'demo_query': demo_query,
            'context_features': context_features.to_dict(),
            'bandit_stats': bandit_stats,
            'reasoning_report': reasoning_report,
            'system_status': system_status,
            'configuration': config
        }
    
    def _create_tool_arm_if_missing(self, tool_id: str, tool_name: str = None) -> EnhancedDecisionArm:
        """
        åŠ¨æ€åˆ›å»ºå·¥å…·å†³ç­–è‡‚ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        
        Args:
            tool_id: å·¥å…·ID
            tool_name: å·¥å…·åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨tool_idï¼‰
            
        Returns:
            å¯¹åº”çš„å·¥å…·å†³ç­–è‡‚
        """
        if tool_id not in self.tool_arms:
            if tool_name is None:
                tool_name = tool_id  # é»˜è®¤ä½¿ç”¨tool_idä½œä¸ºå·¥å…·åç§°
            
            self.tool_arms[tool_id] = EnhancedDecisionArm(
                path_id=tool_id,
                option=tool_name
            )
            logger.debug(f"ğŸ”§ åŠ¨æ€åˆ›å»ºå·¥å…·å†³ç­–è‡‚: {tool_id} ({tool_name})")
        
        return self.tool_arms[tool_id]
    
    # ==================== ğŸ­ è¯•ç‚¼åœºç³»ç»Ÿæ ¸å¿ƒæ–¹æ³• ====================
    
    def _detect_path_source(self, strategy_id: str, path_type: str, reasoning_path: 'ReasoningPath' = None) -> str:
        """
        æ™ºèƒ½æ£€æµ‹è·¯å¾„æ¥æº
        
        Args:
            strategy_id: ç­–ç•¥ID
            path_type: è·¯å¾„ç±»å‹
            reasoning_path: æ¨ç†è·¯å¾„å¯¹è±¡
            
        Returns:
            è·¯å¾„æ¥æºç±»å‹
        """
        # 1. åŸºäºç­–ç•¥IDå‘½åæ¨¡å¼æ£€æµ‹
        if "learned_" in strategy_id or "explored_" in strategy_id or "generated_" in strategy_id:
            return "learned_exploration"
        
        if "custom_" in strategy_id or "manual_" in strategy_id or "user_" in strategy_id:
            return "manual_addition"
        
        # 2. åŸºäºè·¯å¾„ç±»å‹æ£€æµ‹
        if path_type and ("å­¦ä¹ " in path_type or "æ¢ç´¢" in path_type or "å‘ç°" in path_type):
            return "learned_exploration"
        
        # 3. åŸºäºæ¨ç†è·¯å¾„å¯¹è±¡å…ƒæ•°æ®æ£€æµ‹
        if reasoning_path:
            # æ£€æŸ¥è·¯å¾„æè¿°ä¸­çš„å…³é”®è¯
            description = getattr(reasoning_path, 'description', '')
            if any(keyword in description for keyword in ["ä»æ¢ç´¢ä¸­å­¦ä¹ ", "çŸ¥è¯†å‘ç°", "å¤–éƒ¨æ™ºæ…§", "åŠ¨æ€ç”Ÿæˆ"]):
                return "learned_exploration"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å­¦ä¹ æ¥æºæ ‡è®°
            if hasattr(reasoning_path, 'is_learned') and getattr(reasoning_path, 'is_learned', False):
                return "learned_exploration"
        
        # 4. é»˜è®¤ä¸ºé™æ€æ¨¡æ¿
        return "static_template"
    
    def _mark_as_learned_path(self, strategy_id: str, reasoning_path: 'ReasoningPath' = None):
        """
        æ ‡è®°ä¸ºå­¦ä¹ è·¯å¾„ï¼Œè®°å½•ç›¸å…³å…ƒæ•°æ®
        
        Args:
            strategy_id: ç­–ç•¥ID
            reasoning_path: æ¨ç†è·¯å¾„å¯¹è±¡
        """
        learned_metadata = {
            "strategy_id": strategy_id,
            "marked_at": time.time(),
            "source": "knowledge_exploration",
            "initial_boost_given": True,
            "promotion_eligible": True,
            "trial_start_time": time.time()
        }
        
        # ä»æ¨ç†è·¯å¾„å¯¹è±¡ä¸­æå–æ›´å¤šå…ƒæ•°æ®
        if reasoning_path:
            learned_metadata.update({
                "path_type": getattr(reasoning_path, 'path_type', ''),
                "description": getattr(reasoning_path, 'description', ''),
                "learning_source": getattr(reasoning_path, 'learning_source', ''),
                "is_learned": getattr(reasoning_path, 'is_learned', True),
                "effectiveness_score": getattr(reasoning_path, 'effectiveness_score', 0.5)
            })
        
        # æ³¨å†Œåˆ°è¯•ç‚¼åœº
        self.trial_ground["learned_paths"][strategy_id] = learned_metadata
        
        # æ¿€æ´»æ¢ç´¢å¢å¼º
        self.trial_ground["exploration_boost_active"][strategy_id] = self.trial_config["exploration_boost_rounds"]
        
        logger.info(f"ğŸ­ [è¯•ç‚¼åœº] è·¯å¾„å·²æ ‡è®°ä¸ºå­¦ä¹ è·¯å¾„: {strategy_id}")
        logger.info(f"ğŸ­ [è¯•ç‚¼åœº] æ¢ç´¢å¢å¼ºè½®æ•°: {self.trial_config['exploration_boost_rounds']}")
        logger.info(f"ğŸ­ [è¯•ç‚¼åœº] å½“å‰è¯•ç‚¼åœºæ´»è·ƒè·¯å¾„æ•°: {len(self.trial_ground['exploration_boost_active'])}")
    
    def _record_trial_entry(self, strategy_id: str, path_type: str, source: str):
        """
        è®°å½•è¯•ç‚¼åœºè¿›å…¥å†å²
        
        Args:
            strategy_id: ç­–ç•¥ID
            path_type: è·¯å¾„ç±»å‹
            source: è·¯å¾„æ¥æº
        """
        trial_record = {
            "strategy_id": strategy_id,
            "path_type": path_type,
            "source": source,
            "entry_time": time.time(),
            "entry_round": self.total_path_selections,
            "status": "active_trial"
        }
        
        self.trial_ground["trial_history"].append(trial_record)
        
        # ä¿æŒå†å²è®°å½•å¤§å°
        if len(self.trial_ground["trial_history"]) > 1000:
            self.trial_ground["trial_history"] = self.trial_ground["trial_history"][-800:]
        
        logger.info(f"ğŸ­ [è¯•ç‚¼åœº] {strategy_id} å¼€å§‹è¯•ç‚¼ (æ¥æº: {source})")
        logger.info(f"ğŸ­ [è¯•ç‚¼åœº] è¯•ç‚¼å†å²è®°å½•æ•°: {len(self.trial_ground['trial_history'])}")
    
    def is_learned_path(self, strategy_id: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºå­¦ä¹ è·¯å¾„
        
        Args:
            strategy_id: ç­–ç•¥ID
            
        Returns:
            æ˜¯å¦ä¸ºå­¦ä¹ è·¯å¾„
        """
        return strategy_id in self.trial_ground["learned_paths"]
    
    def get_exploration_boost(self, strategy_id: str) -> float:
        """
        è·å–è·¯å¾„çš„æ¢ç´¢å¢å¼ºç³»æ•°
        
        Args:
            strategy_id: ç­–ç•¥ID
            
        Returns:
            æ¢ç´¢å¢å¼ºç³»æ•° (1.0 = æ— å¢å¼º, > 1.0 = æœ‰å¢å¼º)
        """
        boost_factor = 1.0
        
        # åŸºç¡€å¢å¼ºï¼šæ–°å­¦ä¹ è·¯å¾„
        if strategy_id in self.trial_ground["exploration_boost_active"]:
            remaining_rounds = self.trial_ground["exploration_boost_active"][strategy_id]
            if remaining_rounds > 0:
                # é€’å‡çš„æ¢ç´¢å¢å¼º
                base_bonus = self.trial_config["learned_path_bonus"]
                decay_factor = remaining_rounds / self.trial_config["exploration_boost_rounds"]
                boost_factor += base_bonus * decay_factor
        
        # ç‰¹æ®Šå¢å¼ºï¼šå­¦ä¹ è·¯å¾„æ°¸ä¹…å°å¹…å¢å¼º
        if self.is_learned_path(strategy_id):
            boost_factor += 0.05  # 5%çš„æ°¸ä¹…å°å¹…å¢å¼º
        
        return boost_factor
    
    def _update_exploration_boost(self, strategy_id: str):
        """
        æ›´æ–°æ¢ç´¢å¢å¼ºçŠ¶æ€ï¼ˆæ¯æ¬¡é€‰æ‹©åè°ƒç”¨ï¼‰
        
        Args:
            strategy_id: è¢«é€‰æ‹©çš„ç­–ç•¥ID
        """
        if strategy_id in self.trial_ground["exploration_boost_active"]:
            remaining = self.trial_ground["exploration_boost_active"][strategy_id]
            if remaining > 0:
                self.trial_ground["exploration_boost_active"][strategy_id] = remaining - 1
                logger.info(f"ğŸ­ [è¯•ç‚¼åœº] è·¯å¾„ {strategy_id} æ¢ç´¢å¢å¼ºå‰©ä½™: {remaining - 1} è½®")
                
                if remaining == 1:  # å³å°†ç”¨å®Œ
                    logger.info(f"ğŸ¯ [è¯•ç‚¼åœº] è·¯å¾„ {strategy_id} çš„æ¢ç´¢å¢å¼ºå³å°†ç»“æŸ")
                elif remaining - 1 <= 0:
                    del self.trial_ground["exploration_boost_active"][strategy_id]
                    logger.info(f"âœ… [è¯•ç‚¼åœº] è·¯å¾„ {strategy_id} å®Œæˆæ¢ç´¢å¢å¼ºæœŸï¼Œè¿›å…¥æ­£å¸¸ç«äº‰")
    
    def _check_culling_candidates(self, strategy_id: str, arm: EnhancedDecisionArm, success: bool):
        """
        ğŸ—¡ï¸ æ£€æŸ¥å¹¶ç®¡ç†æ·˜æ±°å€™é€‰è·¯å¾„
        
        Args:
            strategy_id: ç­–ç•¥ID
            arm: å†³ç­–è‡‚å¯¹è±¡
            success: æœ€æ–°æ‰§è¡Œç»“æœ
        """
        # åªæ£€æŸ¥æœ‰è¶³å¤Ÿæ ·æœ¬çš„è·¯å¾„
        if arm.activation_count < self.trial_config["culling_min_samples"]:
            return
        
        # è·å–æˆåŠŸç‡é˜ˆå€¼
        culling_threshold = self.trial_config["culling_threshold"]
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¢«åŠ å…¥æ·˜æ±°å€™é€‰
        if arm.success_rate < culling_threshold:
            if strategy_id not in self.trial_ground["culling_candidates"]:
                self.trial_ground["culling_candidates"].add(strategy_id)
                
                # è®°å½•è¿›å…¥æ·˜æ±°å€™é€‰çš„åŸå› 
                self.trial_ground["performance_watch_list"][strategy_id] = {
                    "reason": "low_success_rate",
                    "success_rate": arm.success_rate,
                    "threshold": culling_threshold,
                    "added_at": time.time(),
                    "sample_count": arm.activation_count,
                    "consecutive_failures": self._calculate_consecutive_failures(arm)
                }
                
                logger.warning(f"âš ï¸ è·¯å¾„ {strategy_id} è¿›å…¥æ·˜æ±°å€™é€‰åå•")
                logger.warning(f"   æˆåŠŸç‡: {arm.success_rate:.3f} < é˜ˆå€¼: {culling_threshold}")
                logger.warning(f"   æ ·æœ¬æ•°: {arm.activation_count}")
                
                # å¦‚æœæ˜¯å­¦ä¹ è·¯å¾„ï¼Œç»™äºˆè­¦å‘Šä½†ä¸ç«‹å³æ·˜æ±°
                if self.is_learned_path(strategy_id):
                    logger.warning(f"ğŸŒ± å­¦ä¹ è·¯å¾„ {strategy_id} è¡¨ç°ä¸ä½³ï¼Œå°†ç»™äºˆé¢å¤–è§‚å¯ŸæœŸ")
        
        # å¦‚æœæˆåŠŸç‡å›å‡ï¼Œç§»å‡ºæ·˜æ±°å€™é€‰
        elif strategy_id in self.trial_ground["culling_candidates"]:
            if arm.success_rate >= culling_threshold * 1.2:  # éœ€è¦è¶…è¿‡é˜ˆå€¼20%æ‰èƒ½ç§»å‡º
                self.trial_ground["culling_candidates"].remove(strategy_id)
                if strategy_id in self.trial_ground["performance_watch_list"]:
                    del self.trial_ground["performance_watch_list"][strategy_id]
                
                logger.info(f"âœ… è·¯å¾„ {strategy_id} æ€§èƒ½å›å‡ï¼Œç§»å‡ºæ·˜æ±°å€™é€‰åå•")
                logger.info(f"   å½“å‰æˆåŠŸç‡: {arm.success_rate:.3f} >= å›å½’é˜ˆå€¼: {culling_threshold * 1.2:.3f}")
    
    def _calculate_consecutive_failures(self, arm: EnhancedDecisionArm) -> int:
        """
        è®¡ç®—è¿ç»­å¤±è´¥æ¬¡æ•°
        
        Args:
            arm: å†³ç­–è‡‚å¯¹è±¡
            
        Returns:
            è¿ç»­å¤±è´¥æ¬¡æ•°
        """
        if not arm.recent_results:
            return 0
        
        consecutive_count = 0
        # ä»æœ€è¿‘çš„ç»“æœå¼€å§‹å¾€å‰æ•°
        for result in reversed(arm.recent_results):
            if not result:  # å¦‚æœæ˜¯å¤±è´¥
                consecutive_count += 1
            else:  # å¦‚æœæˆåŠŸäº†ï¼Œå°±åœæ­¢è®¡æ•°
                break
        
        return consecutive_count
    
    def execute_automatic_culling(self) -> Dict[str, Any]:
        """
        ğŸ—¡ï¸ æ‰§è¡Œè‡ªåŠ¨æ·˜æ±°æœºåˆ¶
        
        Returns:
            æ·˜æ±°æ‰§è¡Œç»“æœ
        """
        culling_results = {
            "executed_at": time.time(),
            "candidates_reviewed": len(self.trial_ground["culling_candidates"]),
            "paths_culled": [],
            "paths_spared": [],
            "action_summary": {}
        }
        
        if not self.trial_ground["culling_candidates"]:
            culling_results["action_summary"] = {"message": "æ— éœ€è¦æ·˜æ±°çš„å€™é€‰è·¯å¾„"}
            return culling_results
        
        logger.info(f"ğŸ—¡ï¸ å¼€å§‹è‡ªåŠ¨æ·˜æ±°æ£€æŸ¥ï¼Œå€™é€‰è·¯å¾„: {len(self.trial_ground['culling_candidates'])} ä¸ª")
        
        candidates_to_remove = set()
        
        for strategy_id in list(self.trial_ground["culling_candidates"]):
            if strategy_id not in self.path_arms:
                candidates_to_remove.add(strategy_id)
                continue
            
            arm = self.path_arms[strategy_id]
            watch_data = self.trial_ground["performance_watch_list"].get(strategy_id, {})
            
            # å†³å®šæ˜¯å¦çœŸæ­£æ·˜æ±°
            should_cull, reason = self._should_cull_path(strategy_id, arm, watch_data)
            
            if should_cull:
                # æ‰§è¡Œæ·˜æ±°
                self._cull_path(strategy_id, reason)
                candidates_to_remove.add(strategy_id)
                culling_results["paths_culled"].append({
                    "strategy_id": strategy_id,
                    "reason": reason,
                    "final_success_rate": arm.success_rate,
                    "total_activations": arm.activation_count
                })
                logger.info(f"ğŸ—¡ï¸ æ·˜æ±°è·¯å¾„: {strategy_id} - {reason}")
            else:
                # æš‚ç¼“æ·˜æ±°
                culling_results["paths_spared"].append({
                    "strategy_id": strategy_id,
                    "reason": f"æš‚ç¼“æ·˜æ±° - {reason}",
                    "current_success_rate": arm.success_rate
                })
                logger.info(f"â³ æš‚ç¼“æ·˜æ±°è·¯å¾„: {strategy_id} - {reason}")
        
        # æ¸…ç†å€™é€‰åå•
        for strategy_id in candidates_to_remove:
            self.trial_ground["culling_candidates"].discard(strategy_id)
            self.trial_ground["performance_watch_list"].pop(strategy_id, None)
        
        culling_results["action_summary"] = {
            "total_culled": len(culling_results["paths_culled"]),
            "total_spared": len(culling_results["paths_spared"]),
            "remaining_candidates": len(self.trial_ground["culling_candidates"])
        }
        
        logger.info(f"ğŸ—¡ï¸ æ·˜æ±°æ£€æŸ¥å®Œæˆ: æ·˜æ±° {len(culling_results['paths_culled'])} ä¸ª, "
                   f"æš‚ç¼“ {len(culling_results['paths_spared'])} ä¸ª")
        
        return culling_results
    
    def _should_cull_path(self, strategy_id: str, arm: EnhancedDecisionArm, watch_data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ·˜æ±°æŒ‡å®šè·¯å¾„
        
        Args:
            strategy_id: ç­–ç•¥ID
            arm: å†³ç­–è‡‚å¯¹è±¡
            watch_data: ç›‘æ§æ•°æ®
            
        Returns:
            (æ˜¯å¦æ·˜æ±°, åŸå› )
        """
        # 1. å­¦ä¹ è·¯å¾„è·å¾—é¢å¤–ä¿æŠ¤
        if self.is_learned_path(strategy_id):
            # å­¦ä¹ è·¯å¾„éœ€è¦æ›´å·®çš„è¡¨ç°æ‰ä¼šè¢«æ·˜æ±°
            harsh_threshold = self.trial_config["culling_threshold"] * 0.5  # æ›´ä¸¥æ ¼çš„é˜ˆå€¼
            if arm.success_rate > harsh_threshold:
                return False, "å­¦ä¹ è·¯å¾„äº«å—ä¿æŠ¤æœŸ"
            
            # æ£€æŸ¥å­¦ä¹ è·¯å¾„çš„è¯•éªŒæ—¶é—´
            learned_meta = self.trial_ground["learned_paths"].get(strategy_id, {})
            trial_time = time.time() - learned_meta.get("trial_start_time", time.time())
            if trial_time < 3600:  # 1å°æ—¶ä¿æŠ¤æœŸ
                return False, "å­¦ä¹ è·¯å¾„ä»åœ¨ä¿æŠ¤æœŸå†…"
        
        # 2. é»„é‡‘æ¨¡æ¿ç»ä¸æ·˜æ±°
        if strategy_id in self.golden_templates:
            return False, "é»„é‡‘æ¨¡æ¿ä¸å¯æ·˜æ±°"
        
        # 3. æ£€æŸ¥è¿ç»­å¤±è´¥æƒ…å†µ
        consecutive_failures = watch_data.get("consecutive_failures", 0)
        if consecutive_failures >= 10:  # è¿ç»­10æ¬¡å¤±è´¥
            return True, f"è¿ç»­å¤±è´¥{consecutive_failures}æ¬¡"
        
        # 4. æ£€æŸ¥é•¿æœŸè¡¨ç°
        if arm.success_rate < self.trial_config["culling_threshold"] * 0.8:  # ä½äºé˜ˆå€¼çš„80%
            watch_duration = time.time() - watch_data.get("added_at", time.time())
            if watch_duration > 1800:  # åœ¨è§‚å¯Ÿåå•è¶…è¿‡30åˆ†é’Ÿ
                return True, f"é•¿æœŸè¡¨ç°ä¸ä½³ (æˆåŠŸç‡: {arm.success_rate:.3f})"
        
        # 5. æ£€æŸ¥ä½¿ç”¨é¢‘ç‡
        if arm.activation_count > 50 and arm.success_rate < self.trial_config["culling_threshold"]:
            return True, f"å¤§é‡è¯•éªŒåè¡¨ç°ä»ä¸ä½³ ({arm.activation_count} æ¬¡è¯•éªŒ)"
        
        return False, "æš‚ä¸ç¬¦åˆæ·˜æ±°æ¡ä»¶"
    
    def _cull_path(self, strategy_id: str, reason: str):
        """
        æ‰§è¡Œè·¯å¾„æ·˜æ±°
        
        Args:
            strategy_id: ç­–ç•¥ID
            reason: æ·˜æ±°åŸå› 
        """
        if strategy_id in self.path_arms:
            # è®°å½•æ·˜æ±°å†å²
            culled_arm = self.path_arms[strategy_id]
            cull_record = {
                "strategy_id": strategy_id,
                "culled_at": time.time(),
                "reason": reason,
                "final_stats": {
                    "success_rate": culled_arm.success_rate,
                    "total_activations": culled_arm.activation_count,
                    "total_reward": culled_arm.total_reward
                },
                "was_learned_path": self.is_learned_path(strategy_id)
            }
            
            # ä¿å­˜åˆ°å†å²è®°å½•
            if "culled_paths" not in self.trial_ground:
                self.trial_ground["culled_paths"] = []
            self.trial_ground["culled_paths"].append(cull_record)
            
            # æ‰§è¡Œç§»é™¤
            del self.path_arms[strategy_id]
            
            # æ¸…ç†ç›¸å…³æ•°æ®
            self.trial_ground["learned_paths"].pop(strategy_id, None)
            self.trial_ground["exploration_boost_active"].pop(strategy_id, None)
            self.trial_ground["promotion_candidates"].discard(strategy_id)
            
            logger.info(f"ğŸ—¡ï¸ è·¯å¾„ {strategy_id} å·²è¢«æ·˜æ±°: {reason}")
            logger.info(f"   æœ€ç»ˆç»Ÿè®¡: æˆåŠŸç‡ {culled_arm.success_rate:.3f}, æ¿€æ´» {culled_arm.activation_count} æ¬¡")
    
    def get_trial_ground_analytics(self) -> Dict[str, Any]:
        """
        ğŸ“Š è·å–è¯•ç‚¼åœºå…¨é¢åˆ†ææ•°æ®
        
        Returns:
            è¯•ç‚¼åœºç»Ÿè®¡åˆ†æ
        """
        analytics = {
            "timestamp": time.time(),
            "overview": self._get_trial_overview(),
            "learned_paths": self._analyze_learned_paths(),
            "exploration_status": self._analyze_exploration_status(),
            "culling_analysis": self._analyze_culling_situation(),
            "performance_trends": self._analyze_performance_trends(),
            "golden_template_candidates": self._analyze_golden_candidates()
        }
        
        return analytics
    
    def _get_trial_overview(self) -> Dict[str, Any]:
        """è·å–è¯•ç‚¼åœºæ€»ä½“æ¦‚å†µ"""
        total_paths = len(self.path_arms)
        learned_paths = len(self.trial_ground["learned_paths"])
        
        return {
            "total_active_paths": total_paths,
            "learned_paths_count": learned_paths,
            "static_paths_count": total_paths - learned_paths,
            "exploration_boost_active": len(self.trial_ground["exploration_boost_active"]),
            "culling_candidates": len(self.trial_ground["culling_candidates"]),
            "promotion_candidates": len(self.trial_ground["promotion_candidates"]),
            "golden_templates": len(self.golden_templates),
            "culled_paths_history": len(self.trial_ground.get("culled_paths", []))
        }
    
    def _analyze_learned_paths(self) -> Dict[str, Any]:
        """åˆ†æå­¦ä¹ è·¯å¾„çš„è¯¦ç»†æƒ…å†µ"""
        learned_analysis = {
            "active_learned_paths": [],
            "performance_summary": {
                "excellent": 0,  # > 0.8
                "good": 0,       # 0.6-0.8
                "average": 0,    # 0.4-0.6
                "poor": 0        # < 0.4
            },
            "avg_success_rate": 0.0,
            "total_activations": 0
        }
        
        if not self.trial_ground["learned_paths"]:
            return learned_analysis
        
        success_rates = []
        total_activations = 0
        
        for strategy_id, meta in self.trial_ground["learned_paths"].items():
            if strategy_id not in self.path_arms:
                continue
                
            arm = self.path_arms[strategy_id]
            success_rate = arm.success_rate
            success_rates.append(success_rate)
            total_activations += arm.activation_count
            
            # æ€§èƒ½åˆ†ç±»
            if success_rate >= 0.8:
                learned_analysis["performance_summary"]["excellent"] += 1
            elif success_rate >= 0.6:
                learned_analysis["performance_summary"]["good"] += 1
            elif success_rate >= 0.4:
                learned_analysis["performance_summary"]["average"] += 1
            else:
                learned_analysis["performance_summary"]["poor"] += 1
            
            # è¯¦ç»†ä¿¡æ¯
            trial_duration = time.time() - meta.get("trial_start_time", time.time())
            learned_analysis["active_learned_paths"].append({
                "strategy_id": strategy_id,
                "source": meta.get("source", "unknown"),
                "success_rate": success_rate,
                "activations": arm.activation_count,
                "trial_duration_hours": trial_duration / 3600,
                "has_exploration_boost": strategy_id in self.trial_ground["exploration_boost_active"],
                "is_promotion_candidate": strategy_id in self.trial_ground["promotion_candidates"],
                "is_culling_candidate": strategy_id in self.trial_ground["culling_candidates"]
            })
        
        learned_analysis["avg_success_rate"] = sum(success_rates) / len(success_rates) if success_rates else 0.0
        learned_analysis["total_activations"] = total_activations
        
        return learned_analysis
    
    def _analyze_exploration_status(self) -> Dict[str, Any]:
        """åˆ†ææ¢ç´¢å¢å¼ºçŠ¶æ€"""
        exploration_analysis = {
            "active_boosts": [],
            "total_boost_paths": len(self.trial_ground["exploration_boost_active"]),
            "boost_distribution": {}
        }
        
        for strategy_id, remaining_rounds in self.trial_ground["exploration_boost_active"].items():
            if strategy_id in self.path_arms:
                arm = self.path_arms[strategy_id]
                exploration_analysis["active_boosts"].append({
                    "strategy_id": strategy_id,
                    "remaining_rounds": remaining_rounds,
                    "current_success_rate": arm.success_rate,
                    "activations_during_boost": arm.activation_count,
                    "is_learned_path": self.is_learned_path(strategy_id)
                })
                
                # åˆ†å¸ƒç»Ÿè®¡
                if remaining_rounds not in exploration_analysis["boost_distribution"]:
                    exploration_analysis["boost_distribution"][remaining_rounds] = 0
                exploration_analysis["boost_distribution"][remaining_rounds] += 1
        
        return exploration_analysis
    
    def _analyze_culling_situation(self) -> Dict[str, Any]:
        """åˆ†ææ·˜æ±°æƒ…å†µ"""
        culling_analysis = {
            "current_candidates": [],
            "recent_culled": [],
            "culling_threshold": self.trial_config["culling_threshold"],
            "protection_summary": {
                "golden_templates": 0,
                "learned_paths_protected": 0,
                "recent_paths": 0
            }
        }
        
        # å½“å‰æ·˜æ±°å€™é€‰
        for strategy_id in self.trial_ground["culling_candidates"]:
            if strategy_id in self.path_arms:
                arm = self.path_arms[strategy_id]
                watch_data = self.trial_ground["performance_watch_list"].get(strategy_id, {})
                
                culling_analysis["current_candidates"].append({
                    "strategy_id": strategy_id,
                    "success_rate": arm.success_rate,
                    "activations": arm.activation_count,
                    "watch_reason": watch_data.get("reason", "unknown"),
                    "watch_duration_minutes": (time.time() - watch_data.get("added_at", time.time())) / 60,
                    "is_learned_path": self.is_learned_path(strategy_id),
                    "consecutive_failures": watch_data.get("consecutive_failures", 0)
                })
        
        # æœ€è¿‘æ·˜æ±°çš„è·¯å¾„ï¼ˆæœ€å10ä¸ªï¼‰
        recent_culled = self.trial_ground.get("culled_paths", [])[-10:]
        for cull_record in recent_culled:
            culling_analysis["recent_culled"].append({
                "strategy_id": cull_record["strategy_id"],
                "culled_hours_ago": (time.time() - cull_record["culled_at"]) / 3600,
                "reason": cull_record["reason"],
                "final_success_rate": cull_record["final_stats"]["success_rate"],
                "was_learned_path": cull_record["was_learned_path"]
            })
        
        # ä¿æŠ¤æƒ…å†µç»Ÿè®¡
        for strategy_id in self.path_arms:
            if strategy_id in self.golden_templates:
                culling_analysis["protection_summary"]["golden_templates"] += 1
            elif self.is_learned_path(strategy_id):
                learned_meta = self.trial_ground["learned_paths"].get(strategy_id, {})
                trial_time = time.time() - learned_meta.get("trial_start_time", time.time())
                if trial_time < 3600:  # 1å°æ—¶ä¿æŠ¤æœŸ
                    culling_analysis["protection_summary"]["learned_paths_protected"] += 1
        
        return culling_analysis
    
    def _analyze_performance_trends(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        trends = {
            "overall_system_health": "healthy",
            "avg_success_rate": 0.0,
            "performance_distribution": {
                "excellent": 0,    # > 0.8
                "good": 0,         # 0.6-0.8
                "average": 0,      # 0.4-0.6
                "poor": 0,         # < 0.4
                "critical": 0      # < 0.2
            },
            "activation_distribution": {
                "highly_used": 0,     # > 100 activations
                "moderately_used": 0, # 20-100 activations
                "lightly_used": 0,    # 5-20 activations
                "rarely_used": 0      # < 5 activations
            },
            "trend_indicators": {
                "paths_improving": 0,
                "paths_declining": 0,
                "stable_paths": 0
            }
        }
        
        if not self.path_arms:
            return trends
        
        success_rates = []
        
        for strategy_id, arm in self.path_arms.items():
            success_rate = arm.success_rate
            success_rates.append(success_rate)
            
            # æ€§èƒ½åˆ†å¸ƒ
            if success_rate >= 0.8:
                trends["performance_distribution"]["excellent"] += 1
            elif success_rate >= 0.6:
                trends["performance_distribution"]["good"] += 1
            elif success_rate >= 0.4:
                trends["performance_distribution"]["average"] += 1
            elif success_rate >= 0.2:
                trends["performance_distribution"]["poor"] += 1
            else:
                trends["performance_distribution"]["critical"] += 1
            
            # ä½¿ç”¨é¢‘ç‡åˆ†å¸ƒ
            if arm.activation_count > 100:
                trends["activation_distribution"]["highly_used"] += 1
            elif arm.activation_count >= 20:
                trends["activation_distribution"]["moderately_used"] += 1
            elif arm.activation_count >= 5:
                trends["activation_distribution"]["lightly_used"] += 1
            else:
                trends["activation_distribution"]["rarely_used"] += 1
        
        trends["avg_success_rate"] = sum(success_rates) / len(success_rates)
        
        # ç³»ç»Ÿå¥åº·è¯„ä¼°
        poor_performance_ratio = (trends["performance_distribution"]["poor"] + 
                                trends["performance_distribution"]["critical"]) / len(self.path_arms)
        
        if poor_performance_ratio > 0.4:
            trends["overall_system_health"] = "critical"
        elif poor_performance_ratio > 0.2:
            trends["overall_system_health"] = "degraded"
        elif trends["avg_success_rate"] > 0.7:
            trends["overall_system_health"] = "excellent"
        else:
            trends["overall_system_health"] = "healthy"
        
        return trends
    
    def _analyze_golden_candidates(self) -> Dict[str, Any]:
        """åˆ†æé»„é‡‘æ¨¡æ¿å€™é€‰æƒ…å†µ"""
        golden_analysis = {
            "current_golden_count": len(self.golden_templates),
            "promotion_candidates": [],
            "golden_performance": {
                "avg_success_rate": 0.0,
                "total_activations": 0,
                "stability_score": 0.0
            }
        }
        
        # åˆ†ææå‡å€™é€‰
        for strategy_id in self.trial_ground["promotion_candidates"]:
            if strategy_id in self.path_arms:
                arm = self.path_arms[strategy_id]
                golden_analysis["promotion_candidates"].append({
                    "strategy_id": strategy_id,
                    "success_rate": arm.success_rate,
                    "activations": arm.activation_count,
                    "stability": arm.get_stability_score() if hasattr(arm, 'get_stability_score') else 0.0,
                    "is_learned_path": self.is_learned_path(strategy_id),
                    "qualification_score": self._calculate_golden_qualification_score(strategy_id, arm)
                })
        
        # åˆ†æç°æœ‰é»„é‡‘æ¨¡æ¿æ€§èƒ½
        if self.golden_templates:
            golden_success_rates = []
            golden_activations = 0
            
            for strategy_id in self.golden_templates:
                if strategy_id in self.path_arms:
                    arm = self.path_arms[strategy_id]
                    golden_success_rates.append(arm.success_rate)
                    golden_activations += arm.activation_count
            
            if golden_success_rates:
                golden_analysis["golden_performance"]["avg_success_rate"] = sum(golden_success_rates) / len(golden_success_rates)
                golden_analysis["golden_performance"]["total_activations"] = golden_activations
                golden_analysis["golden_performance"]["stability_score"] = min(golden_success_rates)  # æœ€ä½æˆåŠŸç‡ä½œä¸ºç¨³å®šæ€§æŒ‡æ ‡
        
        return golden_analysis
    
    def _calculate_golden_qualification_score(self, strategy_id: str, arm: EnhancedDecisionArm) -> float:
        """
        è®¡ç®—é»„é‡‘æ¨¡æ¿èµ„æ ¼è¯„åˆ†
        
        Args:
            strategy_id: ç­–ç•¥ID
            arm: å†³ç­–è‡‚å¯¹è±¡
            
        Returns:
            èµ„æ ¼è¯„åˆ† (0-1ä¹‹é—´)
        """
        # åŸºç¡€æˆåŠŸç‡æƒé‡ (40%)
        success_score = arm.success_rate * 0.4
        
        # ä½¿ç”¨é¢‘ç‡æƒé‡ (20%)
        frequency_score = min(arm.activation_count / 100, 1.0) * 0.2
        
        # ç¨³å®šæ€§æƒé‡ (20%) - åŸºäºæœ€è¿‘è¡¨ç°çš„æ–¹å·®
        stability_score = 0.0
        if arm.recent_results and len(arm.recent_results) >= 5:
            recent_success_rate = sum(arm.recent_results[-10:]) / min(len(arm.recent_results), 10)
            # ç¨³å®šæ€§ = 1 - |æ€»ä½“æˆåŠŸç‡ - æœ€è¿‘æˆåŠŸç‡|
            stability_score = max(0, 1 - abs(arm.success_rate - recent_success_rate)) * 0.2
        
        # å­¦ä¹ è·¯å¾„åŠ åˆ† (10%) - é¼“åŠ±ä»æ¢ç´¢ä¸­å­¦åˆ°çš„ä¼˜ç§€è·¯å¾„
        learning_bonus = 0.1 if self.is_learned_path(strategy_id) and arm.success_rate > 0.7 else 0.0
        
        # æ—¶é—´è¡°å‡ (10%) - æ–°è·¯å¾„éœ€è¦æ›´å¤šéªŒè¯æ—¶é—´
        if strategy_id in self.trial_ground["learned_paths"]:
            learned_meta = self.trial_ground["learned_paths"][strategy_id]
            trial_duration = time.time() - learned_meta.get("trial_start_time", time.time())
            time_score = min(trial_duration / (24 * 3600), 1.0) * 0.1  # 24å°æ—¶è¾¾åˆ°æ»¡åˆ†
        else:
            time_score = 0.1  # é™æ€è·¯å¾„ç»™æ»¡åˆ†
        
        return success_score + frequency_score + stability_score + learning_bonus + time_score
    
    # ğŸ­ è¯•ç‚¼åœºç®¡ç†å’Œç»´æŠ¤æ–¹æ³•
    
    def trigger_trial_ground_maintenance(self) -> Dict[str, Any]:
        """
        ğŸ”§ è§¦å‘è¯•ç‚¼åœºç»´æŠ¤ä»»åŠ¡
        
        Returns:
            ç»´æŠ¤ç»“æœæ‘˜è¦
        """
        maintenance_result = {
            "timestamp": time.time(),
            "tasks_executed": [],
            "cleanup_results": {},
            "analytics_snapshot": {}
        }
        
        logger.info("ğŸ”§ å¼€å§‹è¯•ç‚¼åœºç»´æŠ¤ä»»åŠ¡...")
        
        # 1. æ‰§è¡Œè‡ªåŠ¨æ·˜æ±°æ£€æŸ¥
        try:
            culling_results = self.execute_automatic_culling()
            maintenance_result["tasks_executed"].append("automatic_culling")
            maintenance_result["cleanup_results"]["culling"] = culling_results
            logger.info(f"âœ… è‡ªåŠ¨æ·˜æ±°æ£€æŸ¥å®Œæˆ: æ·˜æ±° {len(culling_results.get('paths_culled', []))} ä¸ªè·¯å¾„")
        except Exception as e:
            logger.error(f"âŒ è‡ªåŠ¨æ·˜æ±°æ£€æŸ¥å¤±è´¥: {e}")
            maintenance_result["cleanup_results"]["culling"] = {"error": str(e)}
        
        # 2. æ¸…ç†è¿‡æœŸçš„æ¢ç´¢å¢å¼º
        try:
            expired_boosts = self._cleanup_expired_exploration_boosts()
            maintenance_result["tasks_executed"].append("boost_cleanup")
            maintenance_result["cleanup_results"]["expired_boosts"] = expired_boosts
            logger.info(f"âœ… æ¢ç´¢å¢å¼ºæ¸…ç†å®Œæˆ: æ¸…ç† {expired_boosts['cleaned_count']} ä¸ªè¿‡æœŸå¢å¼º")
        except Exception as e:
            logger.error(f"âŒ æ¢ç´¢å¢å¼ºæ¸…ç†å¤±è´¥: {e}")
            maintenance_result["cleanup_results"]["expired_boosts"] = {"error": str(e)}
        
        # 3. ç®¡ç†æ·˜æ±°å†å²è®°å½•å¤§å°
        try:
            history_cleanup = self._manage_culled_history()
            maintenance_result["tasks_executed"].append("history_management")
            maintenance_result["cleanup_results"]["history"] = history_cleanup
            if history_cleanup.get("trimmed", 0) > 0:
                logger.info(f"âœ… æ·˜æ±°å†å²ç®¡ç†å®Œæˆ: ä¿®å‰ª {history_cleanup['trimmed']} æ¡è®°å½•")
        except Exception as e:
            logger.error(f"âŒ æ·˜æ±°å†å²ç®¡ç†å¤±è´¥: {e}")
            maintenance_result["cleanup_results"]["history"] = {"error": str(e)}
        
        # 4. ç”Ÿæˆåˆ†æå¿«ç…§
        try:
            analytics_snapshot = self.get_trial_ground_analytics()
            maintenance_result["tasks_executed"].append("analytics_snapshot")
            maintenance_result["analytics_snapshot"] = analytics_snapshot
            logger.info("âœ… åˆ†æå¿«ç…§ç”Ÿæˆå®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ åˆ†æå¿«ç…§ç”Ÿæˆå¤±è´¥: {e}")
            maintenance_result["analytics_snapshot"] = {"error": str(e)}
        
        logger.info(f"ğŸ”§ è¯•ç‚¼åœºç»´æŠ¤å®Œæˆï¼Œæ‰§è¡Œäº† {len(maintenance_result['tasks_executed'])} ä¸ªä»»åŠ¡")
        
        return maintenance_result
    
    def _cleanup_expired_exploration_boosts(self) -> Dict[str, Any]:
        """æ¸…ç†è¿‡æœŸçš„æ¢ç´¢å¢å¼º"""
        cleanup_result = {
            "cleaned_count": 0,
            "expired_paths": []
        }
        
        expired_paths = []
        for strategy_id, remaining_rounds in list(self.trial_ground["exploration_boost_active"].items()):
            if remaining_rounds <= 0:
                expired_paths.append(strategy_id)
        
        for strategy_id in expired_paths:
            del self.trial_ground["exploration_boost_active"][strategy_id]
            cleanup_result["expired_paths"].append(strategy_id)
        
        cleanup_result["cleaned_count"] = len(expired_paths)
        return cleanup_result
    
    def _manage_culled_history(self) -> Dict[str, Any]:
        """ç®¡ç†æ·˜æ±°å†å²è®°å½•å¤§å°"""
        history_result = {
            "current_count": len(self.trial_ground["culled_paths"]),
            "max_allowed": self.trial_config["max_culled_history"],
            "trimmed": 0
        }
        
        if history_result["current_count"] > history_result["max_allowed"]:
            # åªä¿ç•™æœ€æ–°çš„è®°å½•
            excess = history_result["current_count"] - history_result["max_allowed"]
            self.trial_ground["culled_paths"] = self.trial_ground["culled_paths"][-history_result["max_allowed"]:]
            history_result["trimmed"] = excess
            
            logger.info(f"ğŸ“š æ·˜æ±°å†å²è®°å½•ä¿®å‰ª: ä¿ç•™æœ€æ–° {history_result['max_allowed']} æ¡, åˆ é™¤ {excess} æ¡æ—§è®°å½•")
        
        return history_result
    
    def reset_path_trial_status(self, strategy_id: str) -> Dict[str, Any]:
        """
        ğŸ”„ é‡ç½®æŒ‡å®šè·¯å¾„çš„è¯•ç‚¼çŠ¶æ€
        
        Args:
            strategy_id: ç­–ç•¥ID
            
        Returns:
            é‡ç½®ç»“æœ
        """
        reset_result = {
            "strategy_id": strategy_id,
            "actions_taken": [],
            "success": False
        }
        
        try:
            # ä»å„ç§å€™é€‰åå•ä¸­ç§»é™¤
            if strategy_id in self.trial_ground["culling_candidates"]:
                self.trial_ground["culling_candidates"].remove(strategy_id)
                reset_result["actions_taken"].append("removed_from_culling_candidates")
            
            if strategy_id in self.trial_ground["promotion_candidates"]:
                self.trial_ground["promotion_candidates"].remove(strategy_id)
                reset_result["actions_taken"].append("removed_from_promotion_candidates")
            
            # é‡ç½®ç›‘æ§æ•°æ®
            if strategy_id in self.trial_ground["performance_watch_list"]:
                del self.trial_ground["performance_watch_list"][strategy_id]
                reset_result["actions_taken"].append("cleared_watch_list_entry")
            
            # é‡ç½®æ¢ç´¢å¢å¼º
            if strategy_id in self.trial_ground["exploration_boost_active"]:
                del self.trial_ground["exploration_boost_active"][strategy_id]
                reset_result["actions_taken"].append("cleared_exploration_boost")
            
            # é‡ç½®å†³ç­–è‡‚ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if strategy_id in self.path_arms:
                arm = self.path_arms[strategy_id]
                # ä¿ç•™åŸºæœ¬ç»“æ„ï¼Œä½†é‡ç½®ç»Ÿè®¡
                arm.success_count = 0
                arm.failure_count = 0
                arm.total_reward = 0.0
                arm.recent_results = []
                arm.activation_count = 0
                reset_result["actions_taken"].append("reset_decision_arm_stats")
            
            reset_result["success"] = True
            logger.info(f"ğŸ”„ è·¯å¾„ {strategy_id} è¯•ç‚¼çŠ¶æ€å·²é‡ç½®: {', '.join(reset_result['actions_taken'])}")
            
        except Exception as e:
            reset_result["error"] = str(e)
            logger.error(f"âŒ é‡ç½®è·¯å¾„ {strategy_id} è¯•ç‚¼çŠ¶æ€å¤±è´¥: {e}")
        
        return reset_result
    
    def force_promote_to_golden(self, strategy_id: str, reason: str = "manual_promotion") -> Dict[str, Any]:
        """
        ğŸ† å¼ºåˆ¶æå‡è·¯å¾„ä¸ºé»„é‡‘æ¨¡æ¿
        
        Args:
            strategy_id: ç­–ç•¥ID
            reason: æå‡åŸå› 
            
        Returns:
            æå‡ç»“æœ
        """
        promotion_result = {
            "strategy_id": strategy_id,
            "reason": reason,
            "success": False,
            "previous_status": {}
        }
        
        try:
            if strategy_id not in self.path_arms:
                promotion_result["error"] = "ç­–ç•¥IDä¸å­˜åœ¨"
                return promotion_result
            
            # è®°å½•ä¹‹å‰çš„çŠ¶æ€
            arm = self.path_arms[strategy_id]
            promotion_result["previous_status"] = {
                "success_rate": arm.success_rate,
                "activations": arm.activation_count,
                "was_golden": strategy_id in self.golden_templates
            }
            
            # æ‰§è¡Œæå‡
            if strategy_id not in self.golden_templates:
                self.golden_templates.add(strategy_id)
                logger.info(f"ğŸ† è·¯å¾„ {strategy_id} å·²è¢«å¼ºåˆ¶æå‡ä¸ºé»„é‡‘æ¨¡æ¿: {reason}")
                
                # ä»å€™é€‰åå•ä¸­ç§»é™¤
                self.trial_ground["promotion_candidates"].discard(strategy_id)
                self.trial_ground["culling_candidates"].discard(strategy_id)
                
                # è®°å½•æå‡å†å²
                if "promotion_history" not in self.trial_ground:
                    self.trial_ground["promotion_history"] = []
                
                self.trial_ground["promotion_history"].append({
                    "strategy_id": strategy_id,
                    "promoted_at": time.time(),
                    "reason": reason,
                    "promotion_type": "manual_force",
                    "stats_at_promotion": {
                        "success_rate": arm.success_rate,
                        "activations": arm.activation_count
                    }
                })
                
                promotion_result["success"] = True
            else:
                promotion_result["error"] = "è·¯å¾„å·²ç»æ˜¯é»„é‡‘æ¨¡æ¿"
                logger.warning(f"âš ï¸ è·¯å¾„ {strategy_id} å·²ç»æ˜¯é»„é‡‘æ¨¡æ¿ï¼Œæ— éœ€é‡å¤æå‡")
        
        except Exception as e:
            promotion_result["error"] = str(e)
            logger.error(f"âŒ å¼ºåˆ¶æå‡è·¯å¾„ {strategy_id} å¤±è´¥: {e}")
        
        return promotion_result
    
    def revoke_golden_status(self, strategy_id: str, reason: str = "manual_revocation") -> Dict[str, Any]:
        """
        ğŸ”» æ’¤é”€é»„é‡‘æ¨¡æ¿çŠ¶æ€
        
        Args:
            strategy_id: ç­–ç•¥ID
            reason: æ’¤é”€åŸå› 
            
        Returns:
            æ’¤é”€ç»“æœ
        """
        revocation_result = {
            "strategy_id": strategy_id,
            "reason": reason,
            "success": False
        }
        
        try:
            if strategy_id in self.golden_templates:
                self.golden_templates.remove(strategy_id)
                logger.info(f"ğŸ”» è·¯å¾„ {strategy_id} çš„é»„é‡‘æ¨¡æ¿çŠ¶æ€å·²æ’¤é”€: {reason}")
                
                # è®°å½•æ’¤é”€å†å²
                if "revocation_history" not in self.trial_ground:
                    self.trial_ground["revocation_history"] = []
                
                arm = self.path_arms.get(strategy_id)
                self.trial_ground["revocation_history"].append({
                    "strategy_id": strategy_id,
                    "revoked_at": time.time(),
                    "reason": reason,
                    "stats_at_revocation": {
                        "success_rate": arm.success_rate if arm else 0.0,
                        "activations": arm.activation_count if arm else 0
                    }
                })
                
                revocation_result["success"] = True
            else:
                revocation_result["error"] = "è·¯å¾„ä¸æ˜¯é»„é‡‘æ¨¡æ¿"
                logger.warning(f"âš ï¸ è·¯å¾„ {strategy_id} ä¸æ˜¯é»„é‡‘æ¨¡æ¿ï¼Œæ— æ³•æ’¤é”€")
        
        except Exception as e:
            revocation_result["error"] = str(e)
            logger.error(f"âŒ æ’¤é”€è·¯å¾„ {strategy_id} é»„é‡‘çŠ¶æ€å¤±è´¥: {e}")
        
        return revocation_result
    
    def _calculate_path_similarity(self, path1_type: str, path2_type: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªè·¯å¾„ç±»å‹ä¹‹é—´çš„ç›¸ä¼¼åº¦
        
        Args:
            path1_type: ç¬¬ä¸€ä¸ªè·¯å¾„ç±»å‹
            path2_type: ç¬¬äºŒä¸ªè·¯å¾„ç±»å‹
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0.0-1.0)ï¼Œ1.0è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼
        """
        # ç›¸ä¼¼åº¦çŸ©é˜µï¼šå®šä¹‰ä¸åŒè·¯å¾„ç±»å‹ä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦
        similarity_matrix = {
            # ç³»ç»Ÿåˆ†æå‹ç›¸ä¼¼åº¦
            ("ç³»ç»Ÿåˆ†æå‹", "æ•´ä½“ç»¼åˆå‹"): 0.8,
            ("ç³»ç»Ÿåˆ†æå‹", "æ¢ç´¢è°ƒç ”å‹"): 0.6,
            ("ç³»ç»Ÿåˆ†æå‹", "æ‰¹åˆ¤è´¨ç–‘å‹"): 0.5,
            
            # åˆ›æ–°çªç ´å‹ç›¸ä¼¼åº¦
            ("åˆ›æ–°çªç ´å‹", "é€‚åº”çµæ´»å‹"): 0.7,
            ("åˆ›æ–°çªç ´å‹", "æ¢ç´¢è°ƒç ”å‹"): 0.6,
            
            # æ‰¹åˆ¤è´¨ç–‘å‹ç›¸ä¼¼åº¦
            ("æ‰¹åˆ¤è´¨ç–‘å‹", "æ¢ç´¢è°ƒç ”å‹"): 0.5,
            ("æ‰¹åˆ¤è´¨ç–‘å‹", "ç³»ç»Ÿåˆ†æå‹"): 0.5,
            
            # å®ç”¨åŠ¡å®å‹ç›¸ä¼¼åº¦
            ("å®ç”¨åŠ¡å®å‹", "é€‚åº”çµæ´»å‹"): 0.6,
            ("å®ç”¨åŠ¡å®å‹", "ç³»ç»Ÿåˆ†æå‹"): 0.4,
            
            # æ•´ä½“ç»¼åˆå‹ç›¸ä¼¼åº¦
            ("æ•´ä½“ç»¼åˆå‹", "åä½œå’¨è¯¢å‹"): 0.7,
            ("æ•´ä½“ç»¼åˆå‹", "ç³»ç»Ÿåˆ†æå‹"): 0.8,
            
            # æ¢ç´¢è°ƒç ”å‹ç›¸ä¼¼åº¦
            ("æ¢ç´¢è°ƒç ”å‹", "æ‰¹åˆ¤è´¨ç–‘å‹"): 0.5,
            ("æ¢ç´¢è°ƒç ”å‹", "åˆ›æ–°çªç ´å‹"): 0.6,
            
            # åä½œå’¨è¯¢å‹ç›¸ä¼¼åº¦
            ("åä½œå’¨è¯¢å‹", "æ•´ä½“ç»¼åˆå‹"): 0.7,
            ("åä½œå’¨è¯¢å‹", "é€‚åº”çµæ´»å‹"): 0.5,
            
            # é€‚åº”çµæ´»å‹ç›¸ä¼¼åº¦
            ("é€‚åº”çµæ´»å‹", "åˆ›æ–°çªç ´å‹"): 0.7,
            ("é€‚åº”çµæ´»å‹", "å®ç”¨åŠ¡å®å‹"): 0.6,
        }
        
        # ç›¸åŒç±»å‹å®Œå…¨ç›¸ä¼¼
        if path1_type == path2_type:
            return 1.0
        
        # æŸ¥æ‰¾ç›¸ä¼¼åº¦ï¼ˆæ”¯æŒåŒå‘æŸ¥æ‰¾ï¼‰
        key1 = (path1_type, path2_type)
        key2 = (path2_type, path1_type)
        
        similarity = similarity_matrix.get(key1) or similarity_matrix.get(key2)
        
        # å¦‚æœæ²¡æœ‰å®šä¹‰ç›¸ä¼¼åº¦ï¼Œé»˜è®¤ä¸ºä½ç›¸ä¼¼
        return similarity if similarity is not None else 0.3
    
    def select_top_k_paths(self, paths: List[ReasoningPath], k: int = 2, 
                          algorithm: str = 'auto',
                          diversity_threshold: float = 0.7) -> List[ReasoningPath]:
        """
        ğŸ¯ æ–°æ–¹æ¡ˆä¸‰æ ¸å¿ƒæ–¹æ³•ï¼šé€‰æ‹©Top-Kæ¡ä¼˜è´¨ä¸”å¤šæ ·åŒ–çš„è·¯å¾„ï¼ˆåˆ†å±‚è¾“å‡ºç­–ç•¥ï¼‰
        
        æ­¤æ–¹æ³•æ”¯æŒåˆ†å±‚è¾“å‡ºæ¶æ„ï¼š
        - é€‰æ‹©kæ¡æœ€ä¼˜è·¯å¾„
        - ç¡®ä¿è·¯å¾„ä¹‹é—´å…·æœ‰è¶³å¤Ÿçš„å¤šæ ·æ€§
        - æ”¯æŒé»„é‡‘æ¨¡æ¿ä¼˜å…ˆæœºåˆ¶
        
        Args:
            paths: å€™é€‰æ€ç»´è·¯å¾„åˆ—è¡¨
            k: éœ€è¦é€‰æ‹©çš„è·¯å¾„æ•°é‡ï¼ˆé»˜è®¤2æ¡ï¼šä¸»è·¯å¾„+è¡¥å……è·¯å¾„ï¼‰
            algorithm: MABç®—æ³•ç±»å‹ ('thompson_sampling', 'ucb_variant', 'epsilon_greedy', 'auto')
            diversity_threshold: å¤šæ ·æ€§é˜ˆå€¼ï¼Œç›¸ä¼¼åº¦è¶…è¿‡æ­¤å€¼çš„è·¯å¾„ä¼šè¢«è¿‡æ»¤ (0.0-1.0)
            
        Returns:
            é€‰æ‹©çš„kæ¡ä¼˜è´¨è·¯å¾„åˆ—è¡¨ï¼ŒæŒ‰ç½®ä¿¡åº¦é™åºæ’åˆ—
            - ç¬¬ä¸€æ¡ï¼šä¸»è·¯å¾„ï¼ˆæœ€ä¼˜ï¼‰
            - å…¶ä½™ï¼šè¡¥å……è·¯å¾„ï¼ˆæŒ‰è´¨é‡æ’åºï¼‰
        """
        if not paths:
            raise ValueError("è·¯å¾„åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        # å¦‚æœè¯·æ±‚çš„è·¯å¾„æ•°é‡å¤§äºç­‰äºå€™é€‰è·¯å¾„æ•°é‡ï¼Œè¿”å›æ‰€æœ‰è·¯å¾„
        if k >= len(paths):
            logger.info(f"ğŸ¯ è¯·æ±‚{k}æ¡è·¯å¾„ï¼Œä½†åªæœ‰{len(paths)}æ¡å€™é€‰ï¼Œè¿”å›æ‰€æœ‰è·¯å¾„")
            return paths
        
        self.total_path_selections += 1
        logger.info(f"ğŸ¯ å¼€å§‹åˆ†å±‚è·¯å¾„é€‰æ‹©ï¼ˆç¬¬{self.total_path_selections}æ¬¡ï¼‰")
        logger.info(f"   ç›®æ ‡: é€‰æ‹©{k}æ¡å¤šæ ·åŒ–ä¼˜è´¨è·¯å¾„")
        logger.info(f"   å€™é€‰è·¯å¾„: {len(paths)}æ¡")
        logger.info(f"   å¤šæ ·æ€§é˜ˆå€¼: {diversity_threshold}")
        
        # ğŸ† é»„é‡‘æ¨¡æ¿ä¼˜å…ˆæ£€æŸ¥
        golden_match = self._check_golden_template_match(paths)
        selected_paths = []
        
        if golden_match:
            # é»„é‡‘æ¨¡æ¿è·¯å¾„ç›´æ¥ä½œä¸ºä¸»è·¯å¾„
            golden_path = golden_match['path']
            template_id = golden_match['template_id']
            
            selected_paths.append(golden_path)
            
            # æ›´æ–°é»„é‡‘æ¨¡æ¿ç»Ÿè®¡
            self.template_usage_stats[template_id] += 1
            self.template_match_history.append({
                'template_id': template_id,
                'path_id': golden_path.path_id,
                'path_type': golden_path.path_type,
                'match_score': golden_match['match_score'],
                'timestamp': time.time(),
                'selection_round': self.total_path_selections
            })
            
            logger.info(f"ğŸ† é»„é‡‘æ¨¡æ¿ä½œä¸ºä¸»è·¯å¾„: {golden_path.path_type}")
            
            # ä»å€™é€‰ä¸­ç§»é™¤é»„é‡‘è·¯å¾„ï¼Œç»§ç»­é€‰æ‹©è¡¥å……è·¯å¾„
            remaining_paths = [p for p in paths if p.path_id != golden_path.path_id]
        else:
            remaining_paths = paths
        
        # ğŸ”§ å‡†å¤‡MABå†³ç­–è‡‚å’Œè·¯å¾„è¯„åˆ†
        path_scores = []  # (score, path, arm)
        strategy_to_path_mapping = {}
        
        for path in remaining_paths:
            strategy_id = path.strategy_id
            strategy_to_path_mapping[strategy_id] = path
            
            # åˆ›å»ºæˆ–è·å–å†³ç­–è‡‚
            arm = self._create_strategy_arm_if_missing(strategy_id, path.path_type)
            
            # ä½¿ç”¨MABç®—æ³•è®¡ç®—è·¯å¾„è¯„åˆ†
            if algorithm == 'auto':
                algorithm = self._select_best_algorithm_for_paths()
            
            try:
                # è®¡ç®—è·¯å¾„å¾—åˆ†ï¼ˆä½¿ç”¨å„è‡ªçš„MABç®—æ³•ï¼‰
                if algorithm == 'thompson_sampling':
                    score = self._calculate_thompson_score(arm)
                elif algorithm == 'ucb_variant':
                    score = self._calculate_ucb_score(arm)
                elif algorithm == 'epsilon_greedy':
                    score = self._calculate_epsilon_greedy_score(arm)
                else:
                    score = self._calculate_thompson_score(arm)
                
                path_scores.append((score, path, arm))
                
            except Exception as e:
                logger.warning(f"âš ï¸ è®¡ç®—è·¯å¾„ {path.path_type} è¯„åˆ†å¤±è´¥: {e}")
                # ä½¿ç”¨é»˜è®¤åˆ†æ•°
                path_scores.append((0.5, path, arm))
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        path_scores.sort(reverse=True, key=lambda x: x[0])
        
        logger.info(f"ğŸ“Š è·¯å¾„è¯„åˆ†å®Œæˆï¼Œæ’åºç»“æœ:")
        for i, (score, path, _) in enumerate(path_scores[:5], 1):  # åªæ˜¾ç¤ºå‰5å
            logger.info(f"   {i}. {path.path_type}: {score:.3f}")
        
        # ğŸ¨ å¤šæ ·æ€§è¿‡æ»¤ï¼šé€‰æ‹©å¤šæ ·åŒ–çš„Top-Kè·¯å¾„
        for score, path, arm in path_scores:
            if len(selected_paths) >= k:
                break
            
            # æ£€æŸ¥ä¸å·²é€‰è·¯å¾„çš„ç›¸ä¼¼åº¦
            is_diverse = True
            for selected_path in selected_paths:
                similarity = self._calculate_path_similarity(
                    path.path_type, 
                    selected_path.path_type
                )
                
                if similarity >= diversity_threshold:
                    is_diverse = False
                    logger.debug(f"   ğŸ”„ è·¯å¾„ {path.path_type} ä¸ {selected_path.path_type} ç›¸ä¼¼åº¦è¿‡é«˜({similarity:.2f})ï¼Œè·³è¿‡")
                    break
            
            if is_diverse or len(selected_paths) == 0:
                selected_paths.append(path)
                
                # æ›´æ–°å†³ç­–è‡‚ç»Ÿè®¡
                arm.last_used = time.time()
                arm.activation_count += 1
                self._update_exploration_boost(arm.path_id)
                
                logger.info(f"âœ… é€‰ä¸­è·¯å¾„ {len(selected_paths)}/{k}: {path.path_type} (è¯„åˆ†: {score:.3f})")
        
        # å¦‚æœå¤šæ ·æ€§è¿‡æ»¤åè·¯å¾„ä¸è¶³kæ¡ï¼Œè¡¥å……åˆ†æ•°è¾ƒé«˜çš„è·¯å¾„
        if len(selected_paths) < k:
            logger.info(f"âš ï¸ å¤šæ ·æ€§è¿‡æ»¤åä»…{len(selected_paths)}æ¡è·¯å¾„ï¼Œæ”¾å®½æ ‡å‡†è¡¥å……è·¯å¾„")
            for score, path, arm in path_scores:
                if len(selected_paths) >= k:
                    break
                if path not in selected_paths:
                    selected_paths.append(path)
                    arm.last_used = time.time()
                    arm.activation_count += 1
                    logger.info(f"   è¡¥å……è·¯å¾„: {path.path_type} (è¯„åˆ†: {score:.3f})")
        
        # è®°å½•é€‰æ‹©å†å²
        for i, path in enumerate(selected_paths):
            self.path_selection_history.append({
                'path_id': path.strategy_id,
                'path_type': path.path_type,
                'algorithm': algorithm,
                'rank': i + 1,  # 1=ä¸»è·¯å¾„, 2+=è¡¥å……è·¯å¾„
                'is_primary': (i == 0),
                'timestamp': time.time(),
                'selection_round': self.total_path_selections
            })
        
        logger.info(f"ğŸ¯ åˆ†å±‚è·¯å¾„é€‰æ‹©å®Œæˆ:")
        logger.info(f"   ä¸»è·¯å¾„: {selected_paths[0].path_type}")
        if len(selected_paths) > 1:
            supplementary_types = [p.path_type for p in selected_paths[1:]]
            logger.info(f"   è¡¥å……è·¯å¾„: {', '.join(supplementary_types)}")
        
        return selected_paths
    
    def _calculate_thompson_score(self, arm) -> float:
        """è®¡ç®—Thompsoné‡‡æ ·å¾—åˆ†"""
        alpha = arm.success_count + 1
        beta = arm.failure_count + 1
        return np.random.beta(alpha, beta)
    
    def _calculate_ucb_score(self, arm) -> float:
        """è®¡ç®—UCBå¾—åˆ†"""
        if arm.trials == 0:
            return float('inf')
        
        mean_reward = arm.total_reward / arm.trials
        exploration_bonus = np.sqrt(2 * np.log(self.total_path_selections) / arm.trials)
        return mean_reward + exploration_bonus
    
    def _calculate_epsilon_greedy_score(self, arm) -> float:
        """è®¡ç®—Îµ-è´ªå¿ƒå¾—åˆ†"""
        if arm.trials == 0:
            return np.random.random()
        
        epsilon = max(0.1, 1.0 / np.sqrt(self.total_path_selections))
        if np.random.random() < epsilon:
            return np.random.random()
        else:
            return arm.total_reward / arm.trials
    
    def select_best_path(self, paths: List[ReasoningPath], algorithm: str = 'auto') -> ReasoningPath:
        """
        ğŸ”„ å‘åå…¼å®¹æ–¹æ³•ï¼šé€‰æ‹©å•ä¸€æœ€ä¼˜è·¯å¾„
        
        âš ï¸ å·²å¼ƒç”¨ï¼šæ­¤æ–¹æ³•ä¿ç•™ä»…ç”¨äºå‘åå…¼å®¹
        æ¨èä½¿ç”¨: select_top_k_paths() æ–¹æ³•ä»¥è·å¾—åˆ†å±‚è¾“å‡ºèƒ½åŠ›
        
        Args:
            paths: æ€ç»´è·¯å¾„åˆ—è¡¨
            algorithm: ä½¿ç”¨çš„ç®—æ³• ('thompson_sampling', 'ucb_variant', 'epsilon_greedy', 'auto')
            
        Returns:
            é€‰æ‹©çš„æœ€ä¼˜æ€ç»´è·¯å¾„ï¼ˆä»…è¿”å›ç¬¬ä¸€æ¡ï¼‰
        """
        logger.debug("âš ï¸ è°ƒç”¨å·²å¼ƒç”¨çš„ select_best_path æ–¹æ³•ï¼Œå»ºè®®ä½¿ç”¨ select_top_k_paths")
        
        # è°ƒç”¨æ–°çš„åˆ†å±‚é€‰æ‹©æ–¹æ³•ï¼Œåªè¿”å›ç¬¬ä¸€æ¡ï¼ˆä¸»è·¯å¾„ï¼‰
        selected_paths = self.select_top_k_paths(paths, k=1, algorithm=algorithm)
        return selected_paths[0]
    
    def select_best_tool(self, available_tools: List[str], algorithm: str = 'auto') -> str:
        """
        ğŸ”§ æ–°å¢ï¼šä»å¯ç”¨å·¥å…·åˆ—è¡¨ä¸­é€‰æ‹©æœ€ä¼˜å·¥å…·
        
        Args:
            available_tools: å¯ç”¨å·¥å…·åç§°åˆ—è¡¨
            algorithm: ä½¿ç”¨çš„ç®—æ³• ('thompson_sampling', 'ucb_variant', 'epsilon_greedy', 'auto')
            
        Returns:
            é€‰æ‹©çš„æœ€ä¼˜å·¥å…·åç§°
        """
        if not available_tools:
            raise ValueError("å·¥å…·åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        if len(available_tools) == 1:
            logger.info(f"ğŸ”§ åªæœ‰ä¸€ä¸ªå·¥å…·ï¼Œç›´æ¥é€‰æ‹©: {available_tools[0]}")
            return available_tools[0]
        
        self.total_tool_selections += 1
        logger.info(f"ğŸ”§ å¼€å§‹ç¬¬ {self.total_tool_selections} æ¬¡å·¥å…·é€‰æ‹©ï¼Œå€™é€‰å·¥å…·: {len(available_tools)}ä¸ª")
        
        # ğŸ”§ åŠ¨æ€åˆ›å»ºï¼šç¡®ä¿æ‰€æœ‰å·¥å…·çš„å†³ç­–è‡‚éƒ½å­˜åœ¨
        available_arms = []
        tool_to_arm_mapping = {}  # å·¥å…·åç§°åˆ°å†³ç­–è‡‚çš„æ˜ å°„
        
        for tool_name in available_tools:
            tool_id = tool_name  # ä½¿ç”¨å·¥å…·åç§°ä½œä¸ºID
            tool_to_arm_mapping[tool_name] = tool_id
            
            # ğŸ”§ åŠ¨æ€åˆ›å»ºï¼šç¡®ä¿å·¥å…·å†³ç­–è‡‚å­˜åœ¨
            arm = self._create_tool_arm_if_missing(tool_id, tool_name)
            available_arms.append(arm)
            
            logger.debug(f"âœ… å·¥å…·å†³ç­–è‡‚å°±ç»ª: {tool_id} ({tool_name})")
        
        # è‡ªåŠ¨é€‰æ‹©ç®—æ³•
        if algorithm == 'auto':
            algorithm = self._select_best_algorithm_for_tools()
        
        # æ ¹æ®é€‰æ‹©çš„ç®—æ³•è¿›è¡Œå†³ç­–
        try:
            if algorithm == 'thompson_sampling':
                best_arm = self._thompson_sampling_for_tools(available_arms)
            elif algorithm == 'ucb_variant':
                best_arm = self._ucb_variant_for_tools(available_arms)
            elif algorithm == 'epsilon_greedy':
                best_arm = self._epsilon_greedy_for_tools(available_arms)
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥ç®—æ³• {algorithm}ï¼Œä½¿ç”¨Thompsoné‡‡æ ·")
                best_arm = self._thompson_sampling_for_tools(available_arms)
            
            # æ›´æ–°ä½¿ç”¨æ—¶é—´å’Œæ¿€æ´»æ¬¡æ•°
            best_arm.last_used = time.time()
            best_arm.activation_count += 1
            
            # ğŸ¯ æ‰¾åˆ°å¯¹åº”çš„å·¥å…·åç§°
            selected_tool = best_arm.option  # å·¥å…·åç§°å­˜å‚¨åœ¨optionå­—æ®µä¸­
            
            # è®°å½•é€‰æ‹©å†å²
            self.tool_selection_history.append({
                'tool_id': best_arm.path_id,
                'tool_name': selected_tool,
                'algorithm': algorithm,
                'timestamp': time.time(),
                'selection_round': self.total_tool_selections
            })
            
            logger.info(f"ğŸ”§ ä½¿ç”¨ {algorithm} é€‰æ‹©å·¥å…·: {selected_tool} (ID: {best_arm.path_id})")
            return selected_tool
            
        except Exception as e:
            logger.error(f"âŒ MABå·¥å…·é€‰æ‹©ç®—æ³•æ‰§è¡Œå¤±è´¥: {e}")
            # å›é€€åˆ°éšæœºé€‰æ‹©
            selected_tool = np.random.choice(available_tools)
            logger.info(f"ğŸ”„ å›é€€åˆ°éšæœºé€‰æ‹©å·¥å…·: {selected_tool}")
            return selected_tool
    
    def is_tool_cold(self, tool_name: str) -> Dict[str, any]:
        """
        ğŸ” åˆ¤æ–­å·¥å…·æ˜¯å¦å¤„äºå†·å¯åŠ¨çŠ¶æ€
        
        è¿™ä¸ªæ–¹æ³•æ˜¯MABConvergerçš„"è‡ªæˆ‘è®¤çŸ¥"èƒ½åŠ›ï¼Œå½“MainControllerè¯¢é—®æ—¶ï¼Œ
        å®ƒèƒ½æ˜ç¡®å›ç­”ï¼š"æˆ‘æ¨èçš„è¿™ä¸ªå·¥å…·ï¼Œæˆ‘è‡ªå·±ç†Ÿä¸ç†Ÿï¼Ÿ"
        
        Args:
            tool_name: å·¥å…·åç§°
            
        Returns:
            DictåŒ…å«è¯¦ç»†çš„å†·å¯åŠ¨åˆ†æç»“æœ:
            {
                'is_cold_start': bool,      # æ˜¯å¦å¤„äºå†·å¯åŠ¨çŠ¶æ€
                'cold_score': float,        # å†·å¯åŠ¨å¾—åˆ† (0-1, è¶Šé«˜è¶Š"å†·")
                'confidence': float,        # ç»éªŒå¯ä¿¡åº¦ (0-1, è¶Šé«˜è¶Šå¯ä¿¡)
                'analysis': {
                    'usage_count': int,     # ä½¿ç”¨æ¬¡æ•°
                    'reliability_score': float,  # å¯é æ€§åˆ†æ•°
                    'idle_hours': float,    # ç©ºé—²æ—¶é—´(å°æ—¶)
                    'sample_size': int      # æ ·æœ¬æ•°é‡
                },
                'recommendation': str,      # æ¨èæ¨¡å¼ ('experience'/'exploration')
                'reason': str              # åˆ¤æ–­ç†ç”±
            }
        """
        logger.debug(f"ğŸ” å¼€å§‹å†·å¯åŠ¨æ£€æµ‹: å·¥å…· '{tool_name}'")
        
        # è·å–å†·å¯åŠ¨é…ç½®
        cold_start_config = MAB_CONFIG["cold_start_threshold"]
        detection_weights = cold_start_config["detection_weights"]
        
        # è·å–å·¥å…·çš„å†³ç­–è‡‚
        tool_arm = self.tool_arms.get(tool_name)
        
        if not tool_arm:
            # å®Œå…¨æœªä½¿ç”¨çš„å·¥å…· - ç»å¯¹å†·å¯åŠ¨
            logger.debug(f"ğŸ†• å·¥å…· '{tool_name}' ä»æœªä½¿ç”¨è¿‡ï¼Œåˆ¤å®šä¸ºå†·å¯åŠ¨")
            return {
                'is_cold_start': True,
                'cold_score': 1.0,
                'confidence': 0.0,
                'analysis': {
                    'usage_count': 0,
                    'reliability_score': 0.0,
                    'idle_hours': float('inf'),
                    'sample_size': 0
                },
                'recommendation': 'exploration',
                'reason': 'å·¥å…·ä»æœªè¢«ä½¿ç”¨è¿‡ï¼Œæ— ä»»ä½•ç»éªŒæ•°æ®'
            }
        
        # è®¡ç®—å„ä¸ªå†·å¯åŠ¨å› å­
        analysis = self._calculate_cold_start_factors(tool_arm, cold_start_config)
        
        # è®¡ç®—åŠ æƒå†·å¯åŠ¨å¾—åˆ†
        cold_score = (
            analysis['usage_factor'] * detection_weights['usage_frequency'] +
            analysis['reliability_factor'] * detection_weights['reliability'] +
            analysis['recency_factor'] * detection_weights['recency'] +
            analysis['sample_factor'] * detection_weights['sample_sufficiency']
        )
        
        # åˆ¤å®šæ˜¯å¦å†·å¯åŠ¨
        exploration_threshold = cold_start_config["exploration_trigger_threshold"]
        is_cold = cold_score > exploration_threshold
        
        # ç”Ÿæˆåˆ¤æ–­ç†ç”±
        reason = self._generate_cold_start_reason(analysis, cold_score, exploration_threshold)
        
        result = {
            'is_cold_start': is_cold,
            'cold_score': round(cold_score, 3),
            'confidence': round(1.0 - cold_score, 3),
            'analysis': {
                'usage_count': analysis['usage_count'],
                'reliability_score': round(analysis['reliability_score'], 3),
                'idle_hours': round(analysis['idle_hours'], 2),
                'sample_size': analysis['sample_size']
            },
            'recommendation': 'exploration' if is_cold else 'experience',
            'reason': reason
        }
        
        logger.info(f"ğŸ” å†·å¯åŠ¨æ£€æµ‹å®Œæˆ: {tool_name} -> "
                   f"{'å†·å¯åŠ¨' if is_cold else 'ç»éªŒä¸°å¯Œ'} "
                   f"(å¾—åˆ†: {cold_score:.3f}, ç½®ä¿¡åº¦: {result['confidence']:.3f})")
        
        return result
    
    def _calculate_cold_start_factors(self, tool_arm: EnhancedDecisionArm, 
                                    cold_start_config: Dict[str, any]) -> Dict[str, any]:
        """
        è®¡ç®—å†·å¯åŠ¨å„ä¸ªå› å­
        
        Args:
            tool_arm: å·¥å…·å†³ç­–è‡‚
            cold_start_config: å†·å¯åŠ¨é…ç½®
            
        Returns:
            åŒ…å«å„ä¸ªå› å­çš„åˆ†æç»“æœ
        """
        current_time = time.time()
        
        # 1. ä½¿ç”¨é¢‘ç‡å› å­ (ä½¿ç”¨æ¬¡æ•°è¶Šå°‘ï¼Œåˆ†æ•°è¶Šé«˜)
        usage_count = tool_arm.activation_count
        min_usage = cold_start_config["min_usage_count"]
        usage_factor = max(0.0, 1.0 - usage_count / max(min_usage, 1))
        
        # 2. å¯é æ€§å› å­ (æˆåŠŸç‡ä¸ç¨³å®šæˆ–æ ·æœ¬å°‘æ—¶åˆ†æ•°é«˜)
        total_samples = tool_arm.success_count + tool_arm.failure_count
        if total_samples >= 3:
            reliability_score = tool_arm.success_rate
            # æ ·æœ¬æ•°è°ƒæ•´ï¼šæ ·æœ¬è¶Šå°‘ï¼Œå¯é æ€§è¶Šä½
            sample_adjustment = min(1.0, total_samples / 10.0)  # 10ä¸ªæ ·æœ¬è§†ä¸ºå……è¶³
            adjusted_reliability = reliability_score * sample_adjustment
        else:
            adjusted_reliability = 0.0  # æ ·æœ¬å¤ªå°‘ï¼Œä¸å¯é 
        
        min_reliability = cold_start_config["min_reliability_score"]
        reliability_factor = max(0.0, 1.0 - adjusted_reliability / max(min_reliability, 0.1))
        
        # 3. æœ€è¿‘ä½¿ç”¨å› å­ (æ—¶é—´è¶Šä¹…ï¼Œåˆ†æ•°è¶Šé«˜)
        if tool_arm.last_used > 0:
            idle_hours = (current_time - tool_arm.last_used) / 3600
        else:
            idle_hours = float('inf')
        
        max_idle = cold_start_config["max_idle_hours"]
        recency_factor = min(1.0, idle_hours / max(max_idle, 1))
        
        # 4. æ ·æœ¬å……è¶³æ€§å› å­ (æ ·æœ¬è¶Šå°‘ï¼Œåˆ†æ•°è¶Šé«˜)
        min_samples = cold_start_config["min_sample_size"]
        sample_factor = max(0.0, 1.0 - total_samples / max(min_samples, 1))
        
        return {
            'usage_count': usage_count,
            'usage_factor': usage_factor,
            'reliability_score': adjusted_reliability,
            'reliability_factor': reliability_factor,
            'idle_hours': idle_hours if idle_hours != float('inf') else -1,
            'recency_factor': recency_factor,
            'sample_size': total_samples,
            'sample_factor': sample_factor
        }
    
    def _generate_cold_start_reason(self, analysis: Dict[str, any], 
                                   cold_score: float, threshold: float) -> str:
        """
        ç”Ÿæˆå†·å¯åŠ¨åˆ¤æ–­çš„è¯¦ç»†ç†ç”±
        
        Args:
            analysis: åˆ†æç»“æœ
            cold_score: å†·å¯åŠ¨å¾—åˆ†
            threshold: åˆ¤å®šé˜ˆå€¼
            
        Returns:
            åˆ¤æ–­ç†ç”±å­—ç¬¦ä¸²
        """
        reasons = []
        
        # ä½¿ç”¨é¢‘ç‡åˆ†æ
        if analysis['usage_factor'] > 0.7:
            reasons.append(f"ä½¿ç”¨æ¬¡æ•°è¿‡å°‘({analysis['usage_count']}æ¬¡)")
        elif analysis['usage_factor'] > 0.3:
            reasons.append(f"ä½¿ç”¨ç»éªŒæœ‰é™({analysis['usage_count']}æ¬¡)")
        
        # å¯é æ€§åˆ†æ
        if analysis['reliability_factor'] > 0.6:
            reasons.append(f"æ€§èƒ½æ•°æ®ä¸å¯é (å¯é æ€§:{analysis['reliability_score']:.2f})")
        elif analysis['reliability_factor'] > 0.3:
            reasons.append(f"æ€§èƒ½æ•°æ®ä¸å¤Ÿç¨³å®š")
        
        # æœ€è¿‘ä½¿ç”¨åˆ†æ
        if analysis['idle_hours'] > 72:
            reasons.append(f"é•¿æ—¶é—´æœªä½¿ç”¨({analysis['idle_hours']:.1f}å°æ—¶)")
        elif analysis['idle_hours'] > 24:
            reasons.append(f"è¾ƒé•¿æ—¶é—´æœªä½¿ç”¨")
        
        # æ ·æœ¬æ•°åˆ†æ
        if analysis['sample_factor'] > 0.7:
            reasons.append(f"æ ·æœ¬æ•°æ®ä¸è¶³({analysis['sample_size']}ä¸ª)")
        
        if not reasons:
            if cold_score > threshold:
                reasons.append("ç»¼åˆè¯„ä¼°æ˜¾ç¤ºç¼ºä¹è¶³å¤Ÿç»éªŒ")
            else:
                reasons.append("å…·æœ‰å……è¶³çš„ä½¿ç”¨ç»éªŒå’Œå¯é æ•°æ®")
        
        # ç»„åˆç†ç”±
        if cold_score > threshold:
            return f"å†·å¯åŠ¨çŠ¶æ€: {'; '.join(reasons)} (å¾—åˆ†:{cold_score:.3f} > {threshold})"
        else:
            return f"ç»éªŒä¸°å¯Œ: {'; '.join(reasons)} (å¾—åˆ†:{cold_score:.3f} â‰¤ {threshold})"
    
    def _thompson_sampling_for_paths(self, arms: List[EnhancedDecisionArm]) -> EnhancedDecisionArm:
        """é’ˆå¯¹æ€ç»´è·¯å¾„çš„Thompsoné‡‡æ ·ç®—æ³• - ğŸŒŸ å¢å¼ºç‰ˆï¼šæ”¯æŒæ¢ç´¢å¢å¼º"""
        if not arms:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„è·¯å¾„å†³ç­–è‡‚")
        
        best_arm = None
        best_score = -1
        
        logger.debug(f"ğŸ² Thompsoné‡‡æ ·è·¯å¾„é€‰æ‹©ï¼Œå€™é€‰è·¯å¾„: {len(arms)}ä¸ª")
        
        for arm in arms:
            # ä½¿ç”¨Betaåˆ†å¸ƒè¿›è¡ŒThompsoné‡‡æ ·
            alpha = arm.success_count + 1
            beta = arm.failure_count + 1
            
            # ä»Betaåˆ†å¸ƒä¸­é‡‡æ ·
            sampled_value = np.random.beta(alpha, beta)
            
            # è·¯å¾„çº§åˆ«çš„å¥–åŠ±è€ƒè™‘
            if arm.rl_reward_history:
                avg_reward = sum(arm.rl_reward_history) / len(arm.rl_reward_history)
                # å°†å¥–åŠ±è°ƒæ•´åˆ°0-1èŒƒå›´
                normalized_reward = max(0, min(1, (avg_reward + 1) / 2))
                sampled_value = sampled_value * 0.8 + normalized_reward * 0.2
            
            # ğŸŒŸ æ¢ç´¢å¢å¼ºï¼šä¸ºæ–°å­¦ä¹ è·¯å¾„æä¾›é¢å¤–æœºä¼š
            exploration_boost = self.get_exploration_boost(arm.path_id)
            if exploration_boost > 1.0:
                sampled_value *= exploration_boost
                logger.debug(f"   ğŸš€ è·¯å¾„ {arm.path_id} è·å¾—æ¢ç´¢å¢å¼º: {exploration_boost:.3f}x")
            
            # è·¯å¾„å¤šæ ·æ€§è€ƒè™‘ï¼šå‡å°‘è¿‡åº¦ä¾èµ–å•ä¸€è·¯å¾„
            usage_penalty = min(0.1, arm.activation_count / (self.total_path_selections + 1) * 0.2)
            sampled_value = max(0, sampled_value - usage_penalty)
            
            logger.debug(f"   è·¯å¾„ {arm.path_id}: sampled={sampled_value:.3f}, Î±={alpha}, Î²={beta}, boost={exploration_boost:.3f}")
            
            if sampled_value > best_score:
                best_score = sampled_value
                best_arm = arm
        
        logger.debug(f"ğŸ† Thompsoné‡‡æ ·é€‰æ‹©: {best_arm.path_id} (å¾—åˆ†: {best_score:.3f})")
        return best_arm
    
    def _ucb_variant_for_paths(self, arms: List[EnhancedDecisionArm]) -> EnhancedDecisionArm:
        """é’ˆå¯¹æ€ç»´è·¯å¾„çš„UCB (Upper Confidence Bound) å˜ç§ç®—æ³• - ğŸŒŸ å¢å¼ºç‰ˆï¼šæ”¯æŒæ¢ç´¢å¢å¼º"""
        if not arms:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„è·¯å¾„å†³ç­–è‡‚")
        
        total_rounds = sum(arm.activation_count for arm in arms)
        if total_rounds == 0:
            # ç¬¬ä¸€è½®éšæœºé€‰æ‹©
            selected_arm = np.random.choice(arms)
            logger.debug(f"ğŸ² UCBé¦–è½®éšæœºé€‰æ‹©è·¯å¾„: {selected_arm.path_id}")
            return selected_arm
        
        best_arm = None
        best_ucb_value = -float('inf')
        
        logger.debug(f"ğŸ“Š UCBè·¯å¾„é€‰æ‹©ï¼Œæ€»è½®æ•°: {total_rounds}")
        
        for arm in arms:
            if arm.activation_count == 0:
                # æœªå°è¯•è¿‡çš„è·¯å¾„ä¼˜å…ˆé€‰æ‹©ï¼Œå­¦ä¹ è·¯å¾„äº«æœ‰æ›´é«˜ä¼˜å…ˆçº§
                exploration_boost = self.get_exploration_boost(arm.path_id)
                if exploration_boost > 1.0:
                    logger.debug(f"ğŸ†•ğŸš€ ä¼˜å…ˆé€‰æ‹©æœªä½¿ç”¨çš„å­¦ä¹ è·¯å¾„: {arm.path_id} (å¢å¼º: {exploration_boost:.3f}x)")
                else:
                    logger.debug(f"ğŸ†• ä¼˜å…ˆé€‰æ‹©æœªä½¿ç”¨è·¯å¾„: {arm.path_id}")
                return arm
            
            # è®¡ç®—UCBå€¼
            confidence_bound = np.sqrt(2 * np.log(total_rounds) / arm.activation_count)
            
            # åŸºç¡€æˆåŠŸç‡
            base_value = arm.success_rate
            
            # è·¯å¾„çº§åˆ«çš„RLå¥–åŠ±è€ƒè™‘
            if arm.rl_reward_history:
                avg_reward = sum(arm.rl_reward_history) / len(arm.rl_reward_history)
                normalized_reward = max(0, min(1, (avg_reward + 1) / 2))
                base_value = base_value * 0.7 + normalized_reward * 0.3
            
            # ğŸŒŸ æ¢ç´¢å¢å¼ºï¼šä¸ºæ–°å­¦ä¹ è·¯å¾„æä¾›é¢å¤–UCBå¥–åŠ±
            exploration_boost = self.get_exploration_boost(arm.path_id)
            if exploration_boost > 1.0:
                base_value *= exploration_boost
                logger.debug(f"   ğŸš€ è·¯å¾„ {arm.path_id} è·å¾—UCBæ¢ç´¢å¢å¼º: {exploration_boost:.3f}x")
            
            # è·¯å¾„æ¢ç´¢å¥–åŠ±ï¼šé¼“åŠ±å°è¯•ä¸åŒæ€ç»´æ–¹å¼
            exploration_bonus = confidence_bound * 1.2  # å¢å¼ºæ¢ç´¢
            ucb_value = base_value + exploration_bonus
            
            logger.debug(f"   è·¯å¾„ {arm.path_id}: UCB={ucb_value:.3f}, base={base_value:.3f}, conf={confidence_bound:.3f}, boost={exploration_boost:.3f}")
            
            if ucb_value > best_ucb_value:
                best_ucb_value = ucb_value
                best_arm = arm
        
        logger.debug(f"ğŸ† UCBé€‰æ‹©è·¯å¾„: {best_arm.path_id} (UCBå€¼: {best_ucb_value:.3f})")
        return best_arm
    
    def _epsilon_greedy_for_paths(self, arms: List[EnhancedDecisionArm]) -> EnhancedDecisionArm:
        """é’ˆå¯¹æ€ç»´è·¯å¾„çš„Epsilon-Greedyç®—æ³• - ğŸŒŸ å¢å¼ºç‰ˆï¼šæ”¯æŒæ¢ç´¢å¢å¼º"""
        if not arms:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„è·¯å¾„å†³ç­–è‡‚")
        
        # è·¯å¾„çº§åˆ«çš„åŠ¨æ€epsilonå€¼ï¼Œé¼“åŠ±æ€ç»´å¤šæ ·æ€§
        total_activations = sum(arm.activation_count for arm in arms)
        epsilon = max(0.1, 0.4 / (1 + total_activations * 0.008))  # æ¯”ä¼ ç»Ÿæ›´é«˜çš„æ¢ç´¢ç‡
        
        # ğŸŒŸ å­¦ä¹ è·¯å¾„å¢å¼ºï¼šå¦‚æœæœ‰å­¦ä¹ è·¯å¾„ï¼Œé€‚å½“æé«˜æ¢ç´¢ç‡
        has_boosted_paths = any(self.get_exploration_boost(arm.path_id) > 1.0 for arm in arms)
        if has_boosted_paths:
            epsilon = min(0.6, epsilon * 1.3)  # å¢å¼ºæ¢ç´¢ï¼Œç»™å­¦ä¹ è·¯å¾„æ›´å¤šæœºä¼š
        
        logger.debug(f"ğŸ¯ Epsilon-Greedyè·¯å¾„é€‰æ‹©ï¼ŒÎµ={epsilon:.3f} {'(å­¦ä¹ å¢å¼º)' if has_boosted_paths else ''}")
        
        # ä½¿ç”¨epsilonå†³å®šæ˜¯å¦æ¢ç´¢
        if np.random.random() < epsilon:
            # ğŸŒŸ æ™ºèƒ½æ¢ç´¢ï¼šä¼˜å…ˆé€‰æ‹©æœ‰æ¢ç´¢å¢å¼ºçš„è·¯å¾„
            boosted_arms = [arm for arm in arms if self.get_exploration_boost(arm.path_id) > 1.0]
            if boosted_arms and np.random.random() < 0.7:  # 70%æ¦‚ç‡é€‰æ‹©å¢å¼ºè·¯å¾„
                selected_arm = np.random.choice(boosted_arms)
                boost = self.get_exploration_boost(selected_arm.path_id)
                logger.debug(f"ğŸ”ğŸš€ æ™ºèƒ½æ¢ç´¢é€‰æ‹©å¢å¼ºè·¯å¾„: {selected_arm.path_id} (å¢å¼º: {boost:.3f}x)")
            else:
                # å¸¸è§„éšæœºæ¢ç´¢
                selected_arm = np.random.choice(arms)
                logger.debug(f"ğŸ” æ¢ç´¢æ¨¡å¼é€‰æ‹©è·¯å¾„: {selected_arm.path_id}")
            return selected_arm
        else:
            # åˆ©ç”¨ï¼šé€‰æ‹©å½“å‰æœ€å¥½çš„è·¯å¾„
            best_arm = None
            best_score = -float('inf')
            
            for arm in arms:
                # è·¯å¾„çº§åˆ«çš„ç»¼åˆè¯„åˆ†
                score = arm.success_rate
                
                # RLå¥–åŠ±æƒé‡
                if arm.rl_reward_history:
                    avg_reward = sum(arm.rl_reward_history) / len(arm.rl_reward_history)
                    normalized_reward = max(0, min(1, (avg_reward + 1) / 2))
                    score = score * 0.6 + normalized_reward * 0.4
                
                # ğŸŒŸ æ¢ç´¢å¢å¼ºï¼šå³ä½¿åœ¨åˆ©ç”¨æ¨¡å¼ä¸‹ï¼Œä¹Ÿç»™äºˆå­¦ä¹ è·¯å¾„ä¸€å®šä¼˜åŠ¿
                exploration_boost = self.get_exploration_boost(arm.path_id)
                if exploration_boost > 1.0:
                    # åœ¨åˆ©ç”¨æ¨¡å¼ä¸‹ç»™å­¦ä¹ è·¯å¾„ä¸€ä¸ªå°çš„é¢å¤–åˆ†æ•°
                    score += (exploration_boost - 1.0) * 0.1  # è½»å¾®å¢å¼ºï¼Œé¿å…è¿‡åº¦åå‘
                    logger.debug(f"   ğŸš€ è·¯å¾„ {arm.path_id} è·å¾—åˆ©ç”¨æ¨¡å¼å¢å¼º: +{(exploration_boost - 1.0) * 0.1:.3f}")
                
                # è·¯å¾„ä½¿ç”¨é¢‘ç‡å¹³è¡¡ï¼šé¿å…è¿‡åº¦ä¾èµ–å•ä¸€æ€ç»´æ¨¡å¼
                usage_ratio = arm.activation_count / (total_activations + 1)
                if usage_ratio > 0.5:  # å¦‚æœæŸè·¯å¾„ä½¿ç”¨è¿‡äºé¢‘ç¹ï¼Œç¨å¾®é™ä½è¯„åˆ†
                    score *= 0.95
                
                logger.debug(f"   è·¯å¾„ {arm.path_id}: score={score:.3f}, usage_ratio={usage_ratio:.3f}, boost={exploration_boost:.3f}")
                
                if score > best_score:
                    best_score = score
                    best_arm = arm
            
            logger.debug(f"ğŸ† åˆ©ç”¨æ¨¡å¼é€‰æ‹©è·¯å¾„: {best_arm.path_id} (å¾—åˆ†: {best_score:.3f})")
            return best_arm if best_arm else arms[0]
    
    def _select_best_algorithm_for_paths(self) -> str:
        """
        ä¸ºè·¯å¾„é€‰æ‹©é€‰æ‹©æœ€ä½³ç®—æ³•
        
        Returns:
            æœ€ä½³ç®—æ³•åç§°
        """
        # å¦‚æœæ ·æœ¬å¤ªå°‘ï¼Œä½¿ç”¨Thompsoné‡‡æ ·è¿›è¡Œæ¢ç´¢
        if self.total_path_selections < 15:
            logger.debug("ğŸ“Š æ ·æœ¬è¾ƒå°‘ï¼Œé€‰æ‹©Thompsoné‡‡æ ·")
            return 'thompson_sampling'
        
        # è®¡ç®—è·¯å¾„çº§åˆ«çš„æ”¶æ•›æ°´å¹³
        if not self.path_arms:
            return 'thompson_sampling'
        
        arms_list = list(self.path_arms.values())
        convergence_level = self._calculate_path_convergence_level(arms_list)
        
        # è€ƒè™‘æ€ç»´å¤šæ ·æ€§ï¼šè·¯å¾„é€‰æ‹©éœ€è¦æ›´å¤šæ¢ç´¢
        if convergence_level < 0.4:
            # ä½æ”¶æ•›ï¼Œä½¿ç”¨æ¢ç´¢æ€§å¼ºçš„ç®—æ³•
            logger.debug(f"ğŸ“Š ä½æ”¶æ•›({convergence_level:.3f})ï¼Œé€‰æ‹©Thompsoné‡‡æ ·")
            return 'thompson_sampling'
        elif convergence_level < 0.7:
            # ä¸­ç­‰æ”¶æ•›ï¼Œä½¿ç”¨å¹³è¡¡çš„ç®—æ³•
            logger.debug(f"ğŸ“Š ä¸­ç­‰æ”¶æ•›({convergence_level:.3f})ï¼Œé€‰æ‹©UCB")
            return 'ucb_variant'
        else:
            # é«˜æ”¶æ•›ï¼Œä½†ä»éœ€ä¿æŒä¸€å®šæ¢ç´¢ï¼ˆæ€ç»´å¤šæ ·æ€§é‡è¦ï¼‰
            logger.debug(f"ğŸ“Š é«˜æ”¶æ•›({convergence_level:.3f})ï¼Œé€‰æ‹©Epsilon-Greedy")
            return 'epsilon_greedy'
    
    def _calculate_path_convergence_level(self, arms: List[EnhancedDecisionArm]) -> float:
        """
        è®¡ç®—è·¯å¾„çº§åˆ«çš„æ”¶æ•›æ°´å¹³
        
        Args:
            arms: è·¯å¾„å†³ç­–è‡‚åˆ—è¡¨
            
        Returns:
            æ”¶æ•›æ°´å¹³ (0.0-1.0)
        """
        if len(arms) < 2:
            return 0.0
        
        # è®¡ç®—è·¯å¾„æˆåŠŸç‡æ–¹å·®
        success_rates = []
        for arm in arms:
            total = arm.success_count + arm.failure_count
            if total > 0:
                success_rates.append(arm.success_count / total)
        
        if len(success_rates) < 2:
            return 0.0
        
        variance = np.var(success_rates)
        # å°†æ–¹å·®è½¬æ¢ä¸ºæ”¶æ•›æ°´å¹³ï¼ˆæ–¹å·®è¶Šå°ï¼Œæ”¶æ•›æ°´å¹³è¶Šé«˜ï¼‰
        # å¯¹äºæ€ç»´è·¯å¾„ï¼Œæˆ‘ä»¬å¸Œæœ›ä¿æŒä¸€å®šçš„å¤šæ ·æ€§ï¼Œæ‰€ä»¥æ”¶æ•›æ ‡å‡†ç¨å¾®å®½æ¾
        convergence_level = max(0.0, 1.0 - variance * 3.5)
        
        return convergence_level
    
    # ==================== ğŸ”§ å·¥å…·é€‰æ‹©MABç®—æ³•å®ç° ====================
    
    def _select_best_algorithm_for_tools(self) -> str:
        """
        ä¸ºå·¥å…·é€‰æ‹©é€‰æ‹©æœ€ä½³ç®—æ³•
        
        Returns:
            æœ€ä½³ç®—æ³•åç§°
        """
        # å¦‚æœæ ·æœ¬å¤ªå°‘ï¼Œä½¿ç”¨Thompsoné‡‡æ ·è¿›è¡Œæ¢ç´¢
        if self.total_tool_selections < 10:
            logger.debug("ğŸ“Š å·¥å…·é€‰æ‹©æ ·æœ¬è¾ƒå°‘ï¼Œé€‰æ‹©Thompsoné‡‡æ ·")
            return 'thompson_sampling'
        
        # è®¡ç®—å·¥å…·çº§åˆ«çš„æ”¶æ•›æ°´å¹³
        if not self.tool_arms:
            return 'thompson_sampling'
        
        arms_list = list(self.tool_arms.values())
        convergence_level = self._calculate_tool_convergence_level(arms_list)
        
        # å·¥å…·é€‰æ‹©å€¾å‘äºæ›´å¿«æ”¶æ•›åˆ°æœ€ä¼˜å·¥å…·
        if convergence_level < 0.3:
            # ä½æ”¶æ•›ï¼Œä½¿ç”¨æ¢ç´¢æ€§å¼ºçš„ç®—æ³•
            logger.debug(f"ğŸ“Š å·¥å…·é€‰æ‹©ä½æ”¶æ•›({convergence_level:.3f})ï¼Œé€‰æ‹©Thompsoné‡‡æ ·")
            return 'thompson_sampling'
        elif convergence_level < 0.6:
            # ä¸­ç­‰æ”¶æ•›ï¼Œä½¿ç”¨å¹³è¡¡çš„ç®—æ³•
            logger.debug(f"ğŸ“Š å·¥å…·é€‰æ‹©ä¸­ç­‰æ”¶æ•›({convergence_level:.3f})ï¼Œé€‰æ‹©UCB")
            return 'ucb_variant'
        else:
            # é«˜æ”¶æ•›ï¼Œä½¿ç”¨åˆ©ç”¨å‹ç®—æ³•
            logger.debug(f"ğŸ“Š å·¥å…·é€‰æ‹©é«˜æ”¶æ•›({convergence_level:.3f})ï¼Œé€‰æ‹©Epsilon-Greedy")
            return 'epsilon_greedy'
    
    def _calculate_tool_convergence_level(self, arms: List[EnhancedDecisionArm]) -> float:
        """
        è®¡ç®—å·¥å…·çº§åˆ«çš„æ”¶æ•›æ°´å¹³
        
        Args:
            arms: å·¥å…·å†³ç­–è‡‚åˆ—è¡¨
            
        Returns:
            æ”¶æ•›æ°´å¹³ (0.0-1.0)
        """
        if len(arms) < 2:
            return 0.0
        
        # è®¡ç®—å·¥å…·æˆåŠŸç‡æ–¹å·®
        success_rates = []
        for arm in arms:
            total = arm.success_count + arm.failure_count
            if total > 0:
                success_rates.append(arm.success_count / total)
        
        if len(success_rates) < 2:
            return 0.0
        
        variance = np.var(success_rates)
        # å·¥å…·é€‰æ‹©å¯ä»¥æ›´å¿«æ”¶æ•›ï¼Œæ”¶æ•›æ ‡å‡†ç›¸å¯¹ä¸¥æ ¼
        convergence_level = max(0.0, 1.0 - variance * 2.5)
        
        return convergence_level
    
    def _thompson_sampling_for_tools(self, arms: List[EnhancedDecisionArm]) -> EnhancedDecisionArm:
        """é’ˆå¯¹å·¥å…·é€‰æ‹©çš„Thompsoné‡‡æ ·ç®—æ³•"""
        if not arms:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å·¥å…·å†³ç­–è‡‚")
        
        best_arm = None
        best_score = -1
        
        logger.debug(f"ğŸ”§ Thompsoné‡‡æ ·å·¥å…·é€‰æ‹©ï¼Œå€™é€‰å·¥å…·: {len(arms)}ä¸ª")
        
        for arm in arms:
            # ä½¿ç”¨Betaåˆ†å¸ƒè¿›è¡ŒThompsoné‡‡æ ·
            alpha = arm.success_count + 1
            beta = arm.failure_count + 1
            
            # ä»Betaåˆ†å¸ƒä¸­é‡‡æ ·
            sampled_value = np.random.beta(alpha, beta)
            
            # å·¥å…·çº§åˆ«çš„å¥–åŠ±è€ƒè™‘
            if arm.rl_reward_history:
                avg_reward = sum(arm.rl_reward_history) / len(arm.rl_reward_history)
                # å°†å¥–åŠ±è°ƒæ•´åˆ°0-1èŒƒå›´
                normalized_reward = max(0, min(1, (avg_reward + 1) / 2))
                sampled_value = sampled_value * 0.7 + normalized_reward * 0.3
            
            logger.debug(f"   å·¥å…· {arm.path_id}: sampled={sampled_value:.3f}, Î±={alpha}, Î²={beta}")
            
            if sampled_value > best_score:
                best_score = sampled_value
                best_arm = arm
        
        logger.debug(f"ğŸ† Thompsoné‡‡æ ·é€‰æ‹©å·¥å…·: {best_arm.path_id} (å¾—åˆ†: {best_score:.3f})")
        return best_arm
    
    def _ucb_variant_for_tools(self, arms: List[EnhancedDecisionArm]) -> EnhancedDecisionArm:
        """é’ˆå¯¹å·¥å…·é€‰æ‹©çš„UCB (Upper Confidence Bound) å˜ç§ç®—æ³•"""
        if not arms:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å·¥å…·å†³ç­–è‡‚")
        
        total_rounds = sum(arm.activation_count for arm in arms)
        if total_rounds == 0:
            # ç¬¬ä¸€è½®éšæœºé€‰æ‹©
            selected_arm = np.random.choice(arms)
            logger.debug(f"ğŸ”§ UCBé¦–è½®éšæœºé€‰æ‹©å·¥å…·: {selected_arm.path_id}")
            return selected_arm
        
        best_arm = None
        best_ucb_value = -float('inf')
        
        logger.debug(f"ğŸ“Š UCBå·¥å…·é€‰æ‹©ï¼Œæ€»è½®æ•°: {total_rounds}")
        
        for arm in arms:
            if arm.activation_count == 0:
                # æœªå°è¯•è¿‡çš„å·¥å…·ä¼˜å…ˆé€‰æ‹©
                logger.debug(f"ğŸ†• ä¼˜å…ˆé€‰æ‹©æœªä½¿ç”¨å·¥å…·: {arm.path_id}")
                return arm
            
            # è®¡ç®—UCBå€¼
            confidence_bound = np.sqrt(2 * np.log(total_rounds) / arm.activation_count)
            
            # åŸºç¡€æˆåŠŸç‡
            base_value = arm.success_rate
            
            # å·¥å…·çº§åˆ«çš„RLå¥–åŠ±è€ƒè™‘
            if arm.rl_reward_history:
                avg_reward = sum(arm.rl_reward_history) / len(arm.rl_reward_history)
                normalized_reward = max(0, min(1, (avg_reward + 1) / 2))
                base_value = base_value * 0.6 + normalized_reward * 0.4
            
            # å·¥å…·æ¢ç´¢å¥–åŠ±
            exploration_bonus = confidence_bound * 1.0  # æ ‡å‡†æ¢ç´¢
            ucb_value = base_value + exploration_bonus
            
            logger.debug(f"   å·¥å…· {arm.path_id}: UCB={ucb_value:.3f}, base={base_value:.3f}, conf={confidence_bound:.3f}")
            
            if ucb_value > best_ucb_value:
                best_ucb_value = ucb_value
                best_arm = arm
        
        logger.debug(f"ğŸ† UCBé€‰æ‹©å·¥å…·: {best_arm.path_id} (UCBå€¼: {best_ucb_value:.3f})")
        return best_arm
    
    def _epsilon_greedy_for_tools(self, arms: List[EnhancedDecisionArm]) -> EnhancedDecisionArm:
        """é’ˆå¯¹å·¥å…·é€‰æ‹©çš„Epsilon-Greedyç®—æ³•"""
        if not arms:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å·¥å…·å†³ç­–è‡‚")
        
        # å·¥å…·çº§åˆ«çš„åŠ¨æ€epsilonå€¼
        total_activations = sum(arm.activation_count for arm in arms)
        epsilon = max(0.05, 0.3 / (1 + total_activations * 0.01))  # æ¯”è·¯å¾„é€‰æ‹©æ›´ä½çš„æ¢ç´¢ç‡
        
        logger.debug(f"ğŸ”§ Epsilon-Greedyå·¥å…·é€‰æ‹©ï¼ŒÎµ={epsilon:.3f}")
        
        # ä½¿ç”¨epsilonå†³å®šæ˜¯å¦æ¢ç´¢
        if np.random.random() < epsilon:
            # æ¢ç´¢ï¼šéšæœºé€‰æ‹©å·¥å…·
            selected_arm = np.random.choice(arms)
            logger.debug(f"ğŸ” æ¢ç´¢æ¨¡å¼é€‰æ‹©å·¥å…·: {selected_arm.path_id}")
            return selected_arm
        else:
            # åˆ©ç”¨ï¼šé€‰æ‹©å½“å‰æœ€å¥½çš„å·¥å…·
            best_arm = None
            best_score = -float('inf')
            
            for arm in arms:
                # å·¥å…·çº§åˆ«çš„ç»¼åˆè¯„åˆ†
                score = arm.success_rate
                
                # RLå¥–åŠ±æƒé‡
                if arm.rl_reward_history:
                    avg_reward = sum(arm.rl_reward_history) / len(arm.rl_reward_history)
                    normalized_reward = max(0, min(1, (avg_reward + 1) / 2))
                    score = score * 0.5 + normalized_reward * 0.5
                
                logger.debug(f"   å·¥å…· {arm.path_id}: score={score:.3f}")
                
                if score > best_score:
                    best_score = score
                    best_arm = arm
            
            logger.debug(f"ğŸ† åˆ©ç”¨æ¨¡å¼é€‰æ‹©å·¥å…·: {best_arm.path_id} (å¾—åˆ†: {best_score:.3f})")
            return best_arm if best_arm else arms[0]
    
    # ==================== ğŸ“Š æ›´æ–°æ€§èƒ½åé¦ˆæ–¹æ³• ====================
    
    def update_path_performance(self, path_id: str, success: bool, reward: float = 0.0, source: str = "user_feedback"):
        """
        ğŸ”§ åŒå±‚å­¦ä¹ ï¼šæ›´æ–°è·¯å¾„æˆ–å·¥å…·çš„æ€§èƒ½åé¦ˆ - é€šç”¨æ€§åé¦ˆæ›´æ–°æ–¹æ³•ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        å¢å¼ºåŠŸèƒ½ï¼š
        - æ–°å¢sourceå‚æ•°ï¼Œæ”¯æŒè¿½è¸ªåé¦ˆæ¥æº
        - æ”¯æŒå›æº¯åˆ†æ("retrospection")å’Œç”¨æˆ·åé¦ˆ("user_feedback")çš„åŒºåˆ†
        - é’ˆå¯¹ä¸åŒæ¥æºçš„åé¦ˆï¼Œä½¿ç”¨ä¸åŒçš„æƒé‡å’Œå¤„ç†ç­–ç•¥
        
        Args:
            path_id: è·¯å¾„IDæˆ–å·¥å…·IDï¼ˆç”±è°ƒç”¨æ–¹å†³å®šæ˜¯è·¯å¾„è¿˜æ˜¯å·¥å…·ï¼‰
            success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            reward: RLå¥–åŠ±å€¼
            source: åé¦ˆæ¥æº ("user_feedback", "retrospection", "auto_evaluation", "tool_verification")
        """
        # ğŸ¯ æ™ºèƒ½è¯†åˆ«ï¼šæ£€æŸ¥æ˜¯è·¯å¾„åé¦ˆè¿˜æ˜¯å·¥å…·åé¦ˆ
        if path_id in self.path_arms:
            # è·¯å¾„åé¦ˆå¤„ç†
            target_arm = self.path_arms[path_id]
            
            # æ›´æ–°è·¯å¾„ç®—æ³•æ€§èƒ½ç»Ÿè®¡
            if self.path_selection_history:
                last_selection = self.path_selection_history[-1]
                if last_selection['path_id'] == path_id:
                    algorithm = last_selection['algorithm']
                    self.algorithm_performance[algorithm]['total'] += 1
                    if success:
                        self.algorithm_performance[algorithm]['successes'] += 1
                        
        elif path_id in self.tool_arms:
            # å·¥å…·åé¦ˆå¤„ç†
            target_arm = self.tool_arms[path_id]
            
            # æ›´æ–°å·¥å…·ç®—æ³•æ€§èƒ½ç»Ÿè®¡
            if self.tool_selection_history:
                last_selection = self.tool_selection_history[-1]
                if last_selection['tool_id'] == path_id:
                    algorithm = last_selection['algorithm']
                    self.tool_algorithm_performance[algorithm]['total'] += 1
                    if success:
                        self.tool_algorithm_performance[algorithm]['successes'] += 1
                        
        else:
            # åŠ¨æ€åˆ›å»ºå†³ç­–è‡‚ï¼ˆé»˜è®¤ä½œä¸ºè·¯å¾„å¤„ç†ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
            target_arm = self._create_strategy_arm_if_missing(path_id)
            logger.debug(f"ğŸ”§ ä¸ºæœªçŸ¥ID {path_id} åˆ›å»ºè·¯å¾„å†³ç­–è‡‚ï¼ˆå‘åå…¼å®¹ï¼‰")
        
        # âœ… å¢å¼ºç‰ˆæ€§èƒ½æ›´æ–°ï¼šæ ¹æ®æ¥æºè°ƒæ•´å¤„ç†ç­–ç•¥
        adjusted_reward = self._adjust_reward_by_source(reward, source, success)
        target_arm.update_performance(success, adjusted_reward)
        
        # ğŸ“Š è®°å½•æ¥æºè¿½è¸ªä¿¡æ¯
        self._record_feedback_source(path_id, source, success, reward)
        
        # è®°å½•æ›´æ–°æ—¥å¿—
        arm_type = "å·¥å…·" if path_id in self.tool_arms else "è·¯å¾„"
        logger.info(f"ğŸ“Š æ›´æ–°{arm_type}æ€§èƒ½: {path_id} -> æˆåŠŸç‡:{target_arm.success_rate:.3f}, å¥–åŠ±:{reward:.3f}, æ¥æº:{source}")
        logger.debug(f"   è¯¦ç»†: æˆåŠŸ{target_arm.success_count}æ¬¡, å¤±è´¥{target_arm.failure_count}æ¬¡, æ¿€æ´»{target_arm.activation_count}æ¬¡")
        
        # ğŸ† é»„é‡‘æ¨¡æ¿è¯†åˆ«é€»è¾‘ï¼šæ£€æŸ¥æ˜¯å¦ç¬¦åˆé»„é‡‘æ¨¡æ¿æ¡ä»¶ï¼ˆä»…å¯¹è·¯å¾„åº”ç”¨ï¼‰
        if path_id in self.path_arms:
            self._check_and_promote_to_golden_template(path_id, target_arm)
            
            # ğŸ­ è¯•ç‚¼åœºç®¡ç†ï¼šæ£€æŸ¥æ·˜æ±°å€™é€‰
            self._check_culling_candidates(path_id, target_arm, success)
    
    def update_path_feedback(self, path_id: str, success: bool, reward: float = 0.0, source: str = "user_feedback"):
        """
        ğŸ”¥ ä¿®å¤ï¼šæ·»åŠ update_path_feedbackæ–¹æ³•ï¼ˆä¸update_path_performanceåŠŸèƒ½ç›¸åŒï¼Œæä¾›å…¼å®¹æ€§ï¼‰
        
        Args:
            path_id: è·¯å¾„IDæˆ–å·¥å…·ID
            success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            reward: RLå¥–åŠ±å€¼
            source: åé¦ˆæ¥æº
        """
        return self.update_path_performance(path_id, success, reward, source)
    
    def _adjust_reward_by_source(self, reward: float, source: str, success: bool) -> float:
        """
        æ ¹æ®åé¦ˆæ¥æºè°ƒæ•´å¥–åŠ±å€¼
        
        Args:
            reward: åŸå§‹å¥–åŠ±å€¼
            source: åé¦ˆæ¥æº
            success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            
        Returns:
            è°ƒæ•´åçš„å¥–åŠ±å€¼
        """
        # è·å–æ¥æºæƒé‡
        weight = self.source_weight_config.get(source, 1.0)
        
        # ç‰¹æ®Šå¤„ç†ï¼šå›æº¯åˆ†æçš„åˆå§‹æ¢ç´¢å¥–åŠ±
        if source == "retrospection":
            if success and reward > 0:
                # å›æº¯åˆ†ææˆåŠŸçš„åˆ›æ–°æƒ³æ³•ç»™äºˆé¢å¤–å¥–åŠ±
                adjusted_reward = reward * weight + 0.1
            else:
                # å›æº¯åˆ†æå¤±è´¥æ—¶ä»ç»™äºˆå°å¹…æ­£å‘å¥–åŠ±é¼“åŠ±æ¢ç´¢
                adjusted_reward = max(reward * weight, 0.05)
        else:
            # å…¶ä»–æ¥æºæŒ‰æƒé‡è°ƒæ•´
            adjusted_reward = reward * weight
        
        return adjusted_reward
    
    def _record_feedback_source(self, path_id: str, source: str, success: bool, reward: float):
        """
        è®°å½•åé¦ˆæ¥æºè¿½è¸ªä¿¡æ¯
        
        Args:
            path_id: è·¯å¾„ID
            source: åé¦ˆæ¥æº
            success: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
            reward: å¥–åŠ±å€¼
        """
        if source in self.feedback_source_tracking:
            tracking = self.feedback_source_tracking[source]
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            old_count = tracking["count"]
            new_count = old_count + 1
            
            # å¢é‡æ›´æ–°æˆåŠŸç‡
            old_success_rate = tracking["success_rate"]
            new_success_rate = (old_success_rate * old_count + (1 if success else 0)) / new_count
            
            # å¢é‡æ›´æ–°å¹³å‡å¥–åŠ±
            old_avg_reward = tracking["avg_reward"]
            new_avg_reward = (old_avg_reward * old_count + reward) / new_count
            
            # æ›´æ–°è¿½è¸ªè®°å½•
            tracking.update({
                "count": new_count,
                "success_rate": new_success_rate,
                "avg_reward": new_avg_reward
            })
            
            logger.debug(f"ğŸ“Š æ¥æºè¿½è¸ªæ›´æ–°: {source} -> æ¬¡æ•°:{new_count}, æˆåŠŸç‡:{new_success_rate:.3f}, å¹³å‡å¥–åŠ±:{new_avg_reward:.3f}")
    
    def get_feedback_source_stats(self) -> Dict[str, Any]:
        """
        è·å–åé¦ˆæ¥æºç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            è¯¦ç»†çš„æ¥æºè¿½è¸ªç»Ÿè®¡
        """
        return {
            "source_tracking": self.feedback_source_tracking.copy(),
            "source_weights": self.source_weight_config.copy(),
            "total_feedback_by_source": {
                source: data["count"] 
                for source, data in self.feedback_source_tracking.items()
            },
            "retrospection_contribution": {
                "total_retrospection_feedback": self.feedback_source_tracking["retrospection"]["count"],
                "retrospection_success_rate": self.feedback_source_tracking["retrospection"]["success_rate"],
                "retrospection_avg_reward": self.feedback_source_tracking["retrospection"]["avg_reward"]
            }
        }
    
    # ä¿ç•™å‘åå…¼å®¹çš„æ–¹æ³•ï¼ˆæ ‡è®°ä¸ºè¿‡æ—¶ï¼‰
    def update_arm_performance(self, dimension_name: str, option: str, 
                             success: bool, reward: float = 0.0):
        """
        æ›´æ–°å†³ç­–è‡‚çš„æ€§èƒ½ - å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ update_path_performance
        
        Args:
            dimension_name: ç»´åº¦åç§°
            option: é€‰é¡¹åç§°
            success: æ˜¯å¦æˆåŠŸ
            reward: RLå¥–åŠ±å€¼
        """
        logger.warning("âš ï¸ update_arm_performance å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ update_path_performance")
        path_id = f"{dimension_name}_{option}"  # ä¸´æ—¶è½¬æ¢
        self.update_path_performance(path_id, success, reward)
    
    def check_path_convergence(self) -> bool:
        """
        æ£€æŸ¥è·¯å¾„é€‰æ‹©æ˜¯å¦æ”¶æ•›
        
        Returns:
            æ˜¯å¦æ”¶æ•›
        """
        if len(self.path_arms) < 2:
            return False
            
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬
        total_samples = sum(arm.success_count + arm.failure_count for arm in self.path_arms.values())
        if total_samples < self.min_samples:
            return False
            
        # è®¡ç®—è·¯å¾„æˆåŠŸç‡æ–¹å·®ï¼Œåˆ¤æ–­æ˜¯å¦æ”¶æ•›
        success_rates = []
        for arm in self.path_arms.values():
            total = arm.success_count + arm.failure_count
            if total > 0:
                success_rates.append(arm.success_count / total)
                
        if len(success_rates) < 2:
            return False
            
        variance = np.var(success_rates)
        # å¯¹äºæ€ç»´è·¯å¾„ï¼Œä½¿ç”¨ç¨å¾®å®½æ¾çš„æ”¶æ•›æ ‡å‡†ï¼Œä¿æŒå¤šæ ·æ€§
        adjusted_threshold = self.convergence_threshold * 1.2
        is_converged = variance < adjusted_threshold
        
        if is_converged:
            logger.info(f"âœ… è·¯å¾„é€‰æ‹©å·²æ”¶æ•› (æ–¹å·®:{variance:.4f}, é˜ˆå€¼:{adjusted_threshold:.4f})")
        
        return is_converged
    
    # ä¿ç•™å‘åå…¼å®¹çš„æ–¹æ³•ï¼ˆæ ‡è®°ä¸ºè¿‡æ—¶ï¼‰
    def check_convergence(self, dimension_name: str) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šç»´åº¦æ˜¯å¦æ”¶æ•› - å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ check_path_convergence
        """
        logger.warning("âš ï¸ check_convergence å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ check_path_convergence")
        return self.check_path_convergence()
    
    def get_path_statistics(self) -> Dict[str, Dict[str, any]]:
        """
        è·å–æ‰€æœ‰è·¯å¾„çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…å«é»„é‡‘æ¨¡æ¿çŠ¶æ€ï¼‰
        
        Returns:
            è·¯å¾„ç»Ÿè®¡æ•°æ®
        """
        statistics = {}
        
        for path_id, arm in self.path_arms.items():
            # æ£€æŸ¥æ˜¯å¦ä¸ºé»„é‡‘æ¨¡æ¿
            is_golden_template = path_id in self.golden_templates
            golden_template_info = None
            
            if is_golden_template:
                template_data = self.golden_templates[path_id]
                golden_template_info = {
                    'created_timestamp': template_data['created_timestamp'],
                    'last_updated': template_data['last_updated'],
                    'stability_score': template_data['stability_score'],
                    'usage_as_template': self.template_usage_stats.get(path_id, 0),
                    'promotion_reason': template_data['promotion_reason']
                }
            
            # è®¡ç®—è·¯å¾„ç‰¹å®šçš„ç»Ÿè®¡
            statistics[path_id] = {
                'path_type': arm.option,  # è·¯å¾„ç±»å‹
                'path_id': path_id,
                'activation_count': arm.activation_count,
                'success_count': arm.success_count,
                'failure_count': arm.failure_count,
                'success_rate': arm.success_rate,
                'total_reward': arm.total_reward,
                'average_reward': sum(arm.rl_reward_history) / len(arm.rl_reward_history) if arm.rl_reward_history else 0.0,
                'last_used': arm.last_used,
                'recent_trend': self._calculate_recent_trend(arm),
                'consecutive_successes': self._calculate_consecutive_successes(arm),
                'usage_ratio': arm.activation_count / max(self.total_path_selections, 1),
                
                # ğŸ† é»„é‡‘æ¨¡æ¿ç›¸å…³ä¿¡æ¯
                'is_golden_template': is_golden_template,
                'golden_template_info': golden_template_info,
                'meets_golden_criteria': self._check_golden_criteria(arm),
                'stability_score': self._calculate_stability_score(arm) if arm.activation_count >= 10 else 0.0
            }
        
        return statistics
    
    def _check_golden_criteria(self, arm: EnhancedDecisionArm) -> bool:
        """
        æ£€æŸ¥è·¯å¾„æ˜¯å¦ç¬¦åˆé»„é‡‘æ¨¡æ¿çš„åŸºæœ¬æ¡ä»¶ï¼ˆä¸åŒ…æ‹¬ç¨³å®šæ€§æ£€æŸ¥ï¼‰
        
        Args:
            arm: å†³ç­–è‡‚å¯¹è±¡
            
        Returns:
            æ˜¯å¦ç¬¦åˆåŸºæœ¬æ¡ä»¶
        """
        config = self.golden_template_config
        return (arm.success_rate >= config['success_rate_threshold'] and 
                arm.activation_count >= config['min_samples_required'])
    
    def get_system_path_summary(self) -> Dict[str, any]:
        """
        è·å–è·¯å¾„é€‰æ‹©ç³»ç»Ÿçš„æ•´ä½“æ‘˜è¦
        
        Returns:
            ç³»ç»Ÿæ‘˜è¦æ•°æ®
        """
        if not self.path_arms:
            return {
                'total_paths': 0,
                'total_selections': self.total_path_selections,
                'is_converged': False,
                'convergence_level': 0.0,
                'most_used_path': None,
                'best_performing_path': None
            }
        
        # æœ€å¸¸ç”¨è·¯å¾„
        most_used_arm = max(self.path_arms.values(), key=lambda a: a.activation_count)
        
        # æœ€ä½³æ€§èƒ½è·¯å¾„
        best_performing_arm = max(self.path_arms.values(), key=lambda a: a.success_rate)
        
        # ç®—æ³•æ€§èƒ½ç»Ÿè®¡
        algorithm_stats = {}
        for algo, stats in self.algorithm_performance.items():
            if stats['total'] > 0:
                algorithm_stats[algo] = {
                    'success_rate': stats['successes'] / stats['total'],
                    'total_uses': stats['total']
                }
        
        return {
            'total_paths': len(self.path_arms),
            'total_selections': self.total_path_selections,
            'is_converged': self.check_path_convergence(),
            'convergence_level': self._calculate_path_convergence_level(list(self.path_arms.values())),
            'most_used_path': {
                'path_id': most_used_arm.path_id,
                'path_type': most_used_arm.option,
                'usage_count': most_used_arm.activation_count
            },
            'best_performing_path': {
                'path_id': best_performing_arm.path_id,
                'path_type': best_performing_arm.option,
                'success_rate': best_performing_arm.success_rate
            },
            'algorithm_performance': algorithm_stats,
            'total_samples': sum(arm.success_count + arm.failure_count for arm in self.path_arms.values())
        }
    
    # ä¿ç•™å‘åå…¼å®¹çš„æ–¹æ³•ï¼ˆæ ‡è®°ä¸ºè¿‡æ—¶ï¼‰
    def get_dimension_statistics(self) -> Dict[str, Dict[str, any]]:
        """
        è·å–æ‰€æœ‰ç»´åº¦çš„ç»Ÿè®¡ä¿¡æ¯ - å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ get_path_statistics
        """
        logger.warning("âš ï¸ get_dimension_statistics å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ get_path_statistics")
        return self.get_path_statistics()
    
    def get_path_details(self, path_id: str = None) -> Dict[str, any]:
        """
        è·å–æŒ‡å®šè·¯å¾„çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            path_id: è·¯å¾„IDï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰è·¯å¾„çš„è¯¦ç»†ä¿¡æ¯
            
        Returns:
            è·¯å¾„è¯¦ç»†ä¿¡æ¯
        """
        if path_id is not None:
            if path_id not in self.path_arms:
                logger.warning(f"âš ï¸ è·¯å¾„ {path_id} ä¸å­˜åœ¨")
                return {}
            
            arm = self.path_arms[path_id]
            return {
                'path_id': path_id,
                'path_type': arm.option,
                'success_count': arm.success_count,
                'failure_count': arm.failure_count,
                'success_rate': arm.success_rate,
                'total_reward': arm.total_reward,
                'average_reward': sum(arm.rl_reward_history) / len(arm.rl_reward_history) if arm.rl_reward_history else 0.0,
                'activation_count': arm.activation_count,
                'last_used': arm.last_used,
                'recent_trend': self._calculate_recent_trend(arm),
                'consecutive_successes': self._calculate_consecutive_successes(arm),
                'rl_reward_history': arm.rl_reward_history.copy(),
                'recent_results': arm.recent_results.copy()
            }
        else:
            # è¿”å›æ‰€æœ‰è·¯å¾„çš„è¯¦ç»†ä¿¡æ¯
            all_details = {}
            for pid, arm in self.path_arms.items():
                all_details[pid] = self.get_path_details(pid)
            
            # æŒ‰æˆåŠŸç‡æ’åº
            sorted_paths = sorted(all_details.items(), 
                                key=lambda x: x[1]['success_rate'], 
                                reverse=True)
            return dict(sorted_paths)
    
    def get_selection_history(self, limit: int = 10) -> List[Dict[str, any]]:
        """
        è·å–è·¯å¾„é€‰æ‹©å†å²
        
        Args:
            limit: è¿”å›çš„å†å²è®°å½•æ•°é‡é™åˆ¶
            
        Returns:
            é€‰æ‹©å†å²åˆ—è¡¨
        """
        return self.path_selection_history[-limit:] if self.path_selection_history else []
    
    # ä¿ç•™å‘åå…¼å®¹çš„æ–¹æ³•ï¼ˆæ ‡è®°ä¸ºè¿‡æ—¶ï¼‰
    def get_arm_details(self, dimension_name: str) -> List[Dict[str, any]]:
        """
        è·å–æŒ‡å®šç»´åº¦çš„æ‰€æœ‰å†³ç­–è‡‚è¯¦ç»†ä¿¡æ¯ - å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ get_path_details
        """
        logger.warning("âš ï¸ get_arm_details å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ get_path_details")
        return list(self.get_path_details().values())
    
    def reset_path(self, path_id: str):
        """
        é‡ç½®æŒ‡å®šè·¯å¾„çš„æ‰€æœ‰æ•°æ®
        
        Args:
            path_id: è·¯å¾„ID
        """
        if path_id in self.path_arms:
            del self.path_arms[path_id]
            logger.info(f"ğŸ”„ è·¯å¾„ {path_id} å·²é‡ç½®")
        
        # æ¸…ç†é€‰æ‹©å†å²ä¸­çš„ç›¸å…³è®°å½•
        self.path_selection_history = [
            record for record in self.path_selection_history 
            if record['path_id'] != path_id
        ]
    
    def reset_all_paths(self):
        """
        é‡ç½®æ‰€æœ‰è·¯å¾„æ•°æ®ï¼Œå®Œå…¨æ¸…ç©ºå­¦ä¹ å†å²
        """
        self.path_arms.clear()
        self.path_selection_history.clear()
        self.total_path_selections = 0
        self.algorithm_performance.clear()
        logger.info("ğŸ”„ æ‰€æœ‰è·¯å¾„æ•°æ®å·²é‡ç½®")
    
    def get_system_status(self) -> Dict[str, any]:
        """
        è·å–MABè·¯å¾„é€‰æ‹©ç³»ç»Ÿçš„æ•´ä½“çŠ¶æ€
        
        Returns:
            ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
        """
        total_paths = len(self.path_arms)
        is_converged = self.check_path_convergence()
        
        # è®¡ç®—æ´»è·ƒè·¯å¾„æ•°ï¼ˆæœ€è¿‘ä½¿ç”¨è¿‡çš„ï¼‰
        current_time = time.time()
        active_paths = sum(
            1 for arm in self.path_arms.values() 
            if arm.last_used > 0 and (current_time - arm.last_used) < 3600  # 1å°æ—¶å†…ä½¿ç”¨è¿‡
        )
        
        # æœ€å—æ¬¢è¿çš„è·¯å¾„ç±»å‹
        path_type_usage = {}
        for arm in self.path_arms.values():
            path_type = arm.option
            path_type_usage[path_type] = path_type_usage.get(path_type, 0) + arm.activation_count
        
        most_popular_type = max(path_type_usage.items(), key=lambda x: x[1])[0] if path_type_usage else None
        
        # è·å–é»„é‡‘æ¨¡æ¿ç»Ÿè®¡
        golden_stats = self.get_golden_template_stats()
        
        return {
            'mode': 'path_selection',  # æ–°å¢ï¼šæ ‡è¯†å½“å‰ä¸ºè·¯å¾„é€‰æ‹©æ¨¡å¼
            'total_paths': total_paths,
            'active_paths': active_paths,
            'total_selections': self.total_path_selections,
            'is_converged': is_converged,
            'convergence_level': self._calculate_path_convergence_level(list(self.path_arms.values())) if self.path_arms else 0.0,
            'convergence_threshold': self.convergence_threshold,
            'min_samples': self.min_samples,
            'most_popular_path_type': most_popular_type,
            'path_type_distribution': path_type_usage,
            'algorithm_performance': dict(self.algorithm_performance),
            
            # ğŸ† é»„é‡‘æ¨¡æ¿ç³»ç»ŸçŠ¶æ€
            'golden_template_system': {
                'enabled': True,
                'total_templates': golden_stats['total_templates'],
                'avg_success_rate': golden_stats['avg_success_rate'],
                'total_usage_count': golden_stats['total_usage_count'],
                'most_used_template': golden_stats['most_used_template'],
                'match_history_count': golden_stats['match_history_count'],
                'config': self.golden_template_config
            }
        }
    
    # ä¿ç•™å‘åå…¼å®¹çš„æ–¹æ³•ï¼ˆæ ‡è®°ä¸ºè¿‡æ—¶ï¼‰
    def reset_dimension(self, dimension_name: str):
        """
        é‡ç½®æŒ‡å®šç»´åº¦çš„æ‰€æœ‰æ•°æ® - å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ reset_path æˆ– reset_all_paths
        """
        logger.warning("âš ï¸ reset_dimension å·²è¿‡æ—¶ï¼Œè¯·ä½¿ç”¨ reset_path æˆ– reset_all_paths")
        # ä¸æ‰§è¡Œä»»ä½•æ“ä½œï¼Œé¿å…æ„å¤–æ¸…é™¤è·¯å¾„æ•°æ®
    
    # ==================== ğŸ† é»„é‡‘å†³ç­–æ¨¡æ¿ç³»ç»Ÿå®ç° ====================
    
    def _check_golden_template_match(self, paths: List[ReasoningPath]) -> Optional[Dict[str, any]]:
        """
        æ£€æŸ¥å½“å‰è·¯å¾„åˆ—è¡¨æ˜¯å¦ä¸å·²æœ‰é»„é‡‘æ¨¡æ¿åŒ¹é… - ğŸ¯ ä¿®å¤ç‰ˆï¼šåŸºäºç­–ç•¥IDåŒ¹é…
        
        Args:
            paths: å€™é€‰æ€ç»´è·¯å¾„åˆ—è¡¨
            
        Returns:
            åŒ¹é…ç»“æœå­—å…¸ï¼ŒåŒ…å«åŒ¹é…çš„æ¨¡æ¿å’Œè·¯å¾„ä¿¡æ¯ï¼Œå¦‚æœæ— åŒ¹é…åˆ™è¿”å›None
        """
        if not self.golden_templates:
            return None
        
        best_match = None
        best_score = 0.0
        match_threshold = 0.85  # åŒ¹é…é˜ˆå€¼
        
        logger.debug(f"ğŸ† æ£€æŸ¥ {len(self.golden_templates)} ä¸ªé»„é‡‘æ¨¡æ¿")
        
        for template_id, template_data in self.golden_templates.items():
            template_path_type = template_data['path_type']
            
            # ğŸ¯ æ ¹æºä¿®å¤ï¼šç›´æ¥ä½¿ç”¨è·¯å¾„çš„ç­–ç•¥IDï¼Œæ— éœ€æ¨å¯¼
            for path in paths:
                # ç›´æ¥ä½¿ç”¨è·¯å¾„çš„ç­–ç•¥ID
                path_strategy_id = path.strategy_id
                
                # æ£€æŸ¥æ˜¯å¦åŒ¹é…ï¼šç­–ç•¥IDåŒ¹é…æˆ–è·¯å¾„ç±»å‹åŒ¹é…
                is_strategy_match = (template_id == path_strategy_id)
                is_type_match = (template_path_type == path.path_type)
                
                if is_strategy_match or is_type_match:
                    # è®¡ç®—åŒ¹é…åˆ†æ•°
                    match_score = self._calculate_template_match_score(template_data, path)
                    
                    # ç­–ç•¥IDåŒ¹é…ç»™é¢å¤–åˆ†æ•°
                    if is_strategy_match:
                        match_score += 0.1  # ç­–ç•¥IDåŒ¹é…å¥–åŠ±
                    
                    logger.debug(f"   æ¨¡æ¿ {template_id} vs è·¯å¾„ç­–ç•¥ {path_strategy_id}: åŒ¹é…åˆ†æ•° {match_score:.3f}")
                    logger.debug(f"      ç­–ç•¥åŒ¹é…: {is_strategy_match}, ç±»å‹åŒ¹é…: {is_type_match}")
                    
                    if match_score > match_threshold and match_score > best_score:
                        best_match = {
                            'template_id': template_id,
                            'path': path,
                            'match_score': match_score,
                            'template_data': template_data,
                            'strategy_match': is_strategy_match
                        }
                        best_score = match_score
        
        if best_match:
            match_type = "ç­–ç•¥ID" if best_match['strategy_match'] else "è·¯å¾„ç±»å‹"
            logger.debug(f"ğŸ† æ‰¾åˆ°æœ€ä½³åŒ¹é…: æ¨¡æ¿ {best_match['template_id']} (åˆ†æ•°: {best_score:.3f}, åŒ¹é…ç±»å‹: {match_type})")
        else:
            logger.debug("ğŸ† æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é»„é‡‘æ¨¡æ¿åŒ¹é…")
        
        return best_match
    
    def _calculate_template_match_score(self, template_data: Dict[str, any], path: ReasoningPath) -> float:
        """
        è®¡ç®—æ¨¡æ¿ä¸è·¯å¾„çš„åŒ¹é…åˆ†æ•° - ğŸ¯ ä¿®å¤ç‰ˆï¼šåŸºäºç­–ç•¥IDåŒ¹é…
        
        Args:
            template_data: é»„é‡‘æ¨¡æ¿æ•°æ®
            path: å€™é€‰è·¯å¾„
            
        Returns:
            åŒ¹é…åˆ†æ•° (0.0-1.0)
        """
        score = 0.0
        
        # ğŸ¯ æ ¹æºä¿®å¤ï¼šç›´æ¥ä½¿ç”¨è·¯å¾„çš„ç­–ç•¥ID
        path_strategy_id = path.strategy_id
        
        # 1. ç­–ç•¥IDå®Œå…¨åŒ¹é… (åŸºç¡€åˆ†æ•°60%)
        template_strategy_id = template_data.get('strategy_id', template_data.get('path_id', ''))
        if template_strategy_id == path_strategy_id:
            score += 0.6
        # 1b. è·¯å¾„ç±»å‹åŒ¹é…ä½œä¸ºå¤‡é€‰ (åŸºç¡€åˆ†æ•°40%)
        elif template_data['path_type'] == path.path_type:
            score += 0.4
        
        # 2. æè¿°ç›¸ä¼¼æ€§ (é¢å¤–20%)
        desc_similarity = self._calculate_description_similarity(
            template_data.get('description', ''), path.description
        )
        score += desc_similarity * 0.2
        
        # 3. å†å²æ€§èƒ½å¥–åŠ± (é¢å¤–20%)
        performance_bonus = min(template_data['success_rate'] - 0.8, 0.2) * 1.0  # è¶…è¿‡80%çš„éƒ¨åˆ†è½¬æ¢ä¸ºå¥–åŠ±
        score += performance_bonus
        
        logger.debug(f"ğŸ¯ åŒ¹é…åˆ†æ•°è¯¦æƒ…:")
        logger.debug(f"   æ¨¡æ¿ç­–ç•¥ID: {template_strategy_id}")
        logger.debug(f"   è·¯å¾„ç­–ç•¥ID: {path_strategy_id}")
        logger.debug(f"   ç­–ç•¥åŒ¹é…: {template_strategy_id == path_strategy_id}")
        logger.debug(f"   æè¿°ç›¸ä¼¼æ€§: {desc_similarity:.3f}")
        logger.debug(f"   æ€§èƒ½å¥–åŠ±: {performance_bonus:.3f}")
        logger.debug(f"   æ€»åˆ†: {score:.3f}")
        
        return min(score, 1.0)
    
    def _calculate_description_similarity(self, desc1: str, desc2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªæè¿°æ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰
        
        Args:
            desc1: æè¿°æ–‡æœ¬1
            desc2: æè¿°æ–‡æœ¬2
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0.0-1.0)
        """
        if not desc1 or not desc2:
            return 0.0
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ç®—æ³•
        words1 = set(desc1.lower().split())
        words2 = set(desc2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _check_and_promote_to_golden_template(self, path_id: str, arm: EnhancedDecisionArm):
        """
        æ£€æŸ¥è·¯å¾„æ˜¯å¦ç¬¦åˆé»„é‡‘æ¨¡æ¿æ¡ä»¶ï¼Œå¦‚æœç¬¦åˆåˆ™æå‡ä¸ºé»„é‡‘æ¨¡æ¿
        
        Args:
            path_id: è·¯å¾„ID
            arm: å†³ç­–è‡‚å¯¹è±¡
        """
        config = self.golden_template_config
        
        # æ£€æŸ¥åŸºæœ¬æ¡ä»¶
        if (arm.success_rate >= config['success_rate_threshold'] and 
            arm.activation_count >= config['min_samples_required']):
            
            # æ£€æŸ¥ç¨³å®šæ€§ï¼ˆæœ€è¿‘Næ¬¡çš„è¡¨ç°ï¼‰
            if self._check_path_stability(arm):
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯é»„é‡‘æ¨¡æ¿
                if path_id not in self.golden_templates:
                    self._promote_to_golden_template(path_id, arm)
                else:
                    # æ›´æ–°å·²æœ‰é»„é‡‘æ¨¡æ¿
                    self._update_golden_template(path_id, arm)
    
    def _check_path_stability(self, arm: EnhancedDecisionArm) -> bool:
        """
        æ£€æŸ¥è·¯å¾„çš„ç¨³å®šæ€§ï¼ˆæœ€è¿‘è¡¨ç°æ˜¯å¦æŒç»­è‰¯å¥½ï¼‰
        
        Args:
            arm: å†³ç­–è‡‚å¯¹è±¡
            
        Returns:
            æ˜¯å¦ç¨³å®š
        """
        window_size = self.golden_template_config['stability_check_window']
        
        # è·å–æœ€è¿‘çš„ç»“æœ
        recent_results = arm.recent_results[-window_size:] if len(arm.recent_results) >= window_size else arm.recent_results
        
        if len(recent_results) < window_size:
            return False  # æ ·æœ¬ä¸è¶³
        
        # è®¡ç®—æœ€è¿‘çª—å£çš„æˆåŠŸç‡
        recent_successes = sum(1 for result in recent_results if result)
        recent_success_rate = recent_successes / len(recent_results)
        
        # ç¨³å®šæ€§è¦æ±‚ï¼šæœ€è¿‘è¡¨ç°ä¸ä½äºæ•´ä½“è¡¨ç°çš„95%
        stability_threshold = arm.success_rate * 0.95
        
        return recent_success_rate >= stability_threshold
    
    def _promote_to_golden_template(self, strategy_id: str, arm: EnhancedDecisionArm):
        """
        å°†ç­–ç•¥æå‡ä¸ºé»„é‡‘æ¨¡æ¿ - ğŸ¯ ä¿®å¤ç‰ˆï¼šåŸºäºç­–ç•¥ID
        
        Args:
            strategy_id: ç­–ç•¥IDï¼ˆè€Œéå®ä¾‹IDï¼‰
            arm: å†³ç­–è‡‚å¯¹è±¡
        """
        # æ£€æŸ¥æ¨¡æ¿æ•°é‡é™åˆ¶
        if len(self.golden_templates) >= self.golden_template_config['max_golden_templates']:
            # ç§»é™¤è¡¨ç°æœ€å·®çš„æ¨¡æ¿
            self._remove_worst_golden_template()
        
        # ğŸ¯ ä¿®å¤ï¼šåŸºäºç­–ç•¥IDåˆ›å»ºé»„é‡‘æ¨¡æ¿
        template_data = {
            'strategy_id': strategy_id,        # ç­–ç•¥IDï¼ˆç”¨äºåŒ¹é…ï¼‰
            'path_id': strategy_id,           # å…¼å®¹æ€§å­—æ®µ
            'path_type': arm.option,          # è·¯å¾„ç±»å‹
            'description': getattr(arm, 'description', ''),
            'success_rate': arm.success_rate,
            'total_activations': arm.activation_count,
            'average_reward': sum(arm.rl_reward_history) / len(arm.rl_reward_history) if arm.rl_reward_history else 0.0,
            'created_timestamp': time.time(),
            'last_updated': time.time(),
            'promotion_reason': 'high_performance',
            'stability_score': self._calculate_stability_score(arm),
            'usage_count': 0  # ä½œä¸ºæ¨¡æ¿è¢«ä½¿ç”¨çš„æ¬¡æ•°
        }
        
        # ä½¿ç”¨ç­–ç•¥IDä½œä¸ºæ¨¡æ¿é”®
        self.golden_templates[strategy_id] = template_data
        
        logger.info(f"ğŸ† æ–°é»„é‡‘æ¨¡æ¿è¯ç”Ÿï¼")
        logger.info(f"   ç­–ç•¥ID: {strategy_id}")
        logger.info(f"   è·¯å¾„ç±»å‹: {arm.option}")
        logger.info(f"   æˆåŠŸç‡: {arm.success_rate:.1%}")
        logger.info(f"   æ¿€æ´»æ¬¡æ•°: {arm.activation_count}")
        avg_rl_reward = sum(arm.rl_reward_history) / len(arm.rl_reward_history) if arm.rl_reward_history else 0.0
        logger.info(f"   å¹³å‡å¥–åŠ±: {avg_rl_reward:.3f}")
        logger.info(f"   å½“å‰é»„é‡‘æ¨¡æ¿æ€»æ•°: {len(self.golden_templates)}")
    
    def _update_golden_template(self, strategy_id: str, arm: EnhancedDecisionArm):
        """
        æ›´æ–°å·²æœ‰çš„é»„é‡‘æ¨¡æ¿æ•°æ® - ğŸ¯ ä¿®å¤ç‰ˆï¼šåŸºäºç­–ç•¥ID
        
        Args:
            strategy_id: ç­–ç•¥IDï¼ˆè€Œéå®ä¾‹IDï¼‰
            arm: å†³ç­–è‡‚å¯¹è±¡
        """
        if strategy_id in self.golden_templates:
            template = self.golden_templates[strategy_id]
            template.update({
                'success_rate': arm.success_rate,
                'total_activations': arm.activation_count,
                'average_reward': sum(arm.rl_reward_history) / len(arm.rl_reward_history) if arm.rl_reward_history else 0.0,
                'last_updated': time.time(),
                'stability_score': self._calculate_stability_score(arm)
            })
            
            logger.debug(f"ğŸ† æ›´æ–°é»„é‡‘æ¨¡æ¿: {strategy_id} -> æˆåŠŸç‡:{arm.success_rate:.1%}")
    
    def _calculate_stability_score(self, arm: EnhancedDecisionArm) -> float:
        """
        è®¡ç®—è·¯å¾„çš„ç¨³å®šæ€§åˆ†æ•°
        
        Args:
            arm: å†³ç­–è‡‚å¯¹è±¡
            
        Returns:
            ç¨³å®šæ€§åˆ†æ•° (0.0-1.0)
        """
        if arm.activation_count < 10:
            return 0.0
        
        # è®¡ç®—æˆåŠŸç‡çš„æ–¹å·®ï¼ˆè¶Šå°è¶Šç¨³å®šï¼‰
        recent_results = arm.recent_results[-20:] if len(arm.recent_results) >= 20 else arm.recent_results
        
        if len(recent_results) < 5:
            return 0.5  # æ ·æœ¬ä¸è¶³ï¼Œç»™ä¸­ç­‰åˆ†æ•°
        
        # è®¡ç®—æ»‘åŠ¨çª—å£æˆåŠŸç‡çš„æ–¹å·®
        window_size = 5
        success_rates = []
        
        for i in range(len(recent_results) - window_size + 1):
            window = recent_results[i:i + window_size]
            window_success_rate = sum(window) / len(window)
            success_rates.append(window_success_rate)
        
        if len(success_rates) < 2:
            return 0.5
        
        # æ–¹å·®è¶Šå°ï¼Œç¨³å®šæ€§è¶Šé«˜
        variance = np.var(success_rates)
        stability_score = max(0.0, 1.0 - variance * 4)  # å°†æ–¹å·®è½¬æ¢ä¸ºç¨³å®šæ€§åˆ†æ•°
        
        return stability_score
    
    def _remove_worst_golden_template(self):
        """
        ç§»é™¤è¡¨ç°æœ€å·®çš„é»„é‡‘æ¨¡æ¿
        """
        if not self.golden_templates:
            return
        
        # æŒ‰ç»¼åˆåˆ†æ•°æ’åºï¼Œç§»é™¤æœ€å·®çš„
        worst_template_id = min(self.golden_templates.keys(), 
                               key=lambda tid: self._calculate_template_quality_score(self.golden_templates[tid]))
        
        removed_template = self.golden_templates.pop(worst_template_id)
        
        logger.info(f"ğŸ—‘ï¸ ç§»é™¤è¡¨ç°è¾ƒå·®çš„é»„é‡‘æ¨¡æ¿: {worst_template_id}")
        logger.info(f"   åŸå› : ä¸ºæ–°æ¨¡æ¿è…¾å‡ºç©ºé—´")
        logger.info(f"   è¢«ç§»é™¤æ¨¡æ¿æˆåŠŸç‡: {removed_template['success_rate']:.1%}")
    
    def _calculate_template_quality_score(self, template_data: Dict[str, any]) -> float:
        """
        è®¡ç®—æ¨¡æ¿çš„è´¨é‡åˆ†æ•°
        
        Args:
            template_data: æ¨¡æ¿æ•°æ®
            
        Returns:
            è´¨é‡åˆ†æ•°
        """
        # ç»¼åˆè€ƒè™‘æˆåŠŸç‡ã€ä½¿ç”¨æ¬¡æ•°ã€ç¨³å®šæ€§ç­‰å› ç´ 
        success_score = template_data['success_rate'] * 0.4
        usage_score = min(template_data.get('usage_count', 0) / 10, 1.0) * 0.3  # ä½¿ç”¨æ¬¡æ•°æ ‡å‡†åŒ–
        stability_score = template_data.get('stability_score', 0.5) * 0.2
        recency_score = self._calculate_recency_score(template_data) * 0.1
        
        return success_score + usage_score + stability_score + recency_score
    
    def _calculate_recency_score(self, template_data: Dict[str, any]) -> float:
        """
        è®¡ç®—æ¨¡æ¿çš„æ–°è¿‘æ€§åˆ†æ•°
        
        Args:
            template_data: æ¨¡æ¿æ•°æ®
            
        Returns:
            æ–°è¿‘æ€§åˆ†æ•° (0.0-1.0)
        """
        current_time = time.time()
        last_updated = template_data.get('last_updated', template_data.get('created_timestamp', current_time))
        
        # è®¡ç®—è·ç¦»ä¸Šæ¬¡æ›´æ–°çš„æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        hours_since_update = (current_time - last_updated) / 3600
        
        # 24å°æ—¶å†…æ›´æ–°å¾—æ»¡åˆ†ï¼Œè¶…è¿‡7å¤©å¼€å§‹è¡°å‡
        if hours_since_update <= 24:
            return 1.0
        elif hours_since_update <= 168:  # 7å¤©
            return 1.0 - (hours_since_update - 24) / 144  # çº¿æ€§è¡°å‡
        else:
            return 0.0
    
    # ==================== ğŸ† é»„é‡‘æ¨¡æ¿ç®¡ç†æ¥å£ ====================
    
    def get_golden_templates(self) -> Dict[str, Dict[str, any]]:
        """
        è·å–æ‰€æœ‰é»„é‡‘æ¨¡æ¿
        
        Returns:
            é»„é‡‘æ¨¡æ¿å­—å…¸
        """
        return self.golden_templates.copy()
    
    def get_golden_template_stats(self) -> Dict[str, any]:
        """
        è·å–é»„é‡‘æ¨¡æ¿ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.golden_templates:
            return {
                'total_templates': 0,
                'avg_success_rate': 0.0,
                'total_usage_count': 0,
                'most_used_template': None,
                'template_usage_stats': {},
                'match_history_count': len(self.template_match_history) if hasattr(self, 'template_match_history') else 0
            }
        
        success_rates = [t['success_rate'] for t in self.golden_templates.values()]
        usage_counts = [self.template_usage_stats.get(tid, 0) for tid in self.golden_templates.keys()]
        
        most_used_template_id = max(self.template_usage_stats.keys(), 
                                   key=self.template_usage_stats.get) if self.template_usage_stats else None
        
        return {
            'total_templates': len(self.golden_templates),
            'avg_success_rate': sum(success_rates) / len(success_rates),
            'total_usage_count': sum(usage_counts),
            'most_used_template': {
                'template_id': most_used_template_id,
                'usage_count': self.template_usage_stats.get(most_used_template_id, 0),
                'template_data': self.golden_templates.get(most_used_template_id)
            } if most_used_template_id else None,
            'template_usage_stats': dict(self.template_usage_stats),
            'match_history_count': len(self.template_match_history)
        }
    
    def remove_golden_template(self, template_id: str) -> bool:
        """
        æ‰‹åŠ¨ç§»é™¤æŒ‡å®šçš„é»„é‡‘æ¨¡æ¿
        
        Args:
            template_id: æ¨¡æ¿ID
            
        Returns:
            æ˜¯å¦æˆåŠŸç§»é™¤
        """
        if template_id in self.golden_templates:
            removed_template = self.golden_templates.pop(template_id)
            logger.info(f"ğŸ—‘ï¸ æ‰‹åŠ¨ç§»é™¤é»„é‡‘æ¨¡æ¿: {template_id}")
            logger.info(f"   æ¨¡æ¿ç±»å‹: {removed_template['path_type']}")
            return True
        else:
            logger.warning(f"âš ï¸ é»„é‡‘æ¨¡æ¿ {template_id} ä¸å­˜åœ¨")
            return False
    
    def clear_golden_templates(self):
        """
        æ¸…ç©ºæ‰€æœ‰é»„é‡‘æ¨¡æ¿
        """
        count = len(self.golden_templates)
        self.golden_templates.clear()
        self.template_usage_stats.clear()
        self.template_match_history.clear()
        
        logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç©ºæ‰€æœ‰é»„é‡‘æ¨¡æ¿ (å…± {count} ä¸ª)")
    
    def export_golden_templates(self) -> str:
        """
        å¯¼å‡ºé»„é‡‘æ¨¡æ¿æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
        
        Returns:
            JSONå­—ç¬¦ä¸²
        """
        import json
        export_data = {
            'golden_templates': self.golden_templates,
            'template_usage_stats': dict(self.template_usage_stats),
            'template_match_history': self.template_match_history[-50:],  # åªå¯¼å‡ºæœ€è¿‘50æ¡åŒ¹é…å†å²
            'export_timestamp': time.time(),
            'config': self.golden_template_config
        }
        
        return json.dumps(export_data, indent=2, ensure_ascii=False)
    
    def import_golden_templates(self, json_data: str) -> bool:
        """
        å¯¼å…¥é»„é‡‘æ¨¡æ¿æ•°æ®
        
        Args:
            json_data: JSONå­—ç¬¦ä¸²
            
        Returns:
            æ˜¯å¦æˆåŠŸå¯¼å…¥
        """
        try:
            import json
            data = json.loads(json_data)
            
            # éªŒè¯æ•°æ®æ ¼å¼
            if 'golden_templates' not in data:
                logger.error("âŒ å¯¼å…¥æ•°æ®æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘golden_templateså­—æ®µ")
                return False
            
            # å¯¼å…¥æ¨¡æ¿
            imported_count = 0
            for template_id, template_data in data['golden_templates'].items():
                if len(self.golden_templates) < self.golden_template_config['max_golden_templates']:
                    self.golden_templates[template_id] = template_data
                    imported_count += 1
                else:
                    break
            
            # å¯¼å…¥ä½¿ç”¨ç»Ÿè®¡
            if 'template_usage_stats' in data:
                for template_id, count in data['template_usage_stats'].items():
                    if template_id in self.golden_templates:
                        self.template_usage_stats[template_id] = count
            
            logger.info(f"âœ… æˆåŠŸå¯¼å…¥ {imported_count} ä¸ªé»„é‡‘æ¨¡æ¿")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å…¥é»„é‡‘æ¨¡æ¿å¤±è´¥: {e}")
            return False
    
    # ==================== ğŸ† é»„é‡‘æ¨¡æ¿ä½¿ç”¨ç¤ºä¾‹ ====================
    
    def demo_golden_template_workflow(self):
        """
        æ¼”ç¤ºé»„é‡‘æ¨¡æ¿ç³»ç»Ÿçš„å®Œæ•´å·¥ä½œæµç¨‹
        
        è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–¹æ³•ï¼Œå±•ç¤ºäº†é»„é‡‘æ¨¡æ¿ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½
        """
        logger.info("ğŸ† å¼€å§‹é»„é‡‘æ¨¡æ¿ç³»ç»Ÿæ¼”ç¤º")
        
        # 1. æ˜¾ç¤ºå½“å‰çŠ¶æ€
        stats = self.get_golden_template_stats()
        logger.info(f"å½“å‰é»„é‡‘æ¨¡æ¿æ•°é‡: {stats['total_templates']}")
        
        # 2. æ˜¾ç¤ºé…ç½®
        config = self.golden_template_config
        logger.info(f"é»„é‡‘æ¨¡æ¿é…ç½®:")
        logger.info(f"  - æˆåŠŸç‡é˜ˆå€¼: {config['success_rate_threshold']:.1%}")
        logger.info(f"  - æœ€å°æ ·æœ¬æ•°: {config['min_samples_required']}")
        logger.info(f"  - æœ€å¤§æ¨¡æ¿æ•°: {config['max_golden_templates']}")
        
        # 3. æ˜¾ç¤ºç°æœ‰é»„é‡‘æ¨¡æ¿
        if self.golden_templates:
            logger.info("ğŸ† ç°æœ‰é»„é‡‘æ¨¡æ¿:")
            for template_id, template_data in self.golden_templates.items():
                logger.info(f"  - {template_id}: {template_data['path_type']} "
                           f"(æˆåŠŸç‡: {template_data['success_rate']:.1%}, "
                           f"ä½¿ç”¨æ¬¡æ•°: {self.template_usage_stats.get(template_id, 0)})")
        else:
            logger.info("ğŸ“ æš‚æ— é»„é‡‘æ¨¡æ¿")
        
        # 4. æ˜¾ç¤ºå€™é€‰è·¯å¾„
        candidate_paths = []
        for path_id, arm in self.path_arms.items():
            if self._check_golden_criteria(arm) and path_id not in self.golden_templates:
                candidate_paths.append((path_id, arm))
        
        if candidate_paths:
            logger.info("â­ ç¬¦åˆé»„é‡‘æ¨¡æ¿æ¡ä»¶çš„å€™é€‰è·¯å¾„:")
            for path_id, arm in candidate_paths:
                stability = self._calculate_stability_score(arm)
                logger.info(f"  - {path_id}: {arm.option} "
                           f"(æˆåŠŸç‡: {arm.success_rate:.1%}, "
                           f"æ ·æœ¬: {arm.activation_count}, "
                           f"ç¨³å®šæ€§: {stability:.2f})")
        else:
            logger.info("ğŸ“ æš‚æ— ç¬¦åˆæ¡ä»¶çš„å€™é€‰è·¯å¾„")
        
        logger.info("ğŸ† é»„é‡‘æ¨¡æ¿ç³»ç»Ÿæ¼”ç¤ºå®Œæˆ")
    
    # ==================== ğŸ’¡ Aha-Momentå†³ç­–æ”¯æŒç³»ç»Ÿ ====================
    
    def get_path_confidence(self, strategy_id: str) -> float:
        """
        è·å–æŒ‡å®šç­–ç•¥çš„ç½®ä¿¡åº¦åˆ†æ•°
        
        Args:
            strategy_id: ç­–ç•¥IDï¼ˆæ³¨æ„ï¼šè¿™é‡Œåº”è¯¥ä¼ é€’strategy_idè€Œä¸æ˜¯path_idå®ä¾‹IDï¼‰
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•° (0.0-1.0)ï¼Œ1.0è¡¨ç¤ºéå¸¸æœ‰ä¿¡å¿ƒï¼Œ0.0è¡¨ç¤ºå®Œå…¨æ²¡æœ‰ä¿¡å¿ƒ
        """
        # ğŸ”§ åŠ¨æ€åˆ›å»ºï¼šå¦‚æœç­–ç•¥ä¸å­˜åœ¨ï¼Œåˆ™åŠ¨æ€åˆ›å»ºï¼ˆç½®ä¿¡åº¦ä¸ºæœ€ä½ï¼‰
        arm = self._create_strategy_arm_if_missing(strategy_id)
        
        # å¦‚æœæ ·æœ¬æ•°ä¸è¶³ï¼Œç½®ä¿¡åº¦è¾ƒä½
        if arm.activation_count < 5:
            base_confidence = 0.2  # åŸºç¡€ä¿¡å¿ƒå¾ˆä½
        elif arm.activation_count < 10:
            base_confidence = 0.4
        elif arm.activation_count < 20:
            base_confidence = 0.6
        else:
            base_confidence = 0.8  # å……è¶³æ ·æœ¬çš„åŸºç¡€ä¿¡å¿ƒ
        
        # åŸºäºæˆåŠŸç‡è°ƒæ•´ç½®ä¿¡åº¦
        success_factor = arm.success_rate
        
        # åŸºäºç¨³å®šæ€§è°ƒæ•´ç½®ä¿¡åº¦
        stability_factor = self._calculate_stability_score(arm) if arm.activation_count >= 10 else 0.5
        
        # åŸºäºæœ€è¿‘è¡¨ç°è°ƒæ•´ç½®ä¿¡åº¦
        recent_performance_factor = self._calculate_recent_performance_factor(arm)
        
        # ç»¼åˆè®¡ç®—ç½®ä¿¡åº¦
        confidence = (
            base_confidence * 0.3 +          # æ ·æœ¬é‡è´¡çŒ®30%
            success_factor * 0.4 +           # æˆåŠŸç‡è´¡çŒ®40%
            stability_factor * 0.2 +         # ç¨³å®šæ€§è´¡çŒ®20%
            recent_performance_factor * 0.1  # æœ€è¿‘è¡¨ç°è´¡çŒ®10%
        )
        
        return min(max(confidence, 0.0), 1.0)  # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…
    
    def _calculate_recent_performance_factor(self, arm: EnhancedDecisionArm) -> float:
        """
        è®¡ç®—æœ€è¿‘è¡¨ç°å› å­
        
        Args:
            arm: å†³ç­–è‡‚å¯¹è±¡
            
        Returns:
            æœ€è¿‘è¡¨ç°å› å­ (0.0-1.0)
        """
        if not arm.recent_results or len(arm.recent_results) < 3:
            return 0.5  # é»˜è®¤ä¸­ç­‰
        
        # è®¡ç®—æœ€è¿‘5æ¬¡çš„æˆåŠŸç‡
        recent_window = arm.recent_results[-5:]
        recent_success_rate = sum(recent_window) / len(recent_window)
        
        return recent_success_rate
    
    def get_all_paths_confidence(self) -> Dict[str, float]:
        """
        è·å–æ‰€æœ‰è·¯å¾„çš„ç½®ä¿¡åº¦
        
        Returns:
            è·¯å¾„IDåˆ°ç½®ä¿¡åº¦çš„æ˜ å°„
        """
        confidence_map = {}
        for path_id in self.path_arms.keys():
            confidence_map[path_id] = self.get_path_confidence(path_id)
        
        return confidence_map
    
    def check_low_confidence_scenario(self, threshold: float = 0.3) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å¤„äºä½ç½®ä¿¡åº¦åœºæ™¯ï¼ˆæ‰€æœ‰è·¯å¾„è¡¨ç°éƒ½å¾ˆå·®ï¼‰
        
        Args:
            threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è®¤ä¸ºæ˜¯ä½ç½®ä¿¡åº¦
            
        Returns:
            æ˜¯å¦æ‰€æœ‰è·¯å¾„éƒ½å¤„äºä½ç½®ä¿¡åº¦çŠ¶æ€
        """
        if not self.path_arms:
            return True  # æ²¡æœ‰è·¯å¾„æ•°æ®ï¼Œè®¤ä¸ºæ˜¯ä½ç½®ä¿¡åº¦åœºæ™¯
        
        confidence_scores = self.get_all_paths_confidence()
        
        if not confidence_scores:
            return True
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è·¯å¾„çš„ç½®ä¿¡åº¦éƒ½ä½äºé˜ˆå€¼
        max_confidence = max(confidence_scores.values())
        avg_confidence = sum(confidence_scores.values()) / len(confidence_scores)
        
        logger.debug(f"ğŸ’¡ ç½®ä¿¡åº¦æ£€æŸ¥: æœ€é«˜ç½®ä¿¡åº¦={max_confidence:.3f}, å¹³å‡ç½®ä¿¡åº¦={avg_confidence:.3f}, é˜ˆå€¼={threshold}")
        
        # å¦‚æœæœ€é«˜ç½®ä¿¡åº¦éƒ½ä½äºé˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºéœ€è¦ç»•é“æ€è€ƒ
        return max_confidence < threshold
    
    def get_confidence_analysis(self) -> Dict[str, any]:
        """
        è·å–ç½®ä¿¡åº¦åˆ†ææŠ¥å‘Š
        
        Returns:
            ç½®ä¿¡åº¦åˆ†ææ•°æ®
        """
        confidence_scores = self.get_all_paths_confidence()
        
        if not confidence_scores:
            return {
                'total_paths': 0,
                'max_confidence': 0.0,
                'min_confidence': 0.0,
                'avg_confidence': 0.0,
                'low_confidence_paths': 0,
                'high_confidence_paths': 0,
                'confidence_distribution': {}
            }
        
        values = list(confidence_scores.values())
        low_confidence_count = sum(1 for conf in values if conf < 0.3)
        high_confidence_count = sum(1 for conf in values if conf > 0.7)
        
        # ç½®ä¿¡åº¦åˆ†å¸ƒç»Ÿè®¡
        distribution = {
            'very_low (0.0-0.2)': sum(1 for conf in values if 0.0 <= conf < 0.2),
            'low (0.2-0.4)': sum(1 for conf in values if 0.2 <= conf < 0.4),
            'medium (0.4-0.6)': sum(1 for conf in values if 0.4 <= conf < 0.6),
            'high (0.6-0.8)': sum(1 for conf in values if 0.6 <= conf < 0.8),
            'very_high (0.8-1.0)': sum(1 for conf in values if 0.8 <= conf <= 1.0)
        }
        
        return {
            'total_paths': len(confidence_scores),
            'max_confidence': max(values),
            'min_confidence': min(values),
            'avg_confidence': sum(values) / len(values),
            'low_confidence_paths': low_confidence_count,
            'high_confidence_paths': high_confidence_count,
            'confidence_distribution': distribution,
            'detailed_scores': confidence_scores
        }
    
    # ==================== ğŸ”§ è¾…åŠ©è®¡ç®—æ–¹æ³• ====================
    
    def _calculate_recent_trend(self, arm: EnhancedDecisionArm) -> str:
        """
        è®¡ç®—è·¯å¾„çš„æœ€è¿‘æ€§èƒ½è¶‹åŠ¿
        
        Args:
            arm: å†³ç­–è‡‚å¯¹è±¡
            
        Returns:
            è¶‹åŠ¿å­—ç¬¦ä¸²: 'improving', 'declining', 'stable', 'insufficient_data'
        """
        if len(arm.recent_results) < 4:
            return 'insufficient_data'
        
        # å–æœ€è¿‘çš„ç»“æœï¼Œåˆ†ä¸ºä¸¤åŠè¿›è¡Œæ¯”è¾ƒ
        recent = arm.recent_results[-10:] if len(arm.recent_results) >= 10 else arm.recent_results
        mid_point = len(recent) // 2
        
        if mid_point < 2:
            return 'insufficient_data'
        
        # è®¡ç®—å‰åŠæ®µå’ŒååŠæ®µçš„æˆåŠŸç‡
        earlier_half = recent[:mid_point]
        later_half = recent[mid_point:]
        
        earlier_rate = sum(earlier_half) / len(earlier_half)
        later_rate = sum(later_half) / len(later_half)
        
        # åˆ¤æ–­è¶‹åŠ¿
        if later_rate > earlier_rate + 0.1:  # 10%çš„æ”¹å–„è§†ä¸ºimproving
            return 'improving'
        elif later_rate < earlier_rate - 0.1:  # 10%çš„ä¸‹é™è§†ä¸ºdeclining
            return 'declining'
        else:
            return 'stable'
    
    def _calculate_consecutive_successes(self, arm: EnhancedDecisionArm) -> int:
        """
        è®¡ç®—è¿ç»­æˆåŠŸæ¬¡æ•°
        
        Args:
            arm: å†³ç­–è‡‚å¯¹è±¡
            
        Returns:
            è¿ç»­æˆåŠŸæ¬¡æ•°
        """
        if not arm.recent_results:
            return 0
        
        consecutive_count = 0
        # ä»æœ€è¿‘çš„ç»“æœå¼€å§‹å¾€å‰æ•°
        for result in reversed(arm.recent_results):
            if result:  # å¦‚æœæ˜¯æˆåŠŸ
                consecutive_count += 1
            else:  # å¦‚æœå¤±è´¥äº†ï¼Œå°±åœæ­¢è®¡æ•°
                break
        
        return consecutive_count
    
    # ==================== ğŸ¯ æ ¹æºä¿®å¤å®Œæˆï¼šç§»é™¤å¤æ‚è§£æé€»è¾‘ ====================
    # æ³¨æ„ï¼š_resolve_strategy_id æ–¹æ³•å·²ç§»é™¤ï¼Œå› ä¸ºæ•°æ®æºå¤´ç°åœ¨ç›´æ¥æä¾›æ­£ç¡®çš„ç­–ç•¥ID
    
    def _infer_path_type_from_strategy_id(self, strategy_id: str) -> str:
        """
        ä»ç­–ç•¥IDæ¨æ–­è·¯å¾„ç±»å‹
        
        Args:
            strategy_id: ç­–ç•¥ID
            
        Returns:
            æ¨æ–­çš„è·¯å¾„ç±»å‹
        """
        # ç­–ç•¥IDåˆ°è·¯å¾„ç±»å‹çš„æ˜ å°„è¡¨
        strategy_to_type_mapping = {
            'systematic_analytical': 'ç³»ç»Ÿåˆ†æå‹',
            'creative_innovative': 'åˆ›æ–°çªç ´å‹',
            'critical_questioning': 'æ‰¹åˆ¤è´¨ç–‘å‹',
            'practical_pragmatic': 'å®ç”¨åŠ¡å®å‹',
            'holistic_comprehensive': 'æ•´ä½“ç»¼åˆå‹',
            'exploratory_investigative': 'æ¢ç´¢è°ƒç ”å‹',
            'collaborative_consultative': 'åä½œå’¨è¯¢å‹',
            'adaptive_flexible': 'é€‚åº”çµæ´»å‹',
            
            # å…¼å®¹æ€§æ˜ å°„ï¼ˆä¸­æ–‡è·¯å¾„ç±»å‹ï¼‰
            'ç³»ç»Ÿåˆ†æ': 'ç³»ç»Ÿåˆ†æå‹',
            'åˆ›æ–°çªç ´': 'åˆ›æ–°çªç ´å‹',
            'æ‰¹åˆ¤è´¨ç–‘': 'æ‰¹åˆ¤è´¨ç–‘å‹',
            'å®ç”¨åŠ¡å®': 'å®ç”¨åŠ¡å®å‹',
            'æ•´ä½“ç»¼åˆ': 'æ•´ä½“ç»¼åˆå‹',
            'æ¢ç´¢è°ƒç ”': 'æ¢ç´¢è°ƒç ”å‹',
            'åä½œå’¨è¯¢': 'åä½œå’¨è¯¢å‹',
            'é€‚åº”çµæ´»': 'é€‚åº”çµæ´»å‹'
        }
        
        # ç›´æ¥åŒ¹é…
        if strategy_id in strategy_to_type_mapping:
            return strategy_to_type_mapping[strategy_id]
        
        # æ¨¡ç³ŠåŒ¹é…
        strategy_lower = strategy_id.lower()
        for key, value in strategy_to_type_mapping.items():
            if key.lower() in strategy_lower or strategy_lower in key.lower():
                logger.debug(f"ğŸ” æ¨¡ç³ŠåŒ¹é…ç­–ç•¥ç±»å‹: {strategy_id} -> {value}")
                return value
        
        # åŸºäºå…³é”®è¯æ¨æ–­
        if 'systematic' in strategy_lower or 'analytical' in strategy_lower or 'ç³»ç»Ÿ' in strategy_id:
            return 'ç³»ç»Ÿåˆ†æå‹'
        elif 'creative' in strategy_lower or 'innovative' in strategy_lower or 'åˆ›æ–°' in strategy_id:
            return 'åˆ›æ–°çªç ´å‹'
        elif 'critical' in strategy_lower or 'questioning' in strategy_lower or 'æ‰¹åˆ¤' in strategy_id:
            return 'æ‰¹åˆ¤è´¨ç–‘å‹'
        elif 'practical' in strategy_lower or 'pragmatic' in strategy_lower or 'å®ç”¨' in strategy_id:
            return 'å®ç”¨åŠ¡å®å‹'
        elif 'holistic' in strategy_lower or 'comprehensive' in strategy_lower or 'æ•´ä½“' in strategy_id:
            return 'æ•´ä½“ç»¼åˆå‹'
        elif 'exploratory' in strategy_lower or 'investigative' in strategy_lower or 'æ¢ç´¢' in strategy_id:
            return 'æ¢ç´¢è°ƒç ”å‹'
        elif 'collaborative' in strategy_lower or 'consultative' in strategy_lower or 'åä½œ' in strategy_id:
            return 'åä½œå’¨è¯¢å‹'
        elif 'adaptive' in strategy_lower or 'flexible' in strategy_lower or 'é€‚åº”' in strategy_id:
            return 'é€‚åº”çµæ´»å‹'
        
        # é»˜è®¤è¿”å›
        logger.debug(f"âš ï¸ æ— æ³•æ¨æ–­è·¯å¾„ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤: {strategy_id} -> é€šç”¨æ–¹æ³•å‹")
        return 'é€šç”¨æ–¹æ³•å‹'


# ğŸ”„ å‘åå…¼å®¹æ€§ï¼šä¿æŒåŸæœ‰çš„MABConvergerç±»å
MABConverger = ContextualMABConverger

# ä¸ºäº†å®Œå…¨å‘åå…¼å®¹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥åˆ›å»ºä¸€ä¸ªç®€å•çš„å·¥å‚å‡½æ•°
def create_mab_converger(algorithm: str = "linucb", **kwargs) -> ContextualMABConverger:
    """
    åˆ›å»ºMABæ”¶æ•›å™¨çš„å·¥å‚å‡½æ•°
    
    Args:
        algorithm: ä½¿ç”¨çš„ç®—æ³•
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        ContextualMABConvergerå®ä¾‹
    """
    return ContextualMABConverger(algorithm=algorithm, **kwargs)
