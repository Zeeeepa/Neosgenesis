#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å·¥ä½œæµç”Ÿæˆä»£ç† - ä¸“æ³¨äº"å†³å®šæ€ä¹ˆåš"çš„æˆ˜æœ¯è§„åˆ’å™¨
é‡æ„åçš„æ¶æ„å°†æˆ˜æœ¯è§„åˆ’èŒè´£ä»NeogenesisPlannerä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå½¢æˆä¸“é—¨çš„WorkflowGenerationAgent

æ ¸å¿ƒèŒè´£:
1. æ¥æ”¶æˆ˜ç•¥å†³ç­–ç»“æœï¼ˆStrategyDecisionï¼‰
2. å°†æŠ½è±¡çš„ReasoningPathè½¬åŒ–ä¸ºå…·ä½“çš„Actionåºåˆ—
3. æ™ºèƒ½å·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆ
4. è¾“å‡ºå¯æ‰§è¡Œçš„Planå¯¹è±¡

è®¾è®¡åŸåˆ™:
- ä¸¥æ ¼éµå¾ªabstractions.pyä¸­çš„BaseAgentå’ŒBasePlanneræ¥å£è§„èŒƒ
- èŒè´£å•ä¸€ï¼šä¸“æ³¨äºæˆ˜æœ¯å±‚é¢çš„"å¦‚ä½•æ‰§è¡Œ"
- ä¸æˆ˜ç•¥è§„åˆ’å™¨è§£è€¦ï¼šé€šè¿‡StrategyDecisionè¿›è¡Œé€šä¿¡
- å¯æ’æ‹”è®¾è®¡ï¼šæ”¯æŒä¸åŒçš„å·¥å…·æ‰§è¡Œå™¨å’Œè®°å¿†æ¨¡å—
"""

import time
import logging
from typing import Dict, List, Optional, Any, Union

# å¯¼å…¥æ¡†æ¶æ ¸å¿ƒæ¥å£
try:
    from ..abstractions import BaseAgent, BasePlanner, BaseToolExecutor, BaseAsyncToolExecutor, BaseMemory
    from ..shared.data_structures import Plan, Action, Observation, ExecutionContext, AgentState
except ImportError:
    from neogenesis_system.abstractions import BaseAgent, BasePlanner, BaseToolExecutor, BaseAsyncToolExecutor, BaseMemory
    from neogenesis_system.shared.data_structures import Plan, Action, Observation, ExecutionContext, AgentState

# å¯¼å…¥æˆ˜ç•¥å†³ç­–æ•°æ®ç»“æ„
try:
    from ..shared.data_structures import StrategyDecision
    from ..cognitive_engine.data_structures import ReasoningPath
except ImportError:
    from neogenesis_system.shared.data_structures import StrategyDecision
    from neogenesis_system.cognitive_engine.data_structures import ReasoningPath

# å¯¼å…¥å·¥å…·ç³»ç»Ÿ
from ..tools.tool_abstraction import ToolRegistry, global_tool_registry

logger = logging.getLogger(__name__)


class WorkflowPlanner(BasePlanner):
    """
    å·¥ä½œæµè§„åˆ’å™¨ - ä¸“é—¨çš„æˆ˜æœ¯è§„åˆ’å™¨
    
    ä¸“æ³¨äºå°†æŠ½è±¡çš„æˆ˜ç•¥å†³ç­–è½¬æ¢ä¸ºå…·ä½“çš„æ‰§è¡Œè®¡åˆ’ã€‚
    è¿™æ˜¯è¿æ¥æŠ½è±¡æ€ç»´å’Œå…·ä½“è¡ŒåŠ¨çš„å…³é”®ç»„ä»¶ã€‚
    
    æ ¸å¿ƒèƒ½åŠ›:
    1. StrategyDecisionåˆ°Plançš„æ™ºèƒ½è½¬æ¢
    2. åŸºäºè·¯å¾„ç±»å‹çš„å·¥å…·é€‰æ‹©ç­–ç•¥
    3. æ™ºèƒ½å‚æ•°ç”Ÿæˆå’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥
    4. LLMè¾…åŠ©çš„å†³ç­–ä¼˜åŒ–
    """
    
    def __init__(self, 
                 tool_registry: Optional[ToolRegistry] = None,
                 config: Optional[Dict] = None,
                 name: str = "WorkflowPlanner",
                 description: str = "å°†æˆ˜ç•¥å†³ç­–è½¬åŒ–ä¸ºå…·ä½“æ‰§è¡Œè®¡åˆ’çš„æˆ˜æœ¯è§„åˆ’å™¨"):
        """
        åˆå§‹åŒ–å·¥ä½œæµè§„åˆ’å™¨
        
        Args:
            tool_registry: å·¥å…·æ³¨å†Œè¡¨ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€æ³¨å†Œè¡¨
            config: é…ç½®å­—å…¸
            name: è§„åˆ’å™¨åç§°
            description: è§„åˆ’å™¨æè¿°
        """
        super().__init__(name=name, description=description)
        
        self.tool_registry = tool_registry or global_tool_registry
        self.config = config or {}
        
        # æˆ˜ç•¥è·¯å¾„åˆ°è¡ŒåŠ¨çš„æ˜ å°„è§„åˆ™
        self.strategy_to_action_rules = {
            'exploratory_investigative': self._handle_exploratory_strategy,
            'critical_questioning': self._handle_critical_strategy,
            'systematic_analytical': self._handle_analytical_strategy,
            'practical_pragmatic': self._handle_practical_strategy,
            'creative_innovative': self._handle_creative_strategy,
            'åˆ›æ–°ç»•é“æ€è€ƒ': self._handle_detour_strategy,
            'default': self._handle_default_strategy
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.conversion_stats = {
            'total_conversions': 0,
            'successful_conversions': 0,
            'direct_answer_rate': 0.0,
            'avg_action_count': 0.0,
            'strategy_type_distribution': {}
        }
        
        logger.info(f"ğŸ”§ WorkflowPlanner åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ”¯æŒç­–ç•¥ç±»å‹: {len(self.strategy_to_action_rules)} ç§")
        
    def create_plan(self, query: str, memory: Any, context: Optional[Dict[str, Any]] = None) -> Plan:
        """
        åŸºäºæˆ˜ç•¥å†³ç­–åˆ›å»ºå…·ä½“æ‰§è¡Œè®¡åˆ’ - å®ç°BasePlanneræ¥å£
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆä¸»è¦ç”¨äºå…¼å®¹æ¥å£ï¼‰
            memory: Agentè®°å¿†æ¨¡å—
            context: æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œå¿…é¡»åŒ…å«'strategy_decision'å­—æ®µ
            
        Returns:
            Plan: å…·ä½“çš„æ‰§è¡Œè®¡åˆ’
            
        Raises:
            ValueError: å½“ç¼ºå°‘å¿…è¦çš„æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡æ—¶
        """
        start_time = time.time()
        self.conversion_stats['total_conversions'] += 1
        
        logger.info(f"ğŸ”§ å¼€å§‹æˆ˜æœ¯è§„åˆ’: æŸ¥è¯¢='{query[:50]}...'")
        
        # éªŒè¯è¾“å…¥
        if not context or 'strategy_decision' not in context:
            error_msg = "WorkflowPlanneréœ€è¦æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡æ‰èƒ½ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"
            logger.error(f"âŒ {error_msg}")
            return self._create_error_plan(query, error_msg)
        
        strategy_decision: StrategyDecision = context['strategy_decision']
        
        try:
            # ğŸ¯ æ ¸å¿ƒè½¬æ¢ï¼šä»StrategyDecisionåˆ°Plan
            plan = self._convert_strategy_to_workflow_plan(strategy_decision, query, memory)
            
            # ğŸ“Š æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            execution_time = time.time() - start_time
            self._update_conversion_stats(plan, strategy_decision, execution_time, success=True)
            
            logger.info(f"âœ… æˆ˜æœ¯è§„åˆ’å®Œæˆ: {plan.action_count} ä¸ªè¡ŒåŠ¨, è€—æ—¶ {execution_time:.3f}s")
            return plan
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_conversion_stats(None, strategy_decision, execution_time, success=False)
            
            logger.error(f"âŒ æˆ˜æœ¯è§„åˆ’å¤±è´¥: {e}")
            return self._create_error_plan(query, f"æˆ˜æœ¯è§„åˆ’è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
    
    def validate_plan(self, plan: Plan) -> bool:
        """
        éªŒè¯è®¡åˆ’çš„æœ‰æ•ˆæ€§ - å®ç°BasePlanneræ¥å£
        
        Args:
            plan: è¦éªŒè¯çš„è®¡åˆ’
            
        Returns:
            bool: è®¡åˆ’æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not plan.thought:
                logger.warning("âš ï¸ è®¡åˆ’ç¼ºå°‘æ€è€ƒè¿‡ç¨‹")
                return False
            
            # ç›´æ¥å›ç­”æ¨¡å¼éªŒè¯
            if plan.is_direct_answer:
                is_valid = plan.final_answer is not None and len(plan.final_answer.strip()) > 0
                if not is_valid:
                    logger.warning("âš ï¸ ç›´æ¥å›ç­”æ¨¡å¼ä¸‹ç¼ºå°‘æœ‰æ•ˆç­”æ¡ˆ")
                return is_valid
            
            # å·¥å…·æ‰§è¡Œæ¨¡å¼éªŒè¯
            if not plan.actions:
                logger.warning("âš ï¸ å·¥å…·æ‰§è¡Œæ¨¡å¼ä¸‹ç¼ºå°‘è¡ŒåŠ¨åˆ—è¡¨")
                return False
            
            # éªŒè¯æ‰€æœ‰è¡ŒåŠ¨
            for i, action in enumerate(plan.actions):
                if not action.tool_name or not isinstance(action.tool_input, dict):
                    logger.warning(f"âš ï¸ è¡ŒåŠ¨ {i} ç¼ºå°‘æœ‰æ•ˆçš„å·¥å…·åç§°æˆ–è¾“å…¥å‚æ•°")
                    return False
                
                # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœæœ‰å·¥å…·æ³¨å†Œè¡¨ï¼‰
                if (self.tool_registry and 
                    hasattr(self.tool_registry, 'has_tool') and 
                    not self.tool_registry.has_tool(action.tool_name)):
                    logger.warning(f"âš ï¸ è¡ŒåŠ¨ {i} ä½¿ç”¨çš„å·¥å…· '{action.tool_name}' æœªåœ¨æ³¨å†Œè¡¨ä¸­æ‰¾åˆ°")
                    return False
            
            logger.debug(f"âœ… è®¡åˆ’éªŒè¯é€šè¿‡: {plan.action_count} ä¸ªè¡ŒåŠ¨")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è®¡åˆ’éªŒè¯å¤±è´¥: {e}")
            return False
    
    def estimate_complexity(self, query: str, context: Optional[Dict[str, Any]] = None) -> float:
        """
        ä¼°ç®—ä»»åŠ¡å¤æ‚åº¦ - é‡å†™BasePlanneræ–¹æ³•
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            float: å¤æ‚åº¦åˆ†æ•° (0.0-1.0)
        """
        if not context or 'strategy_decision' not in context:
            return 0.5  # é»˜è®¤ä¸­ç­‰å¤æ‚åº¦
        
        strategy_decision: StrategyDecision = context['strategy_decision']
        
        # åŸºäºæˆ˜ç•¥å†³ç­–ä¿¡æ¯ä¼°ç®—å¤æ‚åº¦
        complexity_factors = []
        
        # å› å­1ï¼šè·¯å¾„éªŒè¯ç»Ÿè®¡
        verification_stats = strategy_decision.verification_stats
        feasible_ratio = verification_stats.get('feasible_paths', 0) / max(verification_stats.get('paths_verified', 1), 1)
        complexity_factors.append(1.0 - feasible_ratio)  # å¯è¡Œè·¯å¾„è¶Šå°‘ï¼Œå¤æ‚åº¦è¶Šé«˜
        
        # å› å­2ï¼šæŸ¥è¯¢é•¿åº¦
        query_complexity = min(len(query) / 200.0, 1.0)  # æŸ¥è¯¢è¶Šé•¿ï¼Œå¤æ‚åº¦å¯èƒ½è¶Šé«˜
        complexity_factors.append(query_complexity)
        
        # å› å­3ï¼šç­–ç•¥ç±»å‹
        strategy_type_complexity = {
            'exploratory_investigative': 0.7,
            'critical_questioning': 0.8,
            'systematic_analytical': 0.9,
            'creative_innovative': 0.6,
            'practical_pragmatic': 0.3,
            'åˆ›æ–°ç»•é“æ€è€ƒ': 0.5
        }
        path_type = strategy_decision.chosen_path.path_type
        strategy_complexity = strategy_type_complexity.get(path_type, 0.5)
        complexity_factors.append(strategy_complexity)
        
        # è®¡ç®—å¹³å‡å¤æ‚åº¦
        estimated_complexity = sum(complexity_factors) / len(complexity_factors)
        
        logger.debug(f"ğŸ” å¤æ‚åº¦ä¼°ç®—: {estimated_complexity:.2f} (åŸºäº {len(complexity_factors)} ä¸ªå› å­)")
        return estimated_complexity
    
    def can_handle(self, query: str, context: Optional[Dict[str, Any]] = None) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯¥æŸ¥è¯¢ - é‡å†™BasePlanneræ–¹æ³•
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            bool: æ˜¯å¦èƒ½å¤„ç†
        """
        # WorkflowPlanneréœ€è¦æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡æ‰èƒ½å·¥ä½œ
        if not context or 'strategy_decision' not in context:
            return False
        
        try:
            strategy_decision: StrategyDecision = context['strategy_decision']
            # æ£€æŸ¥æˆ˜ç•¥å†³ç­–æ˜¯å¦æœ‰æœ‰æ•ˆçš„é€‰ä¸­è·¯å¾„
            return (strategy_decision.chosen_path is not None and 
                   hasattr(strategy_decision.chosen_path, 'path_type'))
        except Exception as e:
            logger.warning(f"âš ï¸ æ£€æŸ¥å¤„ç†èƒ½åŠ›æ—¶å‡ºé”™: {e}")
            return False
    
    def _convert_strategy_to_workflow_plan(self, strategy_decision: StrategyDecision, 
                                         query: str, memory: Any) -> Plan:
        """
        æ ¸å¿ƒè½¬æ¢æ–¹æ³•ï¼šå°†StrategyDecisionè½¬æ¢ä¸ºPlan
        
        ğŸ”¥ é›†æˆäº†ä»NeogenesisPlannerè¿ç§»çš„LLMé©±åŠ¨å†³ç­–é€»è¾‘
        
        Args:
            strategy_decision: æˆ˜ç•¥å†³ç­–ç»“æœ
            query: ç”¨æˆ·æŸ¥è¯¢
            memory: Agentè®°å¿†
            
        Returns:
            Plan: å·¥ä½œæµæ‰§è¡Œè®¡åˆ’
        """
        chosen_path = strategy_decision.chosen_path
        thinking_seed = strategy_decision.thinking_seed
        
        # å¤„ç†æ–°çš„StrategyDecisionç»“æ„
        path_type = "unknown"
        if chosen_path:
            if isinstance(chosen_path, dict):
                path_type = chosen_path.get("path_type", "unknown")
            else:
                path_type = getattr(chosen_path, 'path_type', 'unknown')
        
        logger.info(f"ğŸ”„ å¼€å§‹ç­–ç•¥è½¬æ¢: {path_type}")
        
        # æ„å»ºæˆ˜æœ¯æ€è€ƒè¿‡ç¨‹
        tactical_thought_parts = [
            f"åŸºäºæˆ˜ç•¥å†³ç­–ï¼Œæˆ‘å°†é‡‡ç”¨'{path_type}'ç­–ç•¥",
            f"æˆ˜ç•¥æ¨ç†: {strategy_decision.final_reasoning}",
            f"ç½®ä¿¡åº¦: {strategy_decision.confidence_score:.3f}",
            f"ç°åœ¨è½¬åŒ–ä¸ºå…·ä½“æ‰§è¡Œè®¡åˆ’..."
        ]
        
        # æ·»åŠ é˜¶æ®µä¿¡æ¯æ‘˜è¦
        if strategy_decision.is_complete:
            tactical_thought_parts.append("âœ… å®Œæ•´äº”é˜¶æ®µå†³ç­–æµç¨‹å·²å®Œæˆ")
            if strategy_decision.stage1_context:
                tactical_thought_parts.append(f"æ€ç»´ç§å­: {strategy_decision.stage1_context.thinking_seed[:100]}...")
            if strategy_decision.stage3_context:
                tactical_thought_parts.append(f"ç”Ÿæˆè·¯å¾„æ•°: {strategy_decision.stage3_context.path_count}")
        else:
            tactical_thought_parts.append("âš ï¸ éƒ¨åˆ†å†³ç­–æµç¨‹ï¼Œä½¿ç”¨å¯ç”¨ä¿¡æ¯")
        
        tactical_thought = "\n".join(tactical_thought_parts)
        
        try:
            # ğŸ§  ä½¿ç”¨LLMä½œä¸ºæœ€ç»ˆæˆ˜æœ¯å†³ç­–å®˜ï¼ˆä»NeogenesisPlannerè¿ç§»çš„æ ¸å¿ƒé€»è¾‘ï¼‰
            llm_decision = self._llm_tactical_decision_maker(chosen_path, query, thinking_seed, strategy_decision)
            
            if llm_decision.get('needs_tools', False):
                # LLMåˆ¤æ–­éœ€è¦å·¥å…·ï¼Œä½¿ç”¨LLMæ¨èçš„è¡ŒåŠ¨
                actions = llm_decision.get('actions', [])
                if not actions:
                    # å¦‚æœLLMæ²¡æœ‰æä¾›å…·ä½“è¡ŒåŠ¨ï¼Œå›é€€åˆ°è§„åˆ™åˆ†æ
                    actions = self._analyze_path_actions(chosen_path, query, strategy_decision)
                
                if actions:
                    plan = Plan(
                        thought=llm_decision.get('explanation', tactical_thought),
                        actions=actions
                    )
                else:
                    # å³ä½¿LLMè¯´éœ€è¦å·¥å…·ï¼Œä½†æ²¡æœ‰æ‰¾åˆ°åˆé€‚å·¥å…·ï¼Œè¿”å›ç›´æ¥å›ç­”
                    plan = Plan(
                        thought=llm_decision.get('explanation', tactical_thought),
                        final_answer=llm_decision.get('direct_answer', "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°åˆé€‚çš„å·¥å…·æ¥å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚")
                    )
            else:
                # LLMåˆ¤æ–­ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥è¿”å›æ™ºèƒ½ç”Ÿæˆçš„å›ç­”
                plan = Plan(
                    thought=llm_decision.get('explanation', tactical_thought),
                    final_answer=llm_decision.get('direct_answer')
                )
            
            # æ·»åŠ å…ƒæ•°æ®
            plan.metadata.update({
                'workflow_generation': {
                    'strategy_decision_id': f"{strategy_decision.round_number}_{strategy_decision.timestamp}",
                    'chosen_strategy': chosen_path.path_type,
                    'conversion_method': 'llm_tactical_decision_maker',
                    'tactical_reasoning': llm_decision.get('explanation', ''),
                    'generation_timestamp': time.time(),
                    'llm_decision': llm_decision
                },
                'strategic_context': {
                    'thinking_seed': thinking_seed,
                    'verification_stats': strategy_decision.verification_stats,
                    'selection_algorithm': strategy_decision.selection_algorithm
                }
            })
            
            action_count = len(plan.actions) if plan.actions else 0
            answer_mode = "å·¥å…·æ‰§è¡Œ" if plan.actions else "ç›´æ¥å›ç­”"
            logger.info(f"ğŸ”„ LLMé©±åŠ¨æˆ˜æœ¯å†³ç­–å®Œæˆ: {answer_mode}, {action_count} ä¸ªè¡ŒåŠ¨ï¼Œç­–ç•¥ '{chosen_path.path_type}'")
            return plan
            
        except Exception as e:
            logger.error(f"âŒ LLMæˆ˜æœ¯å†³ç­–å¤±è´¥ï¼Œå›é€€åˆ°è§„åˆ™å¼•æ“: {e}")
            
            # å›é€€åˆ°åŸæœ‰çš„è§„åˆ™å¼•æ“
            path_type = chosen_path.path_type.lower()
            handler = self.strategy_to_action_rules.get(path_type, self.strategy_to_action_rules['default'])
            
            # è°ƒç”¨ç­–ç•¥å¤„ç†å™¨
            workflow_result = handler(chosen_path, query, strategy_decision, memory)
            
            # æ„å»ºæœ€ç»ˆè®¡åˆ’
            plan = Plan(
                thought=tactical_thought,
                actions=workflow_result.get('actions', []),
                final_answer=workflow_result.get('final_answer')
            )
            
            # æ·»åŠ å…ƒæ•°æ®
            plan.metadata.update({
                'workflow_generation': {
                    'strategy_decision_id': f"{strategy_decision.round_number}_{strategy_decision.timestamp}",
                    'chosen_strategy': chosen_path.path_type,
                    'conversion_method': handler.__name__ + '_fallback',
                    'tactical_reasoning': workflow_result.get('reasoning', ''),
                    'generation_timestamp': time.time(),
                    'fallback_reason': str(e)
                },
                'strategic_context': {
                    'thinking_seed': thinking_seed,
                    'verification_stats': strategy_decision.verification_stats,
                    'selection_algorithm': strategy_decision.selection_algorithm
                }
            })
            
            return plan
    
    # ç­–ç•¥å¤„ç†æ–¹æ³•ç»„
    def _handle_exploratory_strategy(self, path: ReasoningPath, query: str, 
                                   decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†æ¢ç´¢è°ƒç ”å‹ç­–ç•¥"""
        logger.debug("ğŸ” å¤„ç†æ¢ç´¢è°ƒç ”å‹ç­–ç•¥")
        
        # æ¢ç´¢å‹ç­–ç•¥é€šå¸¸éœ€è¦æœç´¢å·¥å…·
        actions = []
        
        # ç”Ÿæˆæœç´¢æŸ¥è¯¢
        search_query = self._optimize_search_query(query, "æ¢ç´¢", path.description)
        
        if self._tool_available("web_search"):
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": search_query}
            ))
        
        # å¦‚æœæœ‰çŸ¥è¯†æŸ¥è¯¢å·¥å…·ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨
        if self._tool_available("knowledge_query"):
            actions.append(Action(
                tool_name="knowledge_query", 
                tool_input={"query": query}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"æ¢ç´¢è°ƒç ”ç­–ç•¥: ä½¿ç”¨æœç´¢å·¥å…·è·å–ç›¸å…³ä¿¡æ¯",
            'final_answer': None if actions else f"åŸºäºæ¢ç´¢è°ƒç ”çš„è§’åº¦ï¼Œæˆ‘æ¥ä¸ºæ‚¨åˆ†æã€Œ{query}ã€è¿™ä¸ªé—®é¢˜..."
        }
    
    def _handle_critical_strategy(self, path: ReasoningPath, query: str, 
                                decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†æ‰¹åˆ¤è´¨ç–‘å‹ç­–ç•¥"""
        logger.debug("ğŸ”¬ å¤„ç†æ‰¹åˆ¤è´¨ç–‘å‹ç­–ç•¥")
        
        actions = []
        
        # æ‰¹åˆ¤å‹ç­–ç•¥å¯èƒ½éœ€è¦éªŒè¯å·¥å…·
        if self._tool_available("idea_verification"):
            verification_idea = f"å¯¹äº'{query}'è¿™ä¸ªé—®é¢˜çš„æ‰¹åˆ¤æ€§æ€è€ƒå’Œè´¨ç–‘åˆ†æ"
            actions.append(Action(
                tool_name="idea_verification",
                tool_input={"idea_text": verification_idea}
            ))
        
        # ä¹Ÿå¯èƒ½éœ€è¦æœç´¢ç›¸å…³çš„åå¯¹è§‚ç‚¹æˆ–äº‰è®®
        if self._tool_available("web_search"):
            critical_search = f"{query} äº‰è®® é—®é¢˜ ç¼ºç‚¹ é£é™©"
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": critical_search}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"æ‰¹åˆ¤è´¨ç–‘ç­–ç•¥: éªŒè¯æƒ³æ³•å¹¶æœç´¢æ½œåœ¨é—®é¢˜",
            'final_answer': None if actions else f"ä»æ‰¹åˆ¤æ€§è§’åº¦æ¥çœ‹ã€Œ{query}ã€ï¼Œæˆ‘éœ€è¦è€ƒè™‘ä»¥ä¸‹å‡ ä¸ªæ–¹é¢..."
        }
    
    def _handle_analytical_strategy(self, path: ReasoningPath, query: str, 
                                  decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†ç³»ç»Ÿåˆ†æå‹ç­–ç•¥"""
        logger.debug("ğŸ“Š å¤„ç†ç³»ç»Ÿåˆ†æå‹ç­–ç•¥")
        
        actions = []
        
        # ç³»ç»Ÿåˆ†æå¯èƒ½éœ€è¦å¤šç§ä¿¡æ¯æº
        if self._tool_available("web_search"):
            analytical_search = self._optimize_search_query(query, "åˆ†æ", "ç³»ç»Ÿæ€§ æ–¹æ³• æ­¥éª¤")
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": analytical_search}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"ç³»ç»Ÿåˆ†æç­–ç•¥: æ”¶é›†å…¨é¢ä¿¡æ¯è¿›è¡Œç»“æ„åŒ–åˆ†æ",
            'final_answer': None if actions else f"å¯¹ã€Œ{query}ã€è¿›è¡Œç³»ç»Ÿåˆ†æï¼Œæˆ‘å°†ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œ..."
        }
    
    def _handle_practical_strategy(self, path: ReasoningPath, query: str, 
                                 decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†å®ç”¨ç›´æ¥å‹ç­–ç•¥"""
        logger.debug("ğŸ¯ å¤„ç†å®ç”¨ç›´æ¥å‹ç­–ç•¥")
        
        # å®ç”¨å‹ç­–ç•¥é€šå¸¸ç›´æ¥å›ç­”ï¼Œä½†å¯èƒ½éœ€è¦å¿«é€ŸéªŒè¯
        query_lower = query.lower()
        
        # ç®€å•é—®å€™å’Œå¸¸è§é—®é¢˜ç›´æ¥å›ç­”
        if any(greeting in query_lower for greeting in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½']):
            return {
                'actions': [],
                'reasoning': "è¯†åˆ«ä¸ºé—®å€™è¯­ï¼Œç›´æ¥å‹å¥½å›åº”",
                'final_answer': "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"
            }
        
        if 'ä»‹ç»' in query_lower and ('è‡ªå·±' in query_lower or 'ä½ ' in query_lower):
            return {
                'actions': [],
                'reasoning': "è¯†åˆ«ä¸ºè‡ªæˆ‘ä»‹ç»è¯·æ±‚ï¼Œæä¾›åŠ©æ‰‹ä¿¡æ¯",
                'final_answer': "æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼ŒåŸºäºå…ˆè¿›çš„è®¤çŸ¥æ¶æ„è®¾è®¡ã€‚æˆ‘å…·å¤‡æˆ˜ç•¥å†³ç­–å’Œæˆ˜æœ¯è§„åˆ’çš„åŒé‡èƒ½åŠ›ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¿¡æ¯æœç´¢ã€é—®é¢˜åˆ†æã€åˆ›æ„æ€è€ƒç­‰å¤šç§ä»»åŠ¡ã€‚æˆ‘çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®ä¸åŒé—®é¢˜æ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„å¤„ç†ç­–ç•¥ã€‚"
            }
        
        # å…¶ä»–æƒ…å†µæä¾›å®ç”¨æ€§å›ç­”
        return {
            'actions': [],
            'reasoning': f"å®ç”¨ç›´æ¥ç­–ç•¥: åŸºäºç°æœ‰çŸ¥è¯†ç›´æ¥å›ç­”",
            'final_answer': f"åŸºäºå®ç”¨çš„è§’åº¦ï¼Œå¯¹äºã€Œ{query}ã€è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘è®¤ä¸º..."
        }
    
    def _handle_creative_strategy(self, path: ReasoningPath, query: str, 
                                decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†åˆ›æ–°åˆ›æ„å‹ç­–ç•¥"""
        logger.debug("ğŸ’¡ å¤„ç†åˆ›æ–°åˆ›æ„å‹ç­–ç•¥")
        
        # åˆ›æ„å‹ç­–ç•¥é€šå¸¸ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥å‘æŒ¥åˆ›é€ åŠ›
        return {
            'actions': [],
            'reasoning': f"åˆ›æ–°åˆ›æ„ç­–ç•¥: å‘æŒ¥åˆ›é€ æ€§æ€ç»´",
            'final_answer': f"è®©æˆ‘ä»¬ä»åˆ›æ–°çš„è§’åº¦æ¥æ€è€ƒã€Œ{query}ã€è¿™ä¸ªé—®é¢˜..."
        }
    
    def _handle_detour_strategy(self, path: ReasoningPath, query: str, 
                              decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†ç»•é“æ€è€ƒå‹ç­–ç•¥"""
        logger.debug("ğŸš€ å¤„ç†ç»•é“æ€è€ƒå‹ç­–ç•¥")
        
        # ç»•é“ç­–ç•¥éœ€è¦çªç ´å¸¸è§„ï¼Œå¯èƒ½éœ€è¦æœç´¢ä¸åŒè§’åº¦çš„ä¿¡æ¯
        actions = []
        
        if self._tool_available("web_search"):
            detour_search = f"{query} å¦ç±»è§’åº¦ ä¸åŒè§‚ç‚¹ æ–°é¢–æ–¹æ³•"
            actions.append(Action(
                tool_name="web_search", 
                tool_input={"query": detour_search}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"ç»•é“æ€è€ƒç­–ç•¥: å¯»æ‰¾éå¸¸è§„è§£å†³æ–¹æ¡ˆ",
            'final_answer': None if actions else f"è®©æˆ‘ç”¨ä¸åŒå¯»å¸¸çš„è§’åº¦æ¥æ€è€ƒã€Œ{query}ã€..."
        }
    
    def _handle_default_strategy(self, path: ReasoningPath, query: str, 
                               decision: StrategyDecision, memory: Any) -> Dict[str, Any]:
        """å¤„ç†é»˜è®¤/æœªçŸ¥ç­–ç•¥"""
        logger.debug("ğŸ”§ å¤„ç†é»˜è®¤ç­–ç•¥")
        
        # é»˜è®¤ç­–ç•¥ï¼šå°è¯•æœç´¢ï¼Œå¦‚æœä¸å¯ç”¨å°±ç›´æ¥å›ç­”
        actions = []
        
        if self._tool_available("web_search"):
            actions.append(Action(
                tool_name="web_search",
                tool_input={"query": query}
            ))
        
        return {
            'actions': actions,
            'reasoning': f"é»˜è®¤ç­–ç•¥å¤„ç†: {path.path_type}",
            'final_answer': None if actions else f"æˆ‘æ¥ä¸ºæ‚¨è§£ç­”ã€Œ{query}ã€è¿™ä¸ªé—®é¢˜..."
        }
    
    # å·¥å…·æ–¹æ³•ç»„
    def _tool_available(self, tool_name: str) -> bool:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
        try:
            if not self.tool_registry:
                return False
            
            if hasattr(self.tool_registry, 'has_tool'):
                return self.tool_registry.has_tool(tool_name)
            elif hasattr(self.tool_registry, 'tools'):
                return tool_name in self.tool_registry.tools
            elif hasattr(self.tool_registry, '_tools'):
                return tool_name in self.tool_registry._tools
            else:
                return False
        except Exception as e:
            logger.debug(f"æ£€æŸ¥å·¥å…·å¯ç”¨æ€§æ—¶å‡ºé”™: {e}")
            return False
    
    def _optimize_search_query(self, original_query: str, strategy_type: str, 
                             additional_keywords: str = "") -> str:
        """ä¼˜åŒ–æœç´¢æŸ¥è¯¢"""
        optimized_query = original_query
        
        if strategy_type == "æ¢ç´¢":
            optimized_query += f" {additional_keywords} è¯¦ç»†ä¿¡æ¯"
        elif strategy_type == "åˆ†æ":
            optimized_query += f" {additional_keywords} åˆ†æ ç ”ç©¶"
        elif additional_keywords:
            optimized_query += f" {additional_keywords}"
        
        return optimized_query.strip()
    
    def _update_conversion_stats(self, plan: Optional[Plan], strategy_decision: StrategyDecision, 
                               execution_time: float, success: bool):
        """æ›´æ–°è½¬æ¢ç»Ÿè®¡ä¿¡æ¯"""
        if success:
            self.conversion_stats['successful_conversions'] += 1
            
            if plan:
                # æ›´æ–°ç›´æ¥å›ç­”ç‡
                total = self.conversion_stats['total_conversions']
                current_direct_rate = self.conversion_stats['direct_answer_rate']
                is_direct = plan.is_direct_answer
                self.conversion_stats['direct_answer_rate'] = (current_direct_rate * (total - 1) + (1 if is_direct else 0)) / total
                
                # æ›´æ–°å¹³å‡è¡ŒåŠ¨æ•°é‡
                current_avg_actions = self.conversion_stats['avg_action_count']
                action_count = plan.action_count
                self.conversion_stats['avg_action_count'] = (current_avg_actions * (total - 1) + action_count) / total
        
        # æ›´æ–°ç­–ç•¥ç±»å‹åˆ†å¸ƒ
        strategy_type = strategy_decision.chosen_path.path_type
        if strategy_type not in self.conversion_stats['strategy_type_distribution']:
            self.conversion_stats['strategy_type_distribution'][strategy_type] = 0
        self.conversion_stats['strategy_type_distribution'][strategy_type] += 1
    
    def _create_error_plan(self, query: str, error_message: str) -> Plan:
        """åˆ›å»ºé”™è¯¯å¤„ç†è®¡åˆ’"""
        return Plan(
            thought=f"æˆ˜æœ¯è§„åˆ’è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {error_message}",
            final_answer=f"æŠ±æ­‰ï¼Œæˆ‘åœ¨åˆ¶å®šæ‰§è¡Œè®¡åˆ’æ—¶é‡åˆ°äº†é—®é¢˜: {error_message}"
        )
    
    def get_conversion_stats(self) -> Dict[str, Any]:
        """è·å–è½¬æ¢ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'planner_name': self.name,
            'conversion_stats': self.conversion_stats.copy(),
            'success_rate': (self.conversion_stats['successful_conversions'] / 
                           max(self.conversion_stats['total_conversions'], 1))
        }
    
    # ==================== ä»NeogenesisPlannerè¿ç§»çš„æˆ˜æœ¯è§„åˆ’æ–¹æ³• ====================
    
    def _llm_tactical_decision_maker(self, chosen_path: ReasoningPath, query: str, 
                                   thinking_seed: str, strategy_decision: StrategyDecision) -> Dict[str, Any]:
        """
        ğŸ§  LLMä½œä¸ºæˆ˜æœ¯å†³ç­–åˆ¶å®šè€…ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰
        
        è®©LLMæ‰®æ¼”"æˆ˜æœ¯å†³ç­–å®˜"çš„è§’è‰²ï¼Œæ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·ä»¥åŠç”Ÿæˆè‡ªç„¶å›ç­”ã€‚
        è¿™æ˜¯ä»NeogenesisPlannerè¿ç§»çš„æ ¸å¿ƒæˆ˜æœ¯é€»è¾‘ã€‚
        
        Args:
            chosen_path: é€‰ä¸­çš„æ€ç»´è·¯å¾„
            query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            thinking_seed: æ€ç»´ç§å­
            strategy_decision: å®Œæ•´æˆ˜ç•¥å†³ç­–ç»“æœ
            
        Returns:
            Dict[str, Any]: LLMçš„æˆ˜æœ¯å†³ç­–ç»“æœï¼ŒåŒ…å«ï¼š
            - needs_tools: bool - æ˜¯å¦éœ€è¦å·¥å…·
            - actions: List[Action] - æ¨èçš„è¡ŒåŠ¨ï¼ˆå¦‚æœéœ€è¦å·¥å…·ï¼‰
            - direct_answer: str - ç›´æ¥å›ç­”ï¼ˆå¦‚æœä¸éœ€è¦å·¥å…·ï¼‰
            - explanation: str - å†³ç­–è§£é‡Š
        """
        try:
            logger.info(f"ğŸ§  LLMæˆ˜æœ¯å†³ç­–å®˜å¼€å§‹å·¥ä½œ: æŸ¥è¯¢='{query[:50]}...', è·¯å¾„='{chosen_path.path_type}'")
            
            # ğŸ” æ”¶é›†å¯ç”¨å·¥å…·ä¿¡æ¯
            available_tools = self._get_available_tools_info()
            
            # ğŸ§  æ„å»ºLLMå†³ç­–æç¤º
            decision_prompt = self._build_llm_decision_prompt(
                user_query=query,
                chosen_path=chosen_path,
                thinking_seed=thinking_seed,
                available_tools=available_tools,
                strategy_context=strategy_decision
            )
            
            # ğŸš€ è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½å†³ç­–
            llm_response = self._call_llm_for_decision(decision_prompt)
            
            if llm_response:
                # ğŸ” è§£æLLMå“åº”
                parsed_decision = self._parse_llm_decision_response(llm_response, chosen_path, query)
                logger.info(f"âœ… LLMæˆ˜æœ¯å†³ç­–æˆåŠŸ: éœ€è¦å·¥å…·={parsed_decision.get('needs_tools')}")
                return parsed_decision
            else:
                logger.warning("âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½å›é€€ç­–ç•¥")
                
            # ğŸ”§ æ™ºèƒ½å›é€€ç­–ç•¥
            return self._intelligent_fallback_decision(chosen_path, query, thinking_seed, available_tools, strategy_decision)
            
        except Exception as e:
            logger.error(f"âŒ LLMæˆ˜æœ¯å†³ç­–å¤±è´¥: {e}")
            return self._emergency_fallback_decision(chosen_path, query, thinking_seed, strategy_decision)
    
    def _call_llm_for_decision(self, decision_prompt: str) -> Optional[str]:
        """è°ƒç”¨LLMè¿›è¡Œå†³ç­–ï¼ˆç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£ï¼‰"""
        # å°è¯•å¤šç§LLMè°ƒç”¨æ–¹å¼
        
        # æ–¹å¼1ï¼šé€šè¿‡prior_reasonerè°ƒç”¨
        try:
            if hasattr(self, 'prior_reasoner') and self.prior_reasoner and hasattr(self.prior_reasoner, 'llm_manager'):
                logger.info(f"ğŸ” å°è¯•é€šè¿‡prior_reasonerè°ƒç”¨LLM...")
                llm_response = self.prior_reasoner.llm_manager.generate_response(
                    query=decision_prompt,
                    provider="deepseek",
                    temperature=0.3,
                    max_tokens=1000
                )
                
                if llm_response and llm_response.strip():
                    return llm_response.strip()
        except Exception as e:
            logger.debug(f"prior_reasoner LLMè°ƒç”¨å¤±è´¥: {e}")
        
        # æ–¹å¼2ï¼šç›´æ¥è°ƒç”¨DeepSeekå®¢æˆ·ç«¯
        try:
            import os
            api_key = os.getenv('DEEPSEEK_API_KEY') or os.getenv('NEOGENESIS_API_KEY')
            
            if api_key:
                logger.info(f"ğŸ” å°è¯•ç›´æ¥åˆ›å»ºDeepSeekå®¢æˆ·ç«¯...")
                from neogenesis_system.providers.impl.deepseek_client import DeepSeekClient, ClientConfig
                
                client_config = ClientConfig(
                    api_key=api_key,
                    model="deepseek-chat",
                    temperature=0.3,
                    max_tokens=1000,
                    enable_cache=False
                )
                
                direct_client = DeepSeekClient(client_config)
                api_response = direct_client.simple_chat(
                    prompt=decision_prompt,
                    max_tokens=1000,
                    temperature=0.3
                )
                
                # ä»APIResponseä¸­æå–æ–‡æœ¬å†…å®¹
                llm_response = api_response.content if hasattr(api_response, 'content') else str(api_response)
                
                if llm_response and llm_response.strip():
                    return llm_response.strip()
        except Exception as e:
            logger.debug(f"ç›´æ¥LLMè°ƒç”¨å¤±è´¥: {e}")
        
        return None
    
    def _analyze_path_actions(self, chosen_path: ReasoningPath, query: str, 
                            strategy_decision: StrategyDecision) -> List[Action]:
        """
        æ™ºèƒ½è·¯å¾„åˆ†æ - æ ¹æ®é€‰ä¸­çš„æ€ç»´è·¯å¾„ç”Ÿæˆå…·ä½“è¡ŒåŠ¨ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰
        
        è¿™ä¸ªæ–¹æ³•åˆ†æchosen_pathçš„ç‰¹å¾ï¼Œåˆ¤æ–­åº”è¯¥ä½¿ç”¨ä»€ä¹ˆå·¥å…·ã€‚
        """
        actions = []
        path_description = chosen_path.description
        
        # å°è¯•ä½¿ç”¨è¯­ä¹‰åˆ†æå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(self, 'semantic_analyzer') and self.semantic_analyzer and path_description:
            try:
                # åˆ†æè·¯å¾„æè¿°å’ŒæŸ¥è¯¢å†…å®¹
                combined_text = f"{path_description} {query}"
                analysis_result = self.semantic_analyzer.analyze(
                    combined_text, 
                    ['intent_detection', 'domain_classification']
                )
                
                # åŸºäºæ„å›¾åˆ†æç”Ÿæˆè¡ŒåŠ¨
                if 'intent_detection' in analysis_result.analysis_results:
                    intent_result = analysis_result.analysis_results['intent_detection'].result
                    primary_intent = intent_result.get('primary_intent', '').lower()
                    
                    # ğŸ” æ™ºèƒ½å·¥å…·é€‰æ‹©
                    if any(word in primary_intent for word in ['information', 'search', 'research', 'explore', 'find']):
                        # ä¿¡æ¯æœç´¢éœ€æ±‚
                        search_query = self._extract_search_query(query, chosen_path)
                        if self._tool_available("web_search"):
                            actions.append(Action(
                                tool_name="web_search",
                                tool_input={"query": search_query}
                            ))
                        logger.debug(f"ğŸ” è¯­ä¹‰è¯†åˆ«ä¸ºæœç´¢è·¯å¾„: {search_query}")
                        
                    elif any(word in primary_intent for word in ['verification', 'validate', 'check', 'confirm', 'verify']):
                        # éªŒè¯éœ€æ±‚
                        idea_to_verify = self._extract_verification_idea(query, chosen_path)
                        if self._tool_available("idea_verification"):
                            actions.append(Action(
                                tool_name="idea_verification",
                                tool_input={"idea_text": idea_to_verify}
                            ))
                        logger.debug(f"ğŸ”¬ è¯­ä¹‰è¯†åˆ«ä¸ºéªŒè¯è·¯å¾„: {idea_to_verify}")
                        
                    elif any(word in primary_intent for word in ['analysis', 'analyze', 'evaluate', 'compare', 'assess']):
                        # åˆ†æéœ€æ±‚
                        if not actions:  # å¦‚æœè¿˜æ²¡æœ‰å…¶ä»–è¡ŒåŠ¨
                            search_query = f"å…³äº {query} çš„è¯¦ç»†ä¿¡æ¯å’Œåˆ†æ"
                            if self._tool_available("web_search"):
                                actions.append(Action(
                                    tool_name="web_search",
                                    tool_input={"query": search_query}
                                ))
                            logger.debug(f"ğŸ“Š è¯­ä¹‰è¯†åˆ«ä¸ºåˆ†æè·¯å¾„ï¼Œå…ˆæœç´¢ä¿¡æ¯: {search_query}")
                
                logger.debug("ğŸ” è·¯å¾„è¡ŒåŠ¨è¯­ä¹‰åˆ†ææˆåŠŸ")
                
            except Exception as e:
                logger.warning(f"âš ï¸ è·¯å¾„è¡ŒåŠ¨è¯­ä¹‰åˆ†æå¤±è´¥: {e}")
        else:
            logger.debug("ğŸ“ è¯­ä¹‰åˆ†æå™¨ä¸å¯ç”¨ï¼Œè·³è¿‡æ™ºèƒ½è·¯å¾„åˆ†æ")
        
        # ğŸ”§ å¦‚æœæ²¡æœ‰è¯†åˆ«å‡ºä»»ä½•è¡ŒåŠ¨ï¼Œä½¿ç”¨å›é€€æ–¹æ³•
        if not actions:
            actions.extend(self._generate_fallback_actions(query, chosen_path))
        
        return actions
    
    def _extract_search_query(self, original_query: str, path: ReasoningPath) -> str:
        """ä»åŸå§‹æŸ¥è¯¢å’Œè·¯å¾„ä¿¡æ¯ä¸­æå–æœç´¢æŸ¥è¯¢ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        # æ ¹æ®è·¯å¾„æè¿°ä¼˜åŒ–æœç´¢æŸ¥è¯¢
        if "å…·ä½“" in path.description or "è¯¦ç»†" in path.description:
            return f"{original_query} è¯¦ç»†ä¿¡æ¯"
        elif "æœ€æ–°" in path.description or "recent" in path.description.lower():
            return f"{original_query} æœ€æ–°å‘å±•"
        elif "å¯¹æ¯”" in path.description or "æ¯”è¾ƒ" in path.description:
            return f"{original_query} å¯¹æ¯”åˆ†æ"
        else:
            return original_query
    
    def _extract_verification_idea(self, original_query: str, path: ReasoningPath) -> str:
        """ä»æŸ¥è¯¢å’Œè·¯å¾„ä¿¡æ¯ä¸­æå–éœ€è¦éªŒè¯çš„æƒ³æ³•ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        return f"åŸºäºæŸ¥è¯¢'{original_query}'çš„æƒ³æ³•: {path.description}"
    
    def _generate_fallback_actions(self, query: str, path: ReasoningPath) -> List[Action]:
        """ç”Ÿæˆç®€åŒ–çš„é»˜è®¤è¡ŒåŠ¨ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        # è¿”å›ç©ºçš„è¡ŒåŠ¨åˆ—è¡¨ï¼Œè®©ç³»ç»Ÿä½¿ç”¨ç›´æ¥å›ç­”æ¨¡å¼
        return []
    
    def _get_available_tools_info(self) -> Dict[str, str]:
        """è·å–å¯ç”¨å·¥å…·ä¿¡æ¯ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        tools_info = {}
        try:
            if self.tool_registry:
                # å°è¯•è·å–å·¥å…·åˆ—è¡¨
                if hasattr(self.tool_registry, 'tools') and self.tool_registry.tools:
                    for tool_name, tool_obj in self.tool_registry.tools.items():
                        if hasattr(tool_obj, 'description'):
                            tools_info[tool_name] = tool_obj.description
                        else:
                            tools_info[tool_name] = f"{tool_name} - å·¥å…·"
                elif hasattr(self.tool_registry, '_tools') and self.tool_registry._tools:
                    for tool_name, tool_obj in self.tool_registry._tools.items():
                        if hasattr(tool_obj, 'description'):
                            tools_info[tool_name] = tool_obj.description
                        else:
                            tools_info[tool_name] = f"{tool_name} - å·¥å…·"
                else:
                    # å¸¸è§å·¥å…·çš„ç¡¬ç¼–ç æè¿°
                    tools_info = {
                        'web_search': 'ç½‘ç»œæœç´¢ - æœç´¢ç½‘ç»œä¿¡æ¯å’Œæœ€æ–°èµ„è®¯',
                        'knowledge_query': 'çŸ¥è¯†æŸ¥è¯¢ - æŸ¥è¯¢å†…éƒ¨çŸ¥è¯†åº“',
                        'idea_verification': 'æƒ³æ³•éªŒè¯ - éªŒè¯æƒ³æ³•çš„å¯è¡Œæ€§',
                        'llm_advisor': 'LLMé¡¾é—® - è·å–AIå»ºè®®å’Œåˆ†æ'
                    }
        except Exception as e:
            logger.debug(f"è·å–å·¥å…·ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            # ä½¿ç”¨é»˜è®¤å·¥å…·ä¿¡æ¯
            tools_info = {
                'web_search': 'ç½‘ç»œæœç´¢ - æœç´¢ç½‘ç»œä¿¡æ¯å’Œæœ€æ–°èµ„è®¯',
                'knowledge_query': 'çŸ¥è¯†æŸ¥è¯¢ - æŸ¥è¯¢å†…éƒ¨çŸ¥è¯†åº“'
            }
        
        logger.debug(f"ğŸ“‹ å¯ç”¨å·¥å…·: {list(tools_info.keys())}")
        return tools_info
    
    def _build_llm_decision_prompt(self, user_query: str, chosen_path: ReasoningPath, 
                                  thinking_seed: str, available_tools: Dict[str, str],
                                  strategy_context: StrategyDecision) -> str:
        """
        æ„å»ºLLMå†³ç­–æç¤º - ğŸš€ MCPå‡çº§ç‰ˆï¼šè®©å·¥å…·è°ƒç”¨"æ„ŸçŸ¥"å®Œæ•´çš„æ¨¡å‹ä¸Šä¸‹æ–‡
        
        æ ¸å¿ƒå‡çº§ï¼šä»"æ˜¯å¦éœ€è¦å·¥å…·"å‡çº§ä¸º"å¦‚ä½•æœ€ç²¾ç¡®åœ°è°ƒç”¨å·¥å…·"
        è¿™æ˜¯å°†MCPæ€æƒ³æ³¨å…¥å·¥å…·ç³»ç»Ÿçš„å…³é”®å®ç°ï¼
        """
        
        # ğŸ”¥ å‡çº§ï¼šæ„å»ºæ›´è¯¦ç»†çš„å·¥å…·ä¿¡æ¯ï¼ŒåŒ…å«å‚æ•°è§„èŒƒ
        detailed_tools_info = self._build_detailed_tools_info(available_tools)
        
        # ğŸ”¥ æ ¸å¿ƒæ”¹è¿›ï¼šæ„å»ºä¸°å¯Œçš„äº”é˜¶æ®µä¸Šä¸‹æ–‡ä¿¡æ¯
        stage_context_info = self._build_five_stage_context_summary(strategy_context)
        
        # ğŸ”¥ æ–°å¢ï¼šåŸºäºä¸Šä¸‹æ–‡çš„æ™ºèƒ½å·¥å…·æ¨è
        contextual_tool_suggestions = self._generate_contextual_tool_suggestions(strategy_context, available_tools)
        
        prompt = f"""ä½ æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹çš„é«˜çº§æˆ˜æœ¯å†³ç­–å®˜ï¼Œè´Ÿè´£åŸºäºå®Œæ•´çš„äº”é˜¶æ®µå†³ç­–æµç¨‹å’ŒMCPæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼Œåšå‡ºæœ€ç²¾ç¡®çš„å·¥å…·è°ƒç”¨å†³ç­–ã€‚

ğŸ“‹ **ç”¨æˆ·æŸ¥è¯¢**
{user_query}

ğŸ§  **äº”é˜¶æ®µå†³ç­–æµç¨‹ä¸Šä¸‹æ–‡** (è¿™æ˜¯ä½ ç²¾å‡†å·¥å…·è°ƒç”¨çš„æ ¸å¿ƒä¾æ®!)
{stage_context_info}

ğŸ¯ **æœ€ç»ˆé€‰æ‹©çš„ç­–ç•¥**
ç­–ç•¥ç±»å‹: {chosen_path.path_type}
ç­–ç•¥æè¿°: {chosen_path.description}
å†³ç­–ç½®ä¿¡åº¦: {strategy_context.confidence_score:.3f}
æœ€ç»ˆæ¨ç†: {strategy_context.final_reasoning}

ğŸ”§ **å¯ç”¨å·¥å…·è¯¦ç»†è§„èŒƒ**
{detailed_tools_info if detailed_tools_info else "æš‚æ— å¯ç”¨å·¥å…·"}

ğŸ’¡ **åŸºäºä¸Šä¸‹æ–‡çš„æ™ºèƒ½å·¥å…·æ¨è**
{contextual_tool_suggestions}

ğŸš€ **ä½ çš„æ ¸å¿ƒä»»åŠ¡**
åŸºäºå®Œæ•´çš„äº”é˜¶æ®µå†³ç­–ä¸Šä¸‹æ–‡å’ŒMCPåè®®ï¼Œåšå‡ºæœ€ç²¾ç¡®çš„å·¥å…·è°ƒç”¨å†³ç­–ï¼š

1. **æ·±åº¦ä¸Šä¸‹æ–‡åˆ†æ**ï¼š
   - åˆ†æäº”é˜¶æ®µæµç¨‹ä¸­æ¯ä¸ªé˜¶æ®µçš„å…³é”®ä¿¡æ¯
   - è¯†åˆ«å“ªäº›ä¿¡æ¯éœ€è¦è¡¥å……æˆ–éªŒè¯
   - ç¡®å®šæœ€é€‚åˆçš„å·¥å…·è°ƒç”¨ç­–ç•¥

2. **ç²¾å‡†å·¥å…·è°ƒç”¨**ï¼š
   - å¦‚æœéœ€è¦å·¥å…·ï¼šåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå®Œæ•´çš„Actionå¯¹è±¡ï¼ˆåŒ…å«ç²¾ç¡®çš„å‚æ•°ï¼‰
   - å¦‚æœä¸éœ€è¦å·¥å…·ï¼šåŸºäºæ·±åº¦åˆ†æç»™å‡ºé«˜è´¨é‡å›ç­”
   - å·¥å…·å‚æ•°å¿…é¡»ä¸äº”é˜¶æ®µä¸Šä¸‹æ–‡é«˜åº¦ç›¸å…³

3. **æ™ºèƒ½å‚æ•°ç”Ÿæˆ**ï¼š
   - æœç´¢å·¥å…·ï¼šåŸºäºç§å­éªŒè¯å’Œè·¯å¾„åˆ†æç”Ÿæˆç²¾å‡†æŸ¥è¯¢
   - éªŒè¯å·¥å…·ï¼šåŸºäºå†³ç­–æ¨ç†ç”Ÿæˆå…·ä½“éªŒè¯å†…å®¹
   - åˆ†æå·¥å…·ï¼šåŸºäºç­–ç•¥ç±»å‹é€‰æ‹©æœ€ä½³åˆ†ææ–¹å¼

ğŸ“ **è¯·ç”¨ä»¥ä¸‹å¢å¼ºJSONæ ¼å¼å›ç­”**
{{
    "needs_tools": false,  // trueæˆ–false
    "context_analysis": "åŸºäºäº”é˜¶æ®µä¸Šä¸‹æ–‡çš„æ·±åº¦åˆ†æå’Œæ´å¯Ÿ",
    "tool_strategy": "å·¥å…·è°ƒç”¨ç­–ç•¥å’Œæ¨ç†è¿‡ç¨‹",
    "actions": [  // å¦‚æœéœ€è¦å·¥å…·ï¼Œæä¾›å®Œæ•´çš„Actionå¯¹è±¡
        {{
            "tool_name": "å…·ä½“å·¥å…·åç§°",
            "tool_input": {{
                "param1": "åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆçš„ç²¾ç¡®å‚æ•°å€¼",
                "param2": "å¦ä¸€ä¸ªå‚æ•°å€¼"
            }},
            "reasoning": "é€‰æ‹©æ­¤å·¥å…·å’Œå‚æ•°çš„å…·ä½“ç†ç”±"
        }}
    ],
    "direct_answer": "å¦‚æœä¸éœ€è¦å·¥å…·ï¼ŒåŸºäºäº”é˜¶æ®µå†³ç­–æµç¨‹çš„æ·±åº¦æ´å¯Ÿç»™å‡ºå›ç­”",
    "confidence_score": 0.85,  // å¯¹å†³ç­–çš„ç½®ä¿¡åº¦ (0-1)
    "explanation": "åŸºäºå®Œæ•´äº”é˜¶æ®µä¸Šä¸‹æ–‡å’ŒMCPåè®®çš„å†³ç­–è§£é‡Š"
}}

âš ï¸ **MCPåè®®è¦æ±‚**
- å·¥å…·è°ƒç”¨å¿…é¡»åŸºäºå®Œæ•´çš„æ¨¡å‹ä¸Šä¸‹æ–‡ï¼Œä¸èƒ½å¿½è§†äº”é˜¶æ®µå†³ç­–ä¿¡æ¯
- å‚æ•°ç”Ÿæˆè¦ä½“ç°å¯¹ä¸Šä¸‹æ–‡çš„æ·±åº¦ç†è§£å’Œç²¾å‡†æŠŠæ¡
- æ¯ä¸ªå·¥å…·è°ƒç”¨éƒ½è¦æœ‰æ˜ç¡®çš„ä¸Šä¸‹æ–‡ä¾æ®å’Œæ¨ç†è¿‡ç¨‹
- ç½®ä¿¡åº¦è¯„åˆ†è¦åæ˜ å¯¹ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æŠŠæ¡ç¨‹åº¦
- JSONæ ¼å¼å¿…é¡»ä¸¥æ ¼æ­£ç¡®ï¼Œæ”¯æŒç›´æ¥è§£æä¸ºActionå¯¹è±¡"""
        
        return prompt
    
    def _build_detailed_tools_info(self, available_tools: Dict[str, str]) -> str:
        """
        ğŸ”¥ æ–°å¢æ–¹æ³•ï¼šæ„å»ºè¯¦ç»†çš„å·¥å…·ä¿¡æ¯ï¼ŒåŒ…å«å‚æ•°è§„èŒƒ
        
        è¿™æ˜¯MCPå‡çº§çš„å…³é”®ï¼šè®©LLMäº†è§£å·¥å…·çš„å®Œæ•´æ¥å£è§„èŒƒï¼Œ
        è€Œä¸ä»…ä»…æ˜¯ç®€å•çš„æè¿°ã€‚
        """
        if not available_tools:
            return "æš‚æ— å¯ç”¨å·¥å…·"
        
        detailed_info_parts = []
        
        for tool_name, tool_desc in available_tools.items():
            # è·å–å·¥å…·çš„è¯¦ç»†ä¿¡æ¯
            tool_detail = self._get_tool_detailed_spec(tool_name, tool_desc)
            detailed_info_parts.append(tool_detail)
        
        return "\n\n".join(detailed_info_parts)
    
    def _get_tool_detailed_spec(self, tool_name: str, tool_desc: str) -> str:
        """è·å–å·¥å…·çš„è¯¦ç»†è§„èŒƒ"""
        # åŸºäºå·¥å…·åç§°æä¾›è¯¦ç»†çš„å‚æ•°è§„èŒƒ
        tool_specs = {
            'web_search': {
                'description': tool_desc,
                'parameters': {
                    'query': {
                        'type': 'string',
                        'description': 'æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œåº”è¯¥åŸºäºä¸Šä¸‹æ–‡åˆ†æç”Ÿæˆç²¾å‡†çš„æœç´¢è¯',
                        'examples': ['AIç³»ç»Ÿæ¶æ„è®¾è®¡æœ€ä½³å®è·µ', 'å¾®æœåŠ¡æ¶æ„ 2024å¹´æœ€æ–°è¶‹åŠ¿']
                    },
                    'max_results': {
                        'type': 'integer', 
                        'description': 'è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5',
                        'optional': True
                    }
                }
            },
            'search_knowledge': {
                'description': tool_desc,
                'parameters': {
                    'query': {
                        'type': 'string',
                        'description': 'çŸ¥è¯†åº“æœç´¢æŸ¥è¯¢ï¼Œåº”åŸºäºäº”é˜¶æ®µå†³ç­–ä¸Šä¸‹æ–‡ç”Ÿæˆ',
                        'examples': ['äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿', 'äº‘è®¡ç®—æ¶æ„è®¾è®¡']
                    },
                    'max_results': {
                        'type': 'integer',
                        'description': 'æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤5',
                        'optional': True
                    }
                }
            },
            'idea_verification': {
                'description': tool_desc,
                'parameters': {
                    'idea': {
                        'type': 'string',
                        'description': 'è¦éªŒè¯çš„æƒ³æ³•æˆ–æ¦‚å¿µï¼Œåº”åŸºäºå†³ç­–æ¨ç†ç”Ÿæˆå…·ä½“å†…å®¹',
                        'examples': ['åŸºäºå¾®æœåŠ¡æ¶æ„çš„AIç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ', 'é‡‡ç”¨å®¹å™¨åŒ–éƒ¨ç½²çš„å¯æ‰©å±•æ€§æ–¹æ¡ˆ']
                    },
                    'criteria': {
                        'type': 'array',
                        'description': 'éªŒè¯æ ‡å‡†åˆ—è¡¨ï¼Œå¯é€‰',
                        'optional': True,
                        'examples': [['feasibility', 'novelty', 'impact'], ['æŠ€æœ¯å¯è¡Œæ€§', 'æˆæœ¬æ•ˆç›Š', 'å®æ–½éš¾åº¦']]
                    }
                }
            },
            'analyze_text': {
                'description': tool_desc,
                'parameters': {
                    'text': {
                        'type': 'string',
                        'description': 'è¦åˆ†æçš„æ–‡æœ¬å†…å®¹',
                        'examples': ['è¿™æ˜¯ä¸€ä¸ªåˆ›æ–°çš„AIè§£å†³æ–¹æ¡ˆ...']
                    },
                    'analysis_type': {
                        'type': 'string',
                        'description': 'åˆ†æç±»å‹ï¼šsentimentï¼ˆæƒ…æ„Ÿåˆ†æï¼‰æˆ–complexityï¼ˆå¤æ‚åº¦åˆ†æï¼‰',
                        'optional': True,
                        'default': 'sentiment'
                    }
                }
            },
            'generate_image': {
                'description': tool_desc,
                'parameters': {
                    'prompt': {
                        'type': 'string',
                        'description': 'å›¾åƒç”Ÿæˆæç¤ºè¯ï¼Œæè¿°è¦ç”Ÿæˆçš„å›¾åƒå†…å®¹',
                        'examples': ['ä¸€ä¸ªç°ä»£åŒ–çš„AIæ•°æ®ä¸­å¿ƒæ¶æ„å›¾', 'å¾®æœåŠ¡ç³»ç»Ÿçš„å¯è§†åŒ–æ¶æ„']
                    },
                    'save_image': {
                        'type': 'boolean',
                        'description': 'æ˜¯å¦ä¿å­˜å›¾åƒåˆ°æœ¬åœ°ï¼Œé»˜è®¤True',
                        'optional': True
                    }
                }
            }
        }
        
        spec = tool_specs.get(tool_name, {
            'description': tool_desc,
            'parameters': {
                'input': {
                    'type': 'string',
                    'description': 'å·¥å…·è¾“å…¥å‚æ•°ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆ'
                }
            }
        })
        
        # æ ¼å¼åŒ–å·¥å…·è§„èŒƒ
        formatted_spec = f"""ğŸ”§ **{tool_name}**
ğŸ“ æè¿°: {spec['description']}
ğŸ“‹ å‚æ•°è§„èŒƒ:"""
        
        for param_name, param_info in spec['parameters'].items():
            optional_mark = " (å¯é€‰)" if param_info.get('optional', False) else " (å¿…éœ€)"
            formatted_spec += f"""
  â€¢ {param_name}{optional_mark}: {param_info['type']}
    - {param_info['description']}"""
            
            if 'examples' in param_info:
                examples = param_info['examples'][:2]  # æœ€å¤šæ˜¾ç¤º2ä¸ªä¾‹å­
                formatted_spec += f"""
    - ç¤ºä¾‹: {', '.join(str(ex) for ex in examples)}"""
            
            if 'default' in param_info:
                formatted_spec += f"""
    - é»˜è®¤å€¼: {param_info['default']}"""
        
        return formatted_spec
    
    def _generate_contextual_tool_suggestions(self, strategy_context: StrategyDecision, 
                                            available_tools: Dict[str, str]) -> str:
        """
        ğŸ”¥ æ–°å¢æ–¹æ³•ï¼šåŸºäºäº”é˜¶æ®µå†³ç­–ä¸Šä¸‹æ–‡ç”Ÿæˆæ™ºèƒ½å·¥å…·æ¨è
        
        è¿™æ˜¯MCPæ€æƒ³çš„ä½“ç°ï¼šè®©å·¥å…·é€‰æ‹©åŸºäºå®Œæ•´çš„æ¨¡å‹ä¸Šä¸‹æ–‡ï¼Œ
        è€Œä¸æ˜¯ç®€å•çš„å…³é”®è¯åŒ¹é…ã€‚
        """
        if not strategy_context or not available_tools:
            return "æ— æ³•ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„å·¥å…·æ¨è"
        
        suggestions = []
        
        # åŸºäºé˜¶æ®µäºŒï¼šç§å­éªŒè¯ç»“æœ
        if strategy_context.stage2_context:
            stage2 = strategy_context.stage2_context
            if not stage2.verification_result or stage2.feasibility_score < 0.7:
                if 'web_search' in available_tools or 'search_knowledge' in available_tools:
                    suggestions.append("""
ğŸ” **åŸºäºç§å­éªŒè¯ç»“æœçš„å»ºè®®**:
- ç§å­éªŒè¯æ˜¾ç¤ºéœ€è¦æ›´å¤šä¿¡æ¯æ”¯æ’‘
- å»ºè®®ä½¿ç”¨æœç´¢å·¥å…·è·å–ç›¸å…³èµ„æ–™å’Œæœ€æ–°ä¿¡æ¯
- æ¨èæŸ¥è¯¢: åŸºäºç§å­å†…å®¹ç”Ÿæˆç²¾å‡†æœç´¢è¯""")
            elif stage2.verification_result and stage2.feasibility_score >= 0.8:
                # ğŸ”¥ æ–°å¢ï¼šéªŒè¯é€šè¿‡ä¸”è¯„åˆ†é«˜çš„æƒ…å†µ
                if 'verify_idea' in available_tools or 'idea_verification' in available_tools:
                    suggestions.append("""
ğŸ” **åŸºäºç§å­éªŒè¯ç»“æœçš„å»ºè®®**:
- ç§å­éªŒè¯é€šè¿‡ä¸”å¯è¡Œæ€§è¯„åˆ†é«˜ ({:.2f})
- å»ºè®®è¿›ä¸€æ­¥éªŒè¯å…·ä½“å®æ–½æ–¹æ¡ˆ
- æ¨èéªŒè¯: æ·±å…¥éªŒè¯æŠ€æœ¯ç»†èŠ‚å’Œå®ç°è·¯å¾„""".format(stage2.feasibility_score))
        
        # åŸºäºé˜¶æ®µä¸‰ï¼šè·¯å¾„ç”Ÿæˆæƒ…å†µ
        if strategy_context.stage3_context:
            stage3 = strategy_context.stage3_context
            if stage3.path_count > 0 and stage3.diversity_score > 0.7:
                if 'idea_verification' in available_tools or 'verify_idea' in available_tools:
                    suggestions.append("""
ğŸ’¡ **åŸºäºè·¯å¾„ç”Ÿæˆç»“æœçš„å»ºè®®**:
- ç”Ÿæˆäº†å¤šæ ·åŒ–çš„æ€ç»´è·¯å¾„ (å¤šæ ·æ€§è¯„åˆ†: {:.2f})
- å»ºè®®éªŒè¯æœ€ä¼˜è·¯å¾„çš„å¯è¡Œæ€§
- æ¨èéªŒè¯: åŸºäºé€‰æ‹©çš„ç­–ç•¥è·¯å¾„ç”ŸæˆéªŒè¯å†…å®¹""".format(stage3.diversity_score))
        
        # åŸºäºé˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯ç»“æœ
        if strategy_context.stage4_context:
            stage4 = strategy_context.stage4_context
            if len(stage4.verified_paths) > 1:
                if 'analyze_text' in available_tools:
                    suggestions.append("""
ğŸ“Š **åŸºäºè·¯å¾„éªŒè¯ç»“æœçš„å»ºè®®**:
- å¤šä¸ªè·¯å¾„é€šè¿‡éªŒè¯ï¼Œéœ€è¦æ·±åº¦åˆ†æ
- å»ºè®®åˆ†æä¸åŒè·¯å¾„çš„ä¼˜åŠ£åŠ¿
- æ¨èåˆ†æ: å¯¹æ¯”åˆ†æå„è·¯å¾„çš„ç‰¹ç‚¹""")
        
        # åŸºäºæœ€ç»ˆç­–ç•¥ç±»å‹ - ğŸ”¥ ä¿®å¤ï¼šæ”¯æŒä¸­æ–‡ç­–ç•¥ç±»å‹
        strategy_type = strategy_context.chosen_path.get('path_type', '').lower() if strategy_context.chosen_path else ''
        
        if 'exploratory' in strategy_type or 'investigative' in strategy_type or 'æ¢ç´¢' in strategy_type or 'è°ƒç ”' in strategy_type:
            if 'web_search' in available_tools or 'search_knowledge' in available_tools:
                suggestions.append("""
ğŸ” **åŸºäºç­–ç•¥ç±»å‹çš„å»ºè®®** (æ¢ç´¢è°ƒç ”å‹):
- å½“å‰ç­–ç•¥éœ€è¦å¹¿æ³›çš„ä¿¡æ¯æ”¶é›†
- å¼ºçƒˆå»ºè®®ä½¿ç”¨ç½‘ç»œæœç´¢å·¥å…·
- æŸ¥è¯¢ç­–ç•¥: å¤šè§’åº¦ã€å¤šå…³é”®è¯æœç´¢""")
        
        elif 'analytical' in strategy_type or 'systematic' in strategy_type or 'åˆ†æ' in strategy_type or 'ç³»ç»Ÿ' in strategy_type:
            if 'idea_verification' in available_tools or 'verify_idea' in available_tools:
                suggestions.append("""
ğŸ”¬ **åŸºäºç­–ç•¥ç±»å‹çš„å»ºè®®** (ç³»ç»Ÿåˆ†æå‹):
- å½“å‰ç­–ç•¥éœ€è¦ä¸¥è°¨çš„éªŒè¯åˆ†æ
- å»ºè®®ä½¿ç”¨æƒ³æ³•éªŒè¯å·¥å…·
- éªŒè¯ç­–ç•¥: å¤šç»´åº¦ã€å¤šæ ‡å‡†éªŒè¯""")
        
        elif 'creative' in strategy_type or 'innovative' in strategy_type or 'åˆ›æ–°' in strategy_type or 'åˆ›æ„' in strategy_type:
            if 'generate_image' in available_tools:
                suggestions.append("""
ğŸ¨ **åŸºäºç­–ç•¥ç±»å‹çš„å»ºè®®** (åˆ›æ–°åˆ›æ„å‹):
- å½“å‰ç­–ç•¥é€‚åˆå¯è§†åŒ–è¡¨è¾¾
- å»ºè®®è€ƒè™‘å›¾åƒç”Ÿæˆå·¥å…·
- ç”Ÿæˆç­–ç•¥: æ¦‚å¿µå¯è§†åŒ–ã€æ¶æ„å›¾ç¤º""")
        
        # åŸºäºç½®ä¿¡åº¦
        if strategy_context.confidence_score < 0.6:
            suggestions.append("""
âš ï¸ **åŸºäºå†³ç­–ç½®ä¿¡åº¦çš„å»ºè®®**:
- å½“å‰å†³ç­–ç½®ä¿¡åº¦è¾ƒä½ ({:.2f})ï¼Œå»ºè®®è¡¥å……ä¿¡æ¯
- ä¼˜å…ˆä½¿ç”¨æœç´¢å’ŒéªŒè¯å·¥å…·æé«˜å†³ç­–è´¨é‡
- ç­–ç•¥: å…ˆæœç´¢åéªŒè¯ï¼Œé€æ­¥æå‡ç½®ä¿¡åº¦""".format(strategy_context.confidence_score))
        elif strategy_context.confidence_score >= 0.8:
            # ğŸ”¥ æ–°å¢ï¼šé«˜ç½®ä¿¡åº¦æƒ…å†µçš„å»ºè®®
            if 'search_knowledge' in available_tools:
                suggestions.append("""
âœ… **åŸºäºå†³ç­–ç½®ä¿¡åº¦çš„å»ºè®®**:
- å½“å‰å†³ç­–ç½®ä¿¡åº¦é«˜ ({:.2f})ï¼Œå¯è¿›è¡Œæ·±åº¦æ¢ç´¢
- å»ºè®®æœç´¢ç›¸å…³çš„æœ€æ–°å‘å±•å’Œæœ€ä½³å®è·µ
- ç­–ç•¥: åœ¨ç°æœ‰åŸºç¡€ä¸Šæ‹“å±•å’Œæ·±åŒ–è®¤çŸ¥""".format(strategy_context.confidence_score))
        
        # ğŸ”¥ æ–°å¢ï¼šåŸºäºå·¥å…·å¯ç”¨æ€§çš„é€šç”¨å»ºè®®
        if available_tools:
            tool_names = list(available_tools.keys())
            suggestions.append("""
ğŸ› ï¸ **åŸºäºå¯ç”¨å·¥å…·çš„å»ºè®®**:
- å½“å‰å¯ç”¨å·¥å…·: {}
- å»ºè®®æ ¹æ®å…·ä½“éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ç»„åˆ
- ç­–ç•¥: ä¼˜å…ˆä½¿ç”¨æœ€åŒ¹é…å½“å‰ä¸Šä¸‹æ–‡çš„å·¥å…·""".format(', '.join(tool_names)))
        
        if not suggestions:
            suggestions.append("""
ğŸ’­ **é€šç”¨å»ºè®®**:
- åŸºäºå½“å‰ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥è€ƒè™‘ç›´æ¥å›ç­”
- å¦‚éœ€è¡¥å……ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨æœç´¢å·¥å…·
- å¦‚éœ€éªŒè¯æƒ³æ³•ï¼Œå¯ä½¿ç”¨éªŒè¯å·¥å…·""")
        
        return "\n".join(suggestions)
    
    def _build_five_stage_context_summary(self, strategy_context: StrategyDecision) -> str:
        """
        ğŸ”¥ æ ¸å¿ƒæ–°å¢æ–¹æ³•ï¼šæ„å»ºäº”é˜¶æ®µå†³ç­–æµç¨‹çš„ä¸Šä¸‹æ–‡æ‘˜è¦
        
        è¿™æ˜¯è§£å†³"æœ€åä¸€å…¬é‡Œä¸Šä¸‹æ–‡ä¸¢å¤±"çš„å…³é”®æ–¹æ³•ï¼
        å°†StrategyDecisionä¸­çš„ä¸°å¯Œäº”é˜¶æ®µä¸Šä¸‹æ–‡ä¿¡æ¯è½¬æ¢ä¸ºLLMå¯ç†è§£çš„æ ¼å¼ã€‚
        
        Args:
            strategy_context: åŒ…å«å®Œæ•´äº”é˜¶æ®µä¸Šä¸‹æ–‡çš„æˆ˜ç•¥å†³ç­–å¯¹è±¡
            
        Returns:
            æ ¼å¼åŒ–çš„äº”é˜¶æ®µä¸Šä¸‹æ–‡æ‘˜è¦å­—ç¬¦ä¸²
        """
        context_parts = []
        
        # é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ
        if strategy_context.stage1_context:
            stage1 = strategy_context.stage1_context
            context_parts.append(f"""
ğŸŒ± **é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ**
- ç§å­å†…å®¹: {stage1.thinking_seed[:200]}{'...' if len(stage1.thinking_seed) > 200 else ''}
- ç§å­ç±»å‹: {stage1.seed_type}
- ç”Ÿæˆæ–¹æ³•: {stage1.generation_method}
- ç½®ä¿¡åº¦: {stage1.confidence_score:.3f}
- æ¨ç†è¿‡ç¨‹: {stage1.reasoning_process[:150]}{'...' if len(stage1.reasoning_process) > 150 else ''}""")
            
            if stage1.source_information:
                context_parts.append(f"- ä¿¡æ¯æºæ•°é‡: {len(stage1.source_information)} ä¸ª")
        
        # é˜¶æ®µäºŒï¼šç§å­éªŒè¯
        if strategy_context.stage2_context:
            stage2 = strategy_context.stage2_context
            verification_status = "âœ… é€šè¿‡" if stage2.verification_result else "âŒ æœªé€šè¿‡"
            context_parts.append(f"""
ğŸ” **é˜¶æ®µäºŒï¼šç§å­éªŒè¯**
- éªŒè¯ç»“æœ: {verification_status}
- å¯è¡Œæ€§è¯„åˆ†: {stage2.feasibility_score:.3f}
- éªŒè¯æ–¹æ³•: {stage2.verification_method}""")
            
            if stage2.verification_evidence:
                evidence_summary = "; ".join(stage2.verification_evidence[:3])
                context_parts.append(f"- éªŒè¯è¯æ®: {evidence_summary}")
            
            if stage2.identified_risks:
                risks_summary = "; ".join(stage2.identified_risks[:2])
                context_parts.append(f"- è¯†åˆ«é£é™©: {risks_summary}")
        
        # é˜¶æ®µä¸‰ï¼šè·¯å¾„ç”Ÿæˆ
        if strategy_context.stage3_context:
            stage3 = strategy_context.stage3_context
            context_parts.append(f"""
ğŸ›¤ï¸ **é˜¶æ®µä¸‰ï¼šå¤šè·¯å¾„ç”Ÿæˆ**
- ç”Ÿæˆè·¯å¾„æ•°: {stage3.path_count}
- ç”Ÿæˆç­–ç•¥: {stage3.generation_strategy}
- å¤šæ ·æ€§è¯„åˆ†: {stage3.diversity_score:.3f}""")
            
            if stage3.path_quality_scores:
                top_paths = sorted(stage3.path_quality_scores.items(), key=lambda x: x[1], reverse=True)[:3]
                paths_info = ", ".join([f"{path}({score:.2f})" for path, score in top_paths])
                context_parts.append(f"- è·¯å¾„è´¨é‡: {paths_info}")
        
        # é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯
        if strategy_context.stage4_context:
            stage4 = strategy_context.stage4_context
            context_parts.append(f"""
âœ… **é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯**
- éªŒè¯è·¯å¾„æ•°: {len(stage4.verified_paths)}""")
            
            if stage4.path_rankings:
                top_rankings = stage4.path_rankings[:3]
                rankings_info = ", ".join([f"{path}({score:.2f})" for path, score in top_rankings])
                context_parts.append(f"- è·¯å¾„æ’å: {rankings_info}")
            
            if stage4.rejected_paths:
                context_parts.append(f"- è¢«æ‹’ç»è·¯å¾„: {len(stage4.rejected_paths)} ä¸ª")
        
        # é˜¶æ®µäº”ï¼šMABå†³ç­–
        if strategy_context.stage5_context:
            stage5 = strategy_context.stage5_context
            context_parts.append(f"""
ğŸ¯ **é˜¶æ®µäº”ï¼šMABæœ€ç»ˆå†³ç­–**
- é€‰æ‹©ç®—æ³•: {stage5.selection_algorithm}
- é€‰æ‹©ç½®ä¿¡åº¦: {stage5.selection_confidence:.3f}
- å†³ç­–æ¨ç†: {stage5.decision_reasoning[:200]}{'...' if len(stage5.decision_reasoning) > 200 else ''}""")
            
            if stage5.golden_template_used:
                context_parts.append("- âœ¨ ä½¿ç”¨äº†é»„é‡‘æ¨¡æ¿ (åŸºäºå†å²æˆåŠŸç»éªŒ)")
        
        # æ€»ä½“å†³ç­–è´¨é‡æŒ‡æ ‡
        if strategy_context.performance_metrics:
            metrics = strategy_context.performance_metrics
            context_parts.append(f"""
ğŸ“Š **å†³ç­–è´¨é‡æŒ‡æ ‡**
- æ€»æ‰§è¡Œæ—¶é—´: {strategy_context.total_execution_time:.2f}ç§’
- å†³ç­–å®Œæ•´æ€§: {'âœ… å®Œæ•´' if strategy_context.is_complete else 'âš ï¸ éƒ¨åˆ†'}""")
            
            if isinstance(metrics, dict):
                for key, value in metrics.items():
                    if isinstance(value, (int, float)):
                        context_parts.append(f"- {key}: {value:.3f}")
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•é˜¶æ®µä¸Šä¸‹æ–‡ï¼Œæä¾›åŸºæœ¬ä¿¡æ¯
        if not context_parts:
            context_parts.append(f"""
âš ï¸ **ç®€åŒ–å†³ç­–æµç¨‹**
- å†³ç­–è½®æ¬¡: {strategy_context.round_number}
- å†³ç­–æ—¶é—´: {strategy_context.timestamp}
- åŸºç¡€æ¨ç†: {strategy_context.final_reasoning}""")
        
        return "\n".join(context_parts)
    
    def _parse_llm_decision_response(self, response: str, chosen_path: ReasoningPath, 
                                   query: str) -> Dict[str, Any]:
        """
        è§£æLLMçš„å†³ç­–å“åº” - ğŸš€ MCPå‡çº§ç‰ˆï¼šç›´æ¥è§£æå®Œæ•´çš„Actionå¯¹è±¡
        
        æ ¸å¿ƒå‡çº§ï¼šæ”¯æŒè§£æLLMç›´æ¥ç”Ÿæˆçš„å®Œæ•´Actionå¯¹è±¡ï¼ŒåŒ…å«ç²¾ç¡®çš„å·¥å…·å‚æ•°
        è¿™æ˜¯MCPæ€æƒ³çš„ä½“ç°ï¼šè®©LLMåŸºäºå®Œæ•´ä¸Šä¸‹æ–‡ç”Ÿæˆç²¾å‡†çš„å·¥å…·è°ƒç”¨
        """
        try:
            import json
            import re
            
            # æå–JSONéƒ¨åˆ† - æ”¯æŒæ›´çµæ´»çš„æ ¼å¼
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',  # æ ‡å‡†markdown jsonå—
                r'```\s*(\{.*?\})\s*```',      # ç®€åŒ–çš„ä»£ç å—
                r'\{.*\}',                     # ç›´æ¥çš„JSONå¯¹è±¡
            ]
            
            json_str = None
            for pattern in json_patterns:
                json_match = re.search(pattern, response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1) if json_match.groups() else json_match.group()
                    break
            
            if json_str:
                decision_data = json.loads(json_str)
                
                # ğŸ”¥ å‡çº§ï¼šæ„å»ºå¢å¼ºçš„å†³ç­–ç»“æœï¼Œæ”¯æŒMCPåè®®
                result = {
                    'needs_tools': decision_data.get('needs_tools', False),
                    'context_analysis': decision_data.get('context_analysis', ''),
                    'tool_strategy': decision_data.get('tool_strategy', ''),
                    'direct_answer': decision_data.get('direct_answer', ''),
                    'confidence_score': decision_data.get('confidence_score', 0.5),
                    'explanation': decision_data.get('explanation', ''),
                    'actions': []
                }
                
                # ğŸš€ æ ¸å¿ƒå‡çº§ï¼šç›´æ¥è§£æå®Œæ•´çš„Actionå¯¹è±¡
                if result['needs_tools'] and decision_data.get('actions'):
                    for action_data in decision_data.get('actions', []):
                        if isinstance(action_data, dict):
                            # ç›´æ¥ä»LLMå“åº”ä¸­è§£æå®Œæ•´çš„Actionå¯¹è±¡
                            tool_name = action_data.get('tool_name')
                            tool_input = action_data.get('tool_input', {})
                            reasoning = action_data.get('reasoning', '')
                            
                            if tool_name:
                                # éªŒè¯å’Œæ¸…ç†å·¥å…·è¾“å…¥å‚æ•°
                                validated_input = self._validate_and_clean_tool_input(
                                    tool_name, tool_input, query, chosen_path
                                )
                                
                                action = Action(
                                    tool_name=tool_name,
                                    tool_input=validated_input
                                )
                                
                                # æ·»åŠ æ¨ç†ä¿¡æ¯åˆ°Actionå¯¹è±¡ï¼ˆå¦‚æœæ”¯æŒï¼‰
                                if hasattr(action, 'reasoning'):
                                    action.reasoning = reasoning
                                
                                result['actions'].append(action)
                                
                                logger.info(f"ğŸ¯ è§£æAction: {tool_name} with params: {list(validated_input.keys())}")
                
                # ğŸ”¥ æ–°å¢ï¼šå…¼å®¹æ—§æ ¼å¼çš„recommended_toolsï¼ˆå‘åå…¼å®¹ï¼‰
                elif result['needs_tools'] and decision_data.get('recommended_tools'):
                    logger.info("ğŸ“‹ ä½¿ç”¨å…¼å®¹æ¨¡å¼è§£ærecommended_tools")
                    for tool_name in decision_data.get('recommended_tools', []):
                        if isinstance(tool_name, str):
                            # åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆæ™ºèƒ½å‚æ•°
                            tool_input = self._generate_contextual_tool_input(
                                tool_name, query, chosen_path, decision_data
                            )
                            result['actions'].append(Action(
                                tool_name=tool_name,
                                tool_input=tool_input
                            ))
                
                logger.info(f"ğŸ” MCPå†³ç­–è§£ææˆåŠŸ: needs_tools={result['needs_tools']}, "
                          f"actions={len(result['actions'])}, confidence={result['confidence_score']:.3f}")
                return result
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æLLMå†³ç­–å“åº”å¤±è´¥: {e}")
        
        # è§£æå¤±è´¥ï¼Œä½¿ç”¨å¢å¼ºçš„å›é€€ç­–ç•¥
        return self._extract_enhanced_fallback_from_response(response, chosen_path, query)
    
    def _validate_and_clean_tool_input(self, tool_name: str, tool_input: Dict[str, Any], 
                                     query: str, chosen_path: ReasoningPath) -> Dict[str, Any]:
        """
        ğŸ”¥ æ–°å¢æ–¹æ³•ï¼šéªŒè¯å’Œæ¸…ç†å·¥å…·è¾“å…¥å‚æ•°
        
        ç¡®ä¿LLMç”Ÿæˆçš„å·¥å…·å‚æ•°ç¬¦åˆå·¥å…·è§„èŒƒï¼Œå¹¶è¿›è¡Œå¿…è¦çš„æ¸…ç†å’Œè¡¥å……
        """
        if not isinstance(tool_input, dict):
            logger.warning(f"âš ï¸ å·¥å…·è¾“å…¥ä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°: {tool_name}")
            return self._generate_tool_input(tool_name, query, chosen_path)
        
        # åŸºäºå·¥å…·åç§°è¿›è¡Œå‚æ•°éªŒè¯å’Œæ¸…ç†
        if tool_name == 'search_knowledge':
            # ç¡®ä¿æœ‰queryå‚æ•°
            if 'query' not in tool_input or not tool_input['query']:
                tool_input['query'] = query
            
            # éªŒè¯max_resultså‚æ•°
            if 'max_results' in tool_input:
                try:
                    tool_input['max_results'] = max(1, min(10, int(tool_input['max_results'])))
                except (ValueError, TypeError):
                    tool_input['max_results'] = 5
        
        elif tool_name == 'idea_verification' or tool_name == 'verify_idea':
            # ç¡®ä¿æœ‰ideaå‚æ•°
            if 'idea' not in tool_input or not tool_input['idea']:
                tool_input['idea'] = query
            
            # éªŒè¯criteriaå‚æ•°
            if 'criteria' in tool_input and isinstance(tool_input['criteria'], list):
                # ä¿æŒcriteriaä¸ºåˆ—è¡¨æ ¼å¼
                pass
            elif 'criteria' in tool_input:
                # å°è¯•è½¬æ¢ä¸ºåˆ—è¡¨
                tool_input['criteria'] = ['feasibility', 'novelty', 'impact']
        
        elif tool_name == 'analyze_text':
            # ç¡®ä¿æœ‰textå‚æ•°
            if 'text' not in tool_input or not tool_input['text']:
                tool_input['text'] = query
            
            # éªŒè¯analysis_typeå‚æ•°
            valid_types = ['sentiment', 'complexity']
            if 'analysis_type' in tool_input and tool_input['analysis_type'] not in valid_types:
                tool_input['analysis_type'] = 'sentiment'
        
        elif tool_name == 'generate_image':
            # ç¡®ä¿æœ‰promptå‚æ•°
            if 'prompt' not in tool_input or not tool_input['prompt']:
                tool_input['prompt'] = f"åŸºäºæŸ¥è¯¢ç”Ÿæˆå›¾åƒ: {query}"
            
            # éªŒè¯save_imageå‚æ•°
            if 'save_image' in tool_input:
                tool_input['save_image'] = bool(tool_input['save_image'])
            else:
                tool_input['save_image'] = True
        
        elif tool_name == 'web_search':
            # ç¡®ä¿æœ‰queryå‚æ•°
            if 'query' not in tool_input or not tool_input['query']:
                tool_input['query'] = query
        
        # ç§»é™¤ç©ºå€¼å’Œæ— æ•ˆå‚æ•°
        cleaned_input = {k: v for k, v in tool_input.items() if v is not None and v != ''}
        
        logger.debug(f"ğŸ§¹ å·¥å…·å‚æ•°æ¸…ç†å®Œæˆ: {tool_name} -> {list(cleaned_input.keys())}")
        return cleaned_input
    
    def _generate_contextual_tool_input(self, tool_name: str, query: str, chosen_path: ReasoningPath, 
                                      decision_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ”¥ æ–°å¢æ–¹æ³•ï¼šåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆæ™ºèƒ½å·¥å…·å‚æ•°
        
        è¿™æ˜¯MCPæ€æƒ³çš„ä½“ç°ï¼šå·¥å…·å‚æ•°ä¸ä»…åŸºäºæŸ¥è¯¢ï¼Œè¿˜åŸºäºå®Œæ•´çš„å†³ç­–ä¸Šä¸‹æ–‡
        """
        # ä»å†³ç­–æ•°æ®ä¸­æå–ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_analysis = decision_data.get('context_analysis', '')
        tool_strategy = decision_data.get('tool_strategy', '')
        
        if tool_name == 'search_knowledge':
            # åŸºäºä¸Šä¸‹æ–‡åˆ†æç”Ÿæˆæ›´ç²¾å‡†çš„æœç´¢æŸ¥è¯¢
            enhanced_query = query
            if context_analysis and 'éœ€è¦' in context_analysis:
                # ä»ä¸Šä¸‹æ–‡åˆ†æä¸­æå–å…³é”®ä¿¡æ¯
                enhanced_query = f"{query} {context_analysis[:50]}"
            
            return {
                'query': enhanced_query.strip(),
                'max_results': 5
            }
        
        elif tool_name == 'idea_verification' or tool_name == 'verify_idea':
            # åŸºäºç­–ç•¥ç±»å‹é€‰æ‹©éªŒè¯æ ‡å‡†
            criteria = ['feasibility', 'novelty', 'impact']
            if 'analytical' in chosen_path.path_type.lower():
                criteria = ['feasibility', 'technical_viability', 'complexity']
            elif 'creative' in chosen_path.path_type.lower():
                criteria = ['novelty', 'creativity', 'impact']
            
            return {
                'idea': query,
                'criteria': criteria
            }
        
        elif tool_name == 'analyze_text':
            # åŸºäºç­–ç•¥ç±»å‹é€‰æ‹©åˆ†ææ–¹å¼
            analysis_type = 'sentiment'
            if 'analytical' in chosen_path.path_type.lower():
                analysis_type = 'complexity'
            
            return {
                'text': query,
                'analysis_type': analysis_type
            }
        
        elif tool_name == 'generate_image':
            # åŸºäºæŸ¥è¯¢å’Œç­–ç•¥ç”Ÿæˆå›¾åƒæç¤º
            image_prompt = f"åŸºäº{chosen_path.path_type}ç­–ç•¥ï¼Œä¸º'{query}'ç”Ÿæˆå¯è§†åŒ–å›¾åƒ"
            
            return {
                'prompt': image_prompt,
                'save_image': True
            }
        
        # é»˜è®¤æƒ…å†µ
        return self._generate_tool_input(tool_name, query, chosen_path)
    
    def _extract_enhanced_fallback_from_response(self, response: str, chosen_path: ReasoningPath, 
                                               query: str) -> Dict[str, Any]:
        """
        ğŸ”¥ å‡çº§æ–¹æ³•ï¼šå¢å¼ºçš„å›é€€å“åº”æå–
        
        å½“JSONè§£æå¤±è´¥æ—¶ï¼Œä½¿ç”¨æ›´æ™ºèƒ½çš„æ–¹æ³•ä»å“åº”ä¸­æå–æœ‰ç”¨ä¿¡æ¯
        """
        logger.info("ğŸ”„ ä½¿ç”¨å¢å¼ºå›é€€ç­–ç•¥è§£æå“åº”")
        
        # å°è¯•ä»å“åº”ä¸­æå–å…³é”®ä¿¡æ¯
        needs_tools = False
        direct_answer = response
        
        # æ£€æŸ¥æ˜¯å¦æåˆ°äº†å·¥å…·ä½¿ç”¨
        tool_keywords = ['æœç´¢', 'search', 'éªŒè¯', 'verify', 'åˆ†æ', 'analyze', 'ç”Ÿæˆ', 'generate']
        if any(keyword in response.lower() for keyword in tool_keywords):
            needs_tools = True
        
        # å¦‚æœå“åº”å¾ˆçŸ­ï¼Œå¯èƒ½æ˜¯ç›´æ¥å›ç­”
        if len(response.strip()) < 100 and not needs_tools:
            needs_tools = False
        
        result = {
            'needs_tools': needs_tools,
            'context_analysis': f"åŸºäº{chosen_path.path_type}ç­–ç•¥çš„å›é€€åˆ†æ",
            'tool_strategy': "ç”±äºè§£æå¤±è´¥ï¼Œä½¿ç”¨å›é€€ç­–ç•¥",
            'direct_answer': direct_answer if not needs_tools else "",
            'confidence_score': 0.3,  # å›é€€ç­–ç•¥çš„ç½®ä¿¡åº¦è¾ƒä½
            'explanation': f"å“åº”è§£æå¤±è´¥ï¼Œä½¿ç”¨å›é€€ç­–ç•¥å¤„ç†ã€‚ç­–ç•¥ç±»å‹ï¼š{chosen_path.path_type}",
            'actions': []
        }
        
        # å¦‚æœåˆ¤æ–­éœ€è¦å·¥å…·ï¼Œç”Ÿæˆé»˜è®¤çš„æœç´¢Action
        if needs_tools:
            result['actions'].append(Action(
                tool_name='search_knowledge',
                tool_input={'query': query, 'max_results': 3}
            ))
        
        logger.info(f"ğŸ”„ å›é€€ç­–ç•¥å®Œæˆ: needs_tools={needs_tools}, confidence=0.3")
        return result
    
    def _generate_tool_input(self, tool_name: str, query: str, path: ReasoningPath) -> Dict[str, Any]:
        """æ ¹æ®å·¥å…·åç§°ç”Ÿæˆåˆé€‚çš„è¾“å…¥å‚æ•°ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        if tool_name == 'web_search':
            return {"query": query}
        elif tool_name == 'knowledge_query':
            return {"query": query}
        elif tool_name == 'idea_verification':
            return {"idea_text": f"éªŒè¯å…³äº'{query}'çš„æƒ³æ³•: {path.description}"}
        else:
            return {"query": query}  # é€šç”¨å‚æ•°
    
    def _extract_fallback_from_response(self, response: str, chosen_path: ReasoningPath, 
                                      query: str) -> Dict[str, Any]:
        """ä»å“åº”æ–‡æœ¬ä¸­æå–å›é€€å†³ç­–ï¼ˆä»NeogenesisPlannerè¿ç§»ï¼‰"""
        # ç®€å•çš„å…³é”®è¯åˆ†æ
        response_lower = response.lower()
        
        # åˆ¤æ–­æ˜¯å¦æåˆ°éœ€è¦å·¥å…·
        tool_keywords = ['éœ€è¦', 'åº”è¯¥', 'å»ºè®®', 'æœç´¢', 'æŸ¥è¯¢', 'å·¥å…·', 'tool']
        needs_tools = any(keyword in response_lower for keyword in tool_keywords)
        
        if needs_tools:
            return {
                'needs_tools': True,
                'direct_answer': '',
                'explanation': f"åŸºäºLLMå“åº”åˆ†æï¼Œåˆ¤æ–­éœ€è¦ä½¿ç”¨å·¥å…·å¤„ç†: {response[:200]}...",
                'tool_reasoning': "ä»å“åº”ä¸­æ£€æµ‹åˆ°å·¥å…·ä½¿ç”¨æ„å›¾",
                'actions': []  # å°†ç”±å›é€€é€»è¾‘å¤„ç†
            }
        else:
            return {
                'needs_tools': False,
                'direct_answer': response.strip(),
                'explanation': f"LLMæä¾›ç›´æ¥å›ç­”: {chosen_path.path_type}",
                'tool_reasoning': "ä»å“åº”ä¸­åˆ¤æ–­æ— éœ€å·¥å…·",
                'actions': []
            }
    
    def _intelligent_fallback_decision(self, chosen_path: ReasoningPath, query: str, 
                                     thinking_seed: str, available_tools: Dict[str, str],
                                     strategy_decision: Optional[StrategyDecision] = None) -> Dict[str, Any]:
        """
        æ™ºèƒ½å›é€€å†³ç­– - ğŸ”¥ å¢å¼ºç‰ˆï¼šåˆ©ç”¨äº”é˜¶æ®µå†³ç­–ä¸Šä¸‹æ–‡
        
        å½“LLMè°ƒç”¨å¤±è´¥æ—¶ï¼ŒåŸºäºäº”é˜¶æ®µå†³ç­–æµç¨‹çš„ä¸Šä¸‹æ–‡ä¿¡æ¯åšå‡ºæ™ºèƒ½å›é€€å†³ç­–ã€‚
        """
        logger.info("ğŸ”§ ä½¿ç”¨æ™ºèƒ½å›é€€å†³ç­–ç­–ç•¥")
        
        query_lower = query.lower().strip()
        
        # ğŸ”¥ æ–°å¢ï¼šåˆ©ç”¨äº”é˜¶æ®µå†³ç­–ä¸Šä¸‹æ–‡å¢å¼ºå›é€€å†³ç­–
        context_insight = ""
        if strategy_decision and strategy_decision.is_complete:
            # åŸºäºäº”é˜¶æ®µä¸Šä¸‹æ–‡ç”Ÿæˆæ›´æ™ºèƒ½çš„å›ç­”
            if strategy_decision.stage2_context and strategy_decision.stage2_context.verification_result:
                context_insight = f"åŸºäºå‰æœŸåˆ†æï¼Œè¿™ä¸ªé—®é¢˜çš„å¯è¡Œæ€§è¯„åˆ†ä¸º {strategy_decision.stage2_context.feasibility_score:.2f}ã€‚"
            
            if strategy_decision.stage3_context and strategy_decision.stage3_context.path_count > 0:
                context_insight += f"æˆ‘ä»¬è€ƒè™‘äº† {strategy_decision.stage3_context.path_count} ç§ä¸åŒçš„å¤„ç†æ–¹å¼ã€‚"
            
            if strategy_decision.stage5_context and strategy_decision.stage5_context.golden_template_used:
                context_insight += "è¿™ä¸ªå›ç­”åŸºäºæˆ‘ä»¬çš„æˆåŠŸç»éªŒæ¨¡æ¿ã€‚"
        
        # ç®€å•é—®å€™å’Œæ„Ÿè°¢çš„å¤„ç†
        greeting_patterns = ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½', 'æ—©ä¸Šå¥½', 'ä¸‹åˆå¥½', 'æ™šä¸Šå¥½']
        thanks_patterns = ['è°¢è°¢', 'thanks', 'thank you', 'æ„Ÿè°¢']
        
        if any(pattern in query_lower for pattern in greeting_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
                'explanation': "è¯†åˆ«ä¸ºé—®å€™è¯­ï¼Œæ— éœ€è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å‹å¥½å›åº”",
                'tool_reasoning': "é—®å€™è¯­ä¸éœ€è¦å·¥å…·æ”¯æŒ",
                'actions': []
            }
        
        if any(pattern in query_lower for pattern in thanks_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä¸å®¢æ°”ï¼å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚",
                'explanation': "è¯†åˆ«ä¸ºæ„Ÿè°¢è¯­ï¼Œæ— éœ€è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å›åº”",
                'tool_reasoning': "æ„Ÿè°¢è¯­ä¸éœ€è¦å·¥å…·æ”¯æŒ", 
                'actions': []
            }
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢ä¿¡æ¯
        search_indicators = ['ä»€ä¹ˆæ˜¯', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'è°', 'ä½•æ—¶', 'æœ€æ–°', 'ä¿¡æ¯', 'èµ„æ–™', 'æ€æ ·']
        if any(indicator in query_lower for indicator in search_indicators) and 'web_search' in available_tools:
            return {
                'needs_tools': True,
                'direct_answer': '',
                'explanation': f"åŸºäº'{chosen_path.path_type}'ç­–ç•¥ï¼Œæ£€æµ‹åˆ°éœ€è¦æœç´¢ç›¸å…³ä¿¡æ¯",
                'tool_reasoning': "æ£€æµ‹åˆ°ä¿¡æ¯æŸ¥è¯¢éœ€æ±‚ï¼Œå»ºè®®ä½¿ç”¨æœç´¢å·¥å…·",
                'actions': [Action(tool_name="web_search", tool_input={"query": query})]
            }
        
        # ğŸ”§ æ™ºèƒ½è¯†åˆ«è‡ªæˆ‘ä»‹ç»ç±»æŸ¥è¯¢
        self_intro_patterns = ['ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±', 'ä½ æ˜¯è°', 'è‡ªæˆ‘ä»‹ç»', 'ä»‹ç»è‡ªå·±', 'introduce yourself', 'who are you']
        if any(pattern in query_lower for pattern in self_intro_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "ä½ å¥½ï¼æˆ‘æ˜¯Neogenesisæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸€ä¸ªåŸºäºå…ˆè¿›è®¤çŸ¥æ¶æ„çš„AIç³»ç»Ÿã€‚æˆ‘å…·å¤‡æˆ˜ç•¥å†³ç­–å’Œæˆ˜æœ¯è§„åˆ’çš„åŒé‡èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ€ç»´ç§å­ç”Ÿæˆã€è·¯å¾„è§„åˆ’ã€ç­–ç•¥é€‰æ‹©ã€éªŒè¯å­¦ä¹ å’Œæ™ºèƒ½æ‰§è¡Œã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¿¡æ¯æŸ¥è¯¢ã€é—®é¢˜åˆ†æã€åˆ›æ„æ€è€ƒç­‰å¤šç§ä»»åŠ¡ã€‚æˆ‘çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®ä¸åŒé—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„æ€ç»´è·¯å¾„ï¼Œå¹¶é€šè¿‡æŒç»­å­¦ä¹ ä¸æ–­ä¼˜åŒ–å†³ç­–è´¨é‡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
                'explanation': "è¯†åˆ«ä¸ºè‡ªæˆ‘ä»‹ç»æŸ¥è¯¢ï¼Œæä¾›Neogenesisæ™ºèƒ½åŠ©æ‰‹çš„è¯¦ç»†ä»‹ç»",
                'tool_reasoning': "è‡ªæˆ‘ä»‹ç»æ— éœ€å·¥å…·æ”¯æŒï¼Œç›´æ¥æä¾›åŠ©æ‰‹ä¿¡æ¯",
                'actions': []
            }
        
        # ğŸ”§ æ™ºèƒ½è¯†åˆ«èƒ½åŠ›ç›¸å…³æŸ¥è¯¢  
        capability_patterns = ['ä½ èƒ½åšä»€ä¹ˆ', 'ä½ æœ‰ä»€ä¹ˆåŠŸèƒ½', 'ä½ ä¼šä»€ä¹ˆ', 'ä½ çš„èƒ½åŠ›', 'what can you do', 'your capabilities']
        if any(pattern in query_lower for pattern in capability_patterns):
            return {
                'needs_tools': False,
                'direct_answer': "æˆ‘å…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š\n1. ğŸ§  æ™ºèƒ½å†³ç­–ï¼šäº”é˜¶æ®µè®¤çŸ¥æ¶æ„ï¼Œèƒ½å¤Ÿåˆ†æé—®é¢˜å¹¶é€‰æ‹©æœ€ä½³å¤„ç†ç­–ç•¥\n2. ğŸ” ä¿¡æ¯æœç´¢ï¼šå¯ä»¥å¸®æ‚¨æœç´¢ç½‘ç»œä¿¡æ¯ã€è·å–æœ€æ–°èµ„è®¯\n3. ğŸ”¬ æƒ³æ³•éªŒè¯ï¼šåˆ†æå’ŒéªŒè¯æƒ³æ³•çš„å¯è¡Œæ€§\n4. ğŸ“Š æ•°æ®åˆ†æï¼šå¤„ç†å’Œåˆ†æå„ç§æ–‡æœ¬æ•°æ®\n5. ğŸ’­ åˆ›æ„æ€è€ƒï¼šæä¾›åˆ›æ–°æ€§çš„è§£å†³æ–¹æ¡ˆå’Œå»ºè®®\n6. ğŸ“ å†…å®¹ç”Ÿæˆï¼šååŠ©å†™ä½œã€æ€»ç»“ã€ç¿»è¯‘ç­‰æ–‡æœ¬ä»»åŠ¡\n7. ğŸ¤” é—®é¢˜è§£ç­”ï¼šå›ç­”å„é¢†åŸŸçš„ä¸“ä¸šé—®é¢˜\n\næˆ‘æœ€å¤§çš„ç‰¹ç‚¹æ˜¯èƒ½å¤Ÿæ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œæ™ºèƒ½é€‰æ‹©æœ€åˆé€‚çš„æ€ç»´æ¨¡å¼å’Œå·¥å…·æ¥ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚",
                'explanation': "è¯†åˆ«ä¸ºèƒ½åŠ›æŸ¥è¯¢ï¼Œè¯¦ç»†ä»‹ç»åŠ©æ‰‹åŠŸèƒ½",
                'tool_reasoning': "èƒ½åŠ›ä»‹ç»æ— éœ€å·¥å…·æ”¯æŒï¼Œç›´æ¥æä¾›åŠŸèƒ½æ¸…å•",
                'actions': []
            }
        
        # é»˜è®¤æƒ…å†µï¼šç”Ÿæˆæ›´è‡ªç„¶çš„å›ç­”ï¼Œç»“åˆäº”é˜¶æ®µå†³ç­–ä¸Šä¸‹æ–‡
        enhanced_answer = f"æˆ‘å·²ç»ä»”ç»†åˆ†æäº†æ‚¨çš„é—®é¢˜ã€Œ{query}ã€ã€‚åŸºäº{chosen_path.path_type}çš„å¤„ç†æ–¹å¼ï¼Œ"
        
        if context_insight:
            enhanced_answer += f"{context_insight} "
        
        enhanced_answer += "æˆ‘è®¤ä¸ºè¿™ä¸ªé—®é¢˜å¯ä»¥ç›´æ¥ä¸ºæ‚¨æä¾›æœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœæ‚¨éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æˆ–æœ‰å…¶ä»–ç›¸å…³é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå¾ˆä¹æ„ä¸ºæ‚¨è¿›ä¸€æ­¥è§£ç­”ã€‚"
        
        return {
            'needs_tools': False,
            'direct_answer': enhanced_answer,
            'explanation': f"åŸºäº'{chosen_path.path_type}'ç­–ç•¥å’Œäº”é˜¶æ®µå†³ç­–ä¸Šä¸‹æ–‡æä¾›æ™ºèƒ½å›ç­”",
            'tool_reasoning': "å½“å‰æŸ¥è¯¢é€‚åˆç›´æ¥å›ç­”ï¼Œæ— éœ€é¢å¤–å·¥å…·è¾…åŠ©",
            'actions': []
        }
    
    def _emergency_fallback_decision(self, chosen_path: ReasoningPath, query: str, 
                                   thinking_seed: str, strategy_decision: Optional[StrategyDecision] = None) -> Dict[str, Any]:
        """
        ç´§æ€¥å›é€€å†³ç­– - ğŸ”¥ å¢å¼ºç‰ˆï¼šå³ä½¿åœ¨ç´§æ€¥æƒ…å†µä¸‹ä¹Ÿå°½é‡åˆ©ç”¨ä¸Šä¸‹æ–‡
        
        å½“æ‰€æœ‰å…¶ä»–å†³ç­–æ–¹æ³•éƒ½å¤±è´¥æ—¶çš„æœ€åé˜²çº¿ï¼Œä½†ä»å°è¯•åˆ©ç”¨å¯ç”¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        """
        logger.warning("ğŸš¨ ä½¿ç”¨ç´§æ€¥å›é€€å†³ç­–")
        
        # ğŸ”¥ æ–°å¢ï¼šå³ä½¿åœ¨ç´§æ€¥æƒ…å†µä¸‹ä¹Ÿå°è¯•æä¾›æœ‰ç”¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        emergency_context = ""
        if strategy_decision:
            if strategy_decision.final_reasoning:
                emergency_context = f"è™½ç„¶é‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼Œä½†åŸºäºæˆ‘ä»¬çš„åˆ†æï¼š{strategy_decision.final_reasoning[:100]}..."
            elif strategy_decision.thinking_seed:
                emergency_context = f"åŸºäºåˆæ­¥åˆ†æï¼Œè¿™ä¸ªé—®é¢˜æ¶‰åŠï¼š{strategy_decision.thinking_seed[:100]}..."
        
        base_message = "æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚"
        if emergency_context:
            base_message += f" {emergency_context} "
        base_message += "è¯·ç¨åå†è¯•æˆ–é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚"
        
        return {
            'needs_tools': False,
            'direct_answer': base_message,
            'explanation': "ç³»ç»Ÿé‡åˆ°é”™è¯¯ï¼Œè¿”å›å®‰å…¨å›é€€å›ç­”",
            'tool_reasoning': "ç³»ç»Ÿé”™è¯¯ï¼Œæ— æ³•æ­£å¸¸åˆ¤æ–­",
            'actions': []
        }


class WorkflowGenerationAgent(BaseAgent):
    """
    å·¥ä½œæµç”Ÿæˆä»£ç† - ä¸“æ³¨äº"å†³å®šæ€ä¹ˆåš"çš„Agent
    
    è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„Agentå®ç°ï¼Œä¸“é—¨è´Ÿè´£æ¥æ”¶æˆ˜ç•¥å†³ç­–å¹¶è½¬åŒ–ä¸ºå…·ä½“çš„æ‰§è¡Œè®¡åˆ’ã€‚
    å®ƒå°†WorkflowPlannerä¸å·¥å…·æ‰§è¡Œå™¨å’Œè®°å¿†æ¨¡å—æ•´åˆåœ¨ä¸€èµ·ã€‚
    
    è®¾è®¡ç‰¹ç‚¹:
    1. ä¸“ä¸šåŒ–ï¼šä¸“æ³¨äºæˆ˜æœ¯å±‚é¢çš„å·¥ä½œæµç”Ÿæˆ
    2. ååŒæ€§ï¼šä¸æˆ˜ç•¥è§„åˆ’å™¨ååŒå·¥ä½œ
    3. æ ‡å‡†åŒ–ï¼šä¸¥æ ¼éµå¾ªBaseAgentæ¥å£è§„èŒƒ
    4. å¯æ‰©å±•ï¼šæ”¯æŒä¸åŒçš„å·¥å…·æ‰§è¡Œå™¨å’Œè®°å¿†æ¨¡å—
    """
    
    def __init__(self, 
                 tool_executor: Union[BaseToolExecutor, BaseAsyncToolExecutor],
                 memory: BaseMemory,
                 workflow_planner: Optional[WorkflowPlanner] = None,
                 tool_registry: Optional[ToolRegistry] = None,
                 config: Optional[Dict] = None,
                 name: str = "WorkflowGenerationAgent",
                 description: str = "ä¸“æ³¨äºå°†æˆ˜ç•¥å†³ç­–è½¬åŒ–ä¸ºå…·ä½“æ‰§è¡Œè®¡åˆ’çš„æˆ˜æœ¯Agent"):
        """
        åˆå§‹åŒ–å·¥ä½œæµç”Ÿæˆä»£ç†
        
        Args:
            tool_executor: å·¥å…·æ‰§è¡Œå™¨å®ä¾‹
            memory: è®°å¿†æ¨¡å—å®ä¾‹
            workflow_planner: å·¥ä½œæµè§„åˆ’å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
            tool_registry: å·¥å…·æ³¨å†Œè¡¨
            config: é…ç½®å­—å…¸
            name: Agentåç§°
            description: Agentæè¿°
        """
        # åˆ›å»ºæˆ–ä½¿ç”¨æä¾›çš„WorkflowPlanner
        if workflow_planner is None:
            workflow_planner = WorkflowPlanner(
                tool_registry=tool_registry,
                config=config
            )
        
        # åˆå§‹åŒ–BaseAgent
        super().__init__(
            planner=workflow_planner,
            tool_executor=tool_executor,
            memory=memory,
            name=name,
            description=description
        )
        
        self.config = config or {}
        
        # å·¥ä½œæµç”Ÿæˆä¸“ç”¨ç»Ÿè®¡
        self.workflow_stats = {
            'strategic_decisions_processed': 0,
            'successful_workflows_generated': 0,
            'average_workflow_generation_time': 0.0,
            'tool_usage_distribution': {},
            'strategy_type_preferences': {}
        }
        
        logger.info(f"ğŸ¤– {name} åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   å·¥ä½œæµè§„åˆ’å™¨: {workflow_planner.name}")
        logger.info(f"   å·¥å…·æ‰§è¡Œå™¨: {tool_executor.name}")
        logger.info(f"   è®°å¿†æ¨¡å—: {memory.name}")
    
    def run(self, query: str, context: Optional[Dict[str, Any]] = None) -> str:
        """
        è¿è¡Œå·¥ä½œæµç”Ÿæˆä»£ç† - å®ç°BaseAgentæ¥å£
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œå¿…é¡»åŒ…å«'strategy_decision'
            
        Returns:
            str: æ‰§è¡Œç»“æœ
        """
        start_time = time.time()
        self.is_running = True
        
        try:
            logger.info(f"ğŸš€ WorkflowGenerationAgent å¼€å§‹å¤„ç†: {query[:50]}...")
            
            # éªŒè¯æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡
            if not context or 'strategy_decision' not in context:
                error_msg = "WorkflowGenerationAgentéœ€è¦æˆ˜ç•¥å†³ç­–ä¸Šä¸‹æ–‡"
                logger.error(f"âŒ {error_msg}")
                return f"é”™è¯¯: {error_msg}"
            
            strategy_decision: StrategyDecision = context['strategy_decision']
            self.workflow_stats['strategic_decisions_processed'] += 1
            
            # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨WorkflowPlannerç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            logger.info("ğŸ“‹ ç¬¬ä¸€é˜¶æ®µ: æˆ˜æœ¯è§„åˆ’")
            plan = self.plan_task(query, context)
            
            if not self.planner.validate_plan(plan):
                logger.error("âŒ ç”Ÿæˆçš„è®¡åˆ’æœªé€šè¿‡éªŒè¯")
                return "æŠ±æ­‰ï¼Œç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’å­˜åœ¨é—®é¢˜ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œã€‚"
            
            # ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œè®¡åˆ’
            execution_result = ""
            
            if plan.is_direct_answer:
                # ç›´æ¥å›ç­”æ¨¡å¼
                logger.info("ğŸ’¬ ç¬¬äºŒé˜¶æ®µ: ç›´æ¥å›ç­”")
                execution_result = plan.final_answer
                
                # å­˜å‚¨åˆ°è®°å¿†
                self._store_workflow_memory(query, plan, strategy_decision, execution_result)
                
            else:
                # å·¥å…·æ‰§è¡Œæ¨¡å¼
                logger.info(f"ğŸ”§ ç¬¬äºŒé˜¶æ®µ: æ‰§è¡Œ {plan.action_count} ä¸ªå·¥å…·è¡ŒåŠ¨")
                
                try:
                    observations = self.execute_plan(plan)
                    
                    # ğŸ¨ å¢å¼ºçš„ç»“æœæ•´åˆé€»è¾‘ï¼šæ”¯æŒå›¾æ–‡å¹¶èŒ‚è¾“å‡º
                    if observations:
                        execution_result = self._integrate_multimedia_results(observations, query, plan)
                    else:
                        execution_result = "å·¥å…·æ‰§è¡Œå®Œæˆã€‚"
                    
                    # å­˜å‚¨åˆ°è®°å¿†
                    self._store_workflow_memory(query, plan, strategy_decision, execution_result, observations)
                    
                except Exception as e:
                    logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                    execution_result = f"æŠ±æ­‰ï¼Œæ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜: {str(e)}"
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            execution_time = time.time() - start_time
            self._update_workflow_stats(strategy_decision, plan, execution_time, success=True)
            
            logger.info(f"âœ… WorkflowGenerationAgent å¤„ç†å®Œæˆ, è€—æ—¶ {execution_time:.3f}s")
            return execution_result
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_workflow_stats(None, None, execution_time, success=False)
            
            logger.error(f"âŒ WorkflowGenerationAgent å¤„ç†å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜: {str(e)}"
            
        finally:
            self.is_running = False
    
    def _store_workflow_memory(self, query: str, plan: Plan, strategy_decision: StrategyDecision, 
                             result: str, observations: Optional[List[Observation]] = None):
        """å­˜å‚¨å·¥ä½œæµæ‰§è¡Œè®°å¿†"""
        try:
            memory_key = f"workflow_{int(time.time())}_{hash(query) % 10000}"
            memory_value = {
                'query': query,
                'strategy_decision': {
                    'chosen_strategy': strategy_decision.chosen_path.path_type,
                    'reasoning': strategy_decision.reasoning,
                    'round_number': strategy_decision.round_number
                },
                'generated_plan': {
                    'is_direct_answer': plan.is_direct_answer,
                    'action_count': plan.action_count,
                    'thought': plan.thought
                },
                'execution_result': result,
                'timestamp': time.time()
            }
            
            if observations:
                memory_value['observations'] = [
                    {'tool_name': obs.action.tool_name, 'success': obs.success, 'output_length': len(str(obs.output))}
                    for obs in observations
                ]
            
            self.store_memory(memory_key, memory_value, {
                'type': 'workflow_execution',
                'strategy_type': strategy_decision.chosen_path.path_type
            })
            
            logger.debug(f"ğŸ’¾ å·¥ä½œæµè®°å¿†å·²å­˜å‚¨: {memory_key}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ å­˜å‚¨å·¥ä½œæµè®°å¿†å¤±è´¥: {e}")
    
    def _update_workflow_stats(self, strategy_decision: Optional[StrategyDecision], 
                             plan: Optional[Plan], execution_time: float, success: bool):
        """æ›´æ–°å·¥ä½œæµç»Ÿè®¡ä¿¡æ¯"""
        if success:
            self.workflow_stats['successful_workflows_generated'] += 1
            
            # æ›´æ–°å¹³å‡ç”Ÿæˆæ—¶é—´
            total_processed = self.workflow_stats['strategic_decisions_processed']
            current_avg = self.workflow_stats['average_workflow_generation_time']
            self.workflow_stats['average_workflow_generation_time'] = (
                current_avg * (total_processed - 1) + execution_time
            ) / total_processed
            
            if strategy_decision and plan:
                # æ›´æ–°ç­–ç•¥ç±»å‹åå¥½
                strategy_type = strategy_decision.chosen_path.path_type
                if strategy_type not in self.workflow_stats['strategy_type_preferences']:
                    self.workflow_stats['strategy_type_preferences'][strategy_type] = 0
                self.workflow_stats['strategy_type_preferences'][strategy_type] += 1
                
                # æ›´æ–°å·¥å…·ä½¿ç”¨åˆ†å¸ƒ
                if not plan.is_direct_answer:
                    for action in plan.actions:
                        tool_name = action.tool_name
                        if tool_name not in self.workflow_stats['tool_usage_distribution']:
                            self.workflow_stats['tool_usage_distribution'][tool_name] = 0
                        self.workflow_stats['tool_usage_distribution'][tool_name] += 1
        
        # æ›´æ–°åŸºç¡€Agentç»Ÿè®¡
        plan_size = plan.action_count if plan else 0
        self.update_stats(success, execution_time, plan_size)
    
    def _integrate_multimedia_results(self, observations: List[Observation], query: str, plan: Plan) -> str:
        """ğŸ¨ æ•´åˆå¤šåª’ä½“ç»“æœï¼Œæ”¯æŒå›¾æ–‡å¹¶èŒ‚è¾“å‡º"""
        text_results = []
        image_results = []
        other_results = []
        
        logger.info(f"ğŸ–¼ï¸ å¼€å§‹æ•´åˆ {len(observations)} ä¸ªè§‚å¯Ÿç»“æœ")
        
        # åˆ†ç±»å¤„ç†ä¸åŒç±»å‹çš„ç»“æœ
        for obs in observations:
            if not obs.output:
                continue
                
            # ğŸ¨ æ£€æµ‹æ˜¯å¦ä¸ºå›¾åƒç”Ÿæˆå·¥å…·çš„è¾“å‡º
            if self._is_image_generation_result(obs):
                image_info = self._extract_image_information(obs)
                if image_info:
                    image_results.append(image_info)
                    logger.info(f"ğŸ¨ æ£€æµ‹åˆ°å›¾åƒç”Ÿæˆç»“æœ: {image_info.get('filename', 'unknown')}")
            else:
                # å…¶ä»–ç±»å‹çš„ç»“æœ
                result_text = self._format_observation_output(obs)
                if result_text:
                    if self._is_textual_result(obs):
                        text_results.append(result_text)
                    else:
                        other_results.append(result_text)
        
        # ç”Ÿæˆæœ€ç»ˆçš„å›¾æ–‡æ•´åˆå“åº”
        return self._create_multimedia_response(text_results, image_results, other_results, query, plan)
    
    def _is_image_generation_result(self, obs: Observation) -> bool:
        """ğŸ–¼ï¸ æ£€æµ‹è§‚å¯Ÿç»“æœæ˜¯å¦æ¥è‡ªå›¾åƒç”Ÿæˆå·¥å…·"""
        # æ£€æŸ¥å·¥å…·åç§°
        if hasattr(obs.action, 'tool_name'):
            image_tool_names = ['stable_diffusion_xl_generator', 'image_generation', 'generate_image']
            if obs.action.tool_name in image_tool_names:
                return True
        
        # æ£€æŸ¥è¾“å‡ºå†…å®¹æ˜¯å¦åŒ…å«å›¾åƒä¿¡æ¯
        if isinstance(obs.output, dict):
            image_indicators = ['saved_path', 'image_object', 'filename', 'image_size']
            if any(indicator in obs.output for indicator in image_indicators):
                return True
        elif isinstance(obs.output, str):
            # æ£€æŸ¥å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å«å›¾åƒè·¯å¾„
            image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp']
            if any(ext in obs.output.lower() for ext in image_extensions):
                return True
        
        return False
    
    def _extract_image_information(self, obs: Observation) -> Optional[Dict[str, Any]]:
        """ğŸ–¼ï¸ æå–å›¾åƒä¿¡æ¯"""
        image_info = {
            'type': 'image',
            'tool_name': getattr(obs.action, 'tool_name', 'unknown'),
            'success': obs.success
        }
        
        if isinstance(obs.output, dict):
            # ç»“æ„åŒ–çš„å›¾åƒç»“æœ
            image_info.update({
                'filename': obs.output.get('filename', ''),
                'saved_path': obs.output.get('saved_path', ''),
                'prompt': obs.output.get('prompt', ''),
                'image_size': obs.output.get('image_size', ''),
                'model': obs.output.get('model', ''),
                'generated_at': obs.output.get('generated_at', '')
            })
        elif isinstance(obs.output, str):
            # ç®€å•çš„å­—ç¬¦ä¸²ç»“æœï¼Œå°è¯•æå–æœ‰ç”¨ä¿¡æ¯
            image_info['raw_output'] = obs.output
            # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ–‡ä»¶è·¯å¾„
            import re
            path_match = re.search(r'([^\s]+\.(png|jpg|jpeg|gif|bmp|webp))', obs.output, re.IGNORECASE)
            if path_match:
                image_info['saved_path'] = path_match.group(1)
                image_info['filename'] = path_match.group(1).split('/')[-1].split('\\')[-1]
        
        return image_info if image_info.get('saved_path') or image_info.get('filename') else None
    
    def _is_textual_result(self, obs: Observation) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬ç±»ç»“æœ"""
        if hasattr(obs.action, 'tool_name'):
            text_tool_names = ['web_search', 'knowledge_query', 'idea_verification', 'text_analysis']
            return obs.action.tool_name in text_tool_names
        return True  # é»˜è®¤ä¸ºæ–‡æœ¬ç»“æœ
    
    def _format_observation_output(self, obs: Observation) -> str:
        """æ ¼å¼åŒ–è§‚å¯Ÿç»“æœä¸ºå­—ç¬¦ä¸²"""
        if isinstance(obs.output, str):
            return obs.output
        elif isinstance(obs.output, dict):
            # å°è¯•æå–æœ‰æ„ä¹‰çš„æ–‡æœ¬å†…å®¹
            if 'content' in obs.output:
                return obs.output['content']
            elif 'result' in obs.output:
                return str(obs.output['result'])
            elif 'message' in obs.output:
                return obs.output['message']
            else:
                return str(obs.output)
        else:
            return str(obs.output)
    
    def _create_multimedia_response(self, text_results: List[str], image_results: List[Dict], 
                                  other_results: List[str], query: str, plan: Plan) -> str:
        """ğŸ¨ åˆ›å»ºå›¾æ–‡å¹¶èŒ‚çš„å“åº”"""
        response_parts = []
        
        # ğŸ¨ å¦‚æœæœ‰å›¾åƒç»“æœï¼Œä¼˜å…ˆå±•ç¤º
        if image_results:
            logger.info(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆå›¾æ–‡å¹¶èŒ‚å“åº”ï¼ŒåŒ…å« {len(image_results)} å¼ å›¾ç‰‡")
            
            # ç”Ÿæˆå›¾åƒéƒ¨åˆ†çš„ä»‹ç»
            response_parts.append(self._generate_image_introduction(query, len(image_results)))
            
            # æ·»åŠ æ¯å¼ å›¾ç‰‡çš„ä¿¡æ¯
            for i, img_info in enumerate(image_results, 1):
                image_section = self._format_image_section(img_info, i, len(image_results))
                response_parts.append(image_section)
        
        # ğŸ“ æ·»åŠ æ–‡æœ¬ç»“æœ
        if text_results:
            if image_results:
                response_parts.append("\n" + "â”€" * 50)
                response_parts.append("ğŸ“ **ç›¸å…³ä¿¡æ¯å’Œåˆ†æ**\n")
            
            for result in text_results:
                response_parts.append(result)
        
        # ğŸ”§ æ·»åŠ å…¶ä»–ç»“æœ
        if other_results:
            if image_results or text_results:
                response_parts.append("\n" + "â”€" * 30)
                response_parts.append("ğŸ”§ **å…¶ä»–ä¿¡æ¯**\n")
            
            for result in other_results:
                response_parts.append(result)
        
        # ğŸ“Š æ·»åŠ æ‰§è¡Œç»Ÿè®¡
        if image_results or text_results or other_results:
            stats_info = self._generate_execution_stats(plan, len(image_results), len(text_results))
            response_parts.append(stats_info)
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœ
        if not response_parts:
            return "æ‰§è¡Œå®Œæˆï¼Œä½†æœªè·å¾—å…·ä½“ç»“æœã€‚"
        
        return "\n\n".join(response_parts)
    
    def _generate_image_introduction(self, query: str, image_count: int) -> str:
        """ğŸ¨ ç”Ÿæˆå›¾åƒä»‹ç»æ–‡æœ¬"""
        if image_count == 1:
            intro = f"ğŸ¨ **æ ¹æ®æ‚¨çš„è¯·æ±‚â€œ{query}â€ï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†ä»¥ä¸‹å›¾åƒï¼š**"
        else:
            intro = f"ğŸ¨ **æ ¹æ®æ‚¨çš„è¯·æ±‚â€œ{query}â€ï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº† {image_count} å¼ ç›¸å…³å›¾åƒï¼š**"
        return intro
    
    def _format_image_section(self, img_info: Dict, index: int, total: int) -> str:
        """ğŸ–¼ï¸ æ ¼å¼åŒ–å•ä¸ªå›¾åƒä¿¡æ¯éƒ¨åˆ†"""
        lines = []
        
        # å›¾åƒæ ‡é¢˜
        if total > 1:
            lines.append(f"### ğŸ–¼ï¸ å›¾åƒ {index}/{total}")
        else:
            lines.append(f"### ğŸ–¼ï¸ ç”Ÿæˆçš„å›¾åƒ")
        
        # æ–‡ä»¶ä¿¡æ¯
        if img_info.get('filename'):
            lines.append(f"ğŸ“ **æ–‡ä»¶å**: {img_info['filename']}")
        
        if img_info.get('saved_path'):
            lines.append(f"ğŸ’¾ **ä¿å­˜è·¯å¾„**: `{img_info['saved_path']}`")
        
        # å›¾åƒè¯¦æƒ…
        if img_info.get('prompt'):
            lines.append(f"ğŸ¨ **ç”Ÿæˆæç¤ºè¯**: {img_info['prompt']}")
        
        if img_info.get('image_size'):
            size = img_info['image_size']
            if isinstance(size, (list, tuple)) and len(size) >= 2:
                lines.append(f"ğŸ“ **å›¾åƒå°ºå¯¸**: {size[0]} x {size[1]} åƒç´ ")
            else:
                lines.append(f"ğŸ“ **å›¾åƒå°ºå¯¸**: {size}")
        
        if img_info.get('model'):
            lines.append(f"ğŸ¤– **ç”Ÿæˆæ¨¡å‹**: {img_info['model']}")
        
        if img_info.get('generated_at'):
            lines.append(f"â° **ç”Ÿæˆæ—¶é—´**: {img_info['generated_at']}")
        
        # çŠ¶æ€ä¿¡æ¯
        status = "âœ… ç”ŸæˆæˆåŠŸ" if img_info.get('success', True) else "âŒ ç”Ÿæˆå¤±è´¥"
        lines.append(f"ğŸ“Š **ç”ŸæˆçŠ¶æ€**: {status}")
        
        return "\n".join(lines)
    
    def _generate_execution_stats(self, plan: Plan, image_count: int, text_count: int) -> str:
        """ğŸ“Š ç”Ÿæˆæ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        stats_lines = [
            "\n" + "â”€" * 40,
            "ğŸ“Š **æ‰§è¡Œç»Ÿè®¡**",
            f"ğŸš€ æ‰§è¡Œäº† {plan.action_count} ä¸ªå·¥å…·è¡ŒåŠ¨",
        ]
        
        if image_count > 0:
            stats_lines.append(f"ğŸ¨ ç”Ÿæˆäº† {image_count} å¼ å›¾ç‰‡")
        
        if text_count > 0:
            stats_lines.append(f"ğŸ“ è·å¾—äº† {text_count} æ¡æ–‡æœ¬ç»“æœ")
        
        stats_lines.append("âœ¨ **æ­¤å“åº”ç”± Neogenesis æ™ºèƒ½ç³»ç»Ÿç”Ÿæˆ**")
        
        return "\n".join(stats_lines)
    
    def get_workflow_status(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµAgentçš„è¯¦ç»†çŠ¶æ€"""
        base_status = self.get_status()
        
        # æ·»åŠ å·¥ä½œæµä¸“ç”¨ç»Ÿè®¡
        base_status['workflow_stats'] = self.workflow_stats.copy()
        
        # æ·»åŠ è§„åˆ’å™¨ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(self.planner, 'get_conversion_stats'):
            base_status['planner_stats'] = self.planner.get_conversion_stats()
        
        # è®¡ç®—æˆåŠŸç‡
        total_processed = self.workflow_stats['strategic_decisions_processed']
        if total_processed > 0:
            base_status['workflow_success_rate'] = (
                self.workflow_stats['successful_workflows_generated'] / total_processed
            )
        else:
            base_status['workflow_success_rate'] = 0.0
        
        return base_status


# å·¥å‚å‡½æ•°ï¼šç®€åŒ–WorkflowGenerationAgentçš„åˆ›å»º
def create_workflow_agent(tool_executor: Union[BaseToolExecutor, BaseAsyncToolExecutor],
                         memory: BaseMemory,
                         tool_registry: Optional[ToolRegistry] = None,
                         config: Optional[Dict] = None) -> WorkflowGenerationAgent:
    """
    å·¥ä½œæµä»£ç†å·¥å‚å‡½æ•°
    
    Args:
        tool_executor: å·¥å…·æ‰§è¡Œå™¨
        memory: è®°å¿†æ¨¡å—
        tool_registry: å·¥å…·æ³¨å†Œè¡¨
        config: é…ç½®
        
    Returns:
        WorkflowGenerationAgent: é…ç½®å®Œæˆçš„å·¥ä½œæµç”Ÿæˆä»£ç†
    """
    return WorkflowGenerationAgent(
        tool_executor=tool_executor,
        memory=memory,
        tool_registry=tool_registry,
        config=config
    )
