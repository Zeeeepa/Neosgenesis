
"""
Neogenesisæ™ºèƒ½è§„åˆ’å™¨ - åŸºäºMeta MABçš„é«˜çº§è§„åˆ’ç³»ç»Ÿ
å°†MainControllerçš„äº”é˜¶æ®µæ™ºèƒ½å†³ç­–é€»è¾‘é‡æ„ä¸ºç¬¦åˆæ¡†æ¶æ ‡å‡†çš„è§„åˆ’å™¨ç»„ä»¶

æ ¸å¿ƒç‰¹æ€§:
1. äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–æµç¨‹
2. ä¾èµ–æ³¨å…¥å¼ç»„ä»¶åä½œ
3. æ ‡å‡†Planè¾“å‡ºæ ¼å¼
4. æ™ºèƒ½å†³ç­–ç»“æœç¿»è¯‘
"""

import time
import logging
from typing import Dict, List, Optional, Any, Tuple

# å¯¼å…¥æ¡†æ¶æ ¸å¿ƒ
try:
    from ..abstractions import BasePlanner
    from ..shared.data_structures import (
        Plan, Action,
        # å¯¼å…¥æ–°çš„ä¸Šä¸‹æ–‡åè®®æ•°æ®ç»“æ„
        StrategyDecision, StageContext, ThinkingSeedContext, SeedVerificationContext,
        PathGenerationContext, PathVerificationContext, MABDecisionContext
    )
except ImportError:
    from neogenesis_system.abstractions import BasePlanner
    from neogenesis_system.shared.data_structures import (
        Plan, Action,
        # å¯¼å…¥æ–°çš„ä¸Šä¸‹æ–‡åè®®æ•°æ®ç»“æ„
        StrategyDecision, StageContext, ThinkingSeedContext, SeedVerificationContext,
        PathGenerationContext, PathVerificationContext, MABDecisionContext
    )

# å¯¼å…¥Meta MABç»„ä»¶
from ..cognitive_engine.reasoner import PriorReasoner
from ..cognitive_engine.path_generator import PathGenerator
from ..cognitive_engine.mab_converger import MABConverger

# å¯¼å…¥ç§å­éªŒè¯å™¨
from .seed_verifier import SeedVerifier

# å¯¼å…¥è¯­ä¹‰åˆ†æå™¨
try:
    from ..cognitive_engine.semantic_analyzer import create_semantic_analyzer
    SEMANTIC_ANALYZER_AVAILABLE = True
except ImportError:
    SEMANTIC_ANALYZER_AVAILABLE = False
from ..cognitive_engine.data_structures import DecisionResult, ReasoningPath
from ..shared.state_manager import StateManager

# å¯¼å…¥å·¥å…·ç³»ç»Ÿ
from ..tools.tool_abstraction import (
    ToolRegistry, 
    global_tool_registry,
    execute_tool,
    ToolResult
)

logger = logging.getLogger(__name__)


class NeogenesisPlanner(BasePlanner):
    """
    Neogenesisæ™ºèƒ½è§„åˆ’å™¨
    
    å°†MainControllerçš„äº”é˜¶æ®µå†³ç­–é€»è¾‘é‡æ„ä¸ºæ ‡å‡†è§„åˆ’å™¨ç»„ä»¶ï¼š
    1. æ€ç»´ç§å­ç”Ÿæˆ (PriorReasoner)
    2. ç§å­éªŒè¯æ£€æŸ¥ (idea_verification)
    3. æ€ç»´è·¯å¾„ç”Ÿæˆ (PathGenerator)
    4. è·¯å¾„éªŒè¯å­¦ä¹  (æ ¸å¿ƒåˆ›æ–°)
    5. æ™ºèƒ½æœ€ç»ˆå†³ç­– (å‡çº§ç‰ˆMAB)
    """
    
    def __init__(self, 
                 prior_reasoner: PriorReasoner,
                 path_generator: PathGenerator,
                 mab_converger: MABConverger,
                 seed_verifier: Optional[SeedVerifier] = None,
                 tool_registry: Optional[ToolRegistry] = None,
                 state_manager: Optional[StateManager] = None,
                 config: Optional[Dict] = None,
                 cognitive_scheduler=None):
        """
        ä¾èµ–æ³¨å…¥å¼åˆå§‹åŒ–
        
        Args:
            prior_reasoner: å…ˆéªŒæ¨ç†å™¨å®ä¾‹
            path_generator: è·¯å¾„ç”Ÿæˆå™¨å®ä¾‹  
            mab_converger: MABæ”¶æ•›å™¨å®ä¾‹
            seed_verifier: ç§å­éªŒè¯å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæä¾›åˆ™è‡ªåŠ¨åˆ›å»ºï¼‰
            tool_registry: å·¥å…·æ³¨å†Œè¡¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€æ³¨å†Œè¡¨ï¼‰
            state_manager: çŠ¶æ€ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰
            config: é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
            cognitive_scheduler: è®¤çŸ¥è°ƒåº¦å™¨ï¼ˆå¯é€‰ï¼‰
        """
        super().__init__(
            name="NeogenesisPlanner",
            description="åŸºäºMeta MABçš„äº”é˜¶æ®µæ™ºèƒ½è§„åˆ’å™¨"
        )
        
        # ä¾èµ–æ³¨å…¥çš„æ ¸å¿ƒç»„ä»¶
        self.prior_reasoner = prior_reasoner
        self.path_generator = path_generator
        self.mab_converger = mab_converger
        
        # MABConvergeråˆå§‹åŒ–éªŒè¯
        self._validate_mab_converger_initialization()
        
        # å¯é€‰ç»„ä»¶
        self.tool_registry = tool_registry or global_tool_registry
        
        # ğŸ”¥ ä» prior_reasoner è·å– llm_manager å¹¶è®¾ç½®ä¸ºå®ä¾‹å±æ€§
        self.llm_manager = None
        if hasattr(self.prior_reasoner, 'llm_manager'):
            self.llm_manager = self.prior_reasoner.llm_manager
            logger.info("âœ… ä» PriorReasoner è·å– LLM ç®¡ç†å™¨")
        else:
            logger.warning("âš ï¸ PriorReasoner æ²¡æœ‰ llm_managerï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä½¿ç”¨å¯å‘å¼æ–¹æ³•")
        
        # ç§å­éªŒè¯å™¨ - å¦‚æœæœªæä¾›åˆ™è‡ªåŠ¨åˆ›å»º
        self.seed_verifier = seed_verifier
        if self.seed_verifier is None:
            self.seed_verifier = SeedVerifier(
                tool_registry=self.tool_registry,
                llm_manager=self.llm_manager
            )
            logger.info("âœ… è‡ªåŠ¨åˆ›å»º SeedVerifier å®ä¾‹")
        
        # ç¡®ä¿æœç´¢å·¥å…·è¢«æ³¨å†Œ
        self._ensure_search_tools_registered()
        
        self.state_manager = state_manager
        self.config = config or {}
        
        # ç”¨æˆ·äº¤äº’é…ç½®
        self.enable_dimension_interaction = self.config.get('enable_dimension_interaction', False)
        
        # è®¤çŸ¥è°ƒåº¦å™¨é›†æˆ
        self.cognitive_scheduler = cognitive_scheduler
        
        # åˆå§‹åŒ–è¯­ä¹‰åˆ†æå™¨
        self.semantic_analyzer = None
        if SEMANTIC_ANALYZER_AVAILABLE:
            try:
                self.semantic_analyzer = create_semantic_analyzer()
                logger.info("NeogenesisPlanner å·²é›†æˆè¯­ä¹‰åˆ†æå™¨")
            except Exception as e:
                logger.warning(f"âš ï¸ è¯­ä¹‰åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨é™çº§æ–¹æ³•: {e}")
                self.semantic_analyzer = None
        else:
            logger.info("æœªå‘ç°è¯­ä¹‰åˆ†æå™¨ï¼Œä½¿ç”¨ä¼ ç»Ÿå…³é”®è¯æ–¹æ³•")
        
        # å¦‚æœè®¤çŸ¥è°ƒåº¦å™¨å­˜åœ¨ï¼Œå°è¯•æ³¨å…¥å›æº¯å¼•æ“ä¾èµ–
        if self.cognitive_scheduler:
            self._inject_cognitive_dependencies()
        
        # å†…éƒ¨çŠ¶æ€
        self.total_rounds = 0
        self.decision_history = []
        self.performance_stats = {
            'total_decisions': 0,
            'avg_decision_time': 0.0,
            'component_performance': {
                'prior_reasoner': {'calls': 0, 'avg_time': 0.0},
                'path_generator': {'calls': 0, 'avg_time': 0.0},
                'mab_converger': {'calls': 0, 'avg_time': 0.0}
            }
        }
        
        logger.info(f"ğŸ§  NeogenesisPlanner åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"æˆ˜ç•¥ç»„ä»¶: PriorReasoner, PathGenerator, MABConverger")
        logger.info(f"ğŸ‘¤ ç”¨æˆ·äº¤äº’æ¨¡å¼: {'å·²å¯ç”¨' if self.enable_dimension_interaction else 'å·²ç¦ç”¨ï¼ˆè‡ªåŠ¨æ¨¡å¼ï¼‰'}")
        try:
            tool_count = len(self.tool_registry.tools) if hasattr(self.tool_registry, 'tools') else len(getattr(self.tool_registry, '_tools', {}))
            logger.info(f"   å·¥å…·æ³¨å†Œè¡¨: {tool_count} ä¸ªå·¥å…·")
        except:
            logger.info(f"   å·¥å…·æ³¨å†Œè¡¨: å·²åˆå§‹åŒ–")
    
    def _ensure_search_tools_registered(self):
        """ç¡®ä¿æœç´¢å·¥å…·è¢«æ­£ç¡®æ³¨å†Œ"""
        try:
            # ğŸ”¥ ä¿®å¤ï¼šå…ˆå¯¼å…¥default_toolsï¼Œå†å¯¼å…¥search_toolsä»¥è¦†ç›–æ¨¡æ‹Ÿå®ç°
            from ..tools import default_tools
            from ..providers import search_tools  # è¿™ä¸ªä¼šè¦†ç›–default_toolsä¸­çš„æ¨¡æ‹Ÿå®ç°
            
            # æ£€æŸ¥å…³é”®å·¥å…·æ˜¯å¦å·²æ³¨å†Œ
            required_tools = ["idea_verification", "web_search"]
            missing_tools = []
            
            for tool_name in required_tools:
                if not self.tool_registry.has_tool(tool_name):
                    missing_tools.append(tool_name)
            
            if missing_tools:
                logger.warning(f"âš ï¸ ç¼ºå°‘å…³é”®å·¥å…·: {missing_tools}")
                logger.info("å°è¯•é‡æ–°å¯¼å…¥å·¥å…·æ¨¡å—...")
                
                # ğŸ”¥ å¼ºåˆ¶é‡æ–°å¯¼å…¥ï¼ˆä¿æŒæ­£ç¡®é¡ºåºï¼‰
                import importlib
                importlib.reload(default_tools)
                importlib.reload(search_tools)  # ç¡®ä¿search_toolsè¦†ç›–default_tools
                
                # å†æ¬¡æ£€æŸ¥
                still_missing = []
                for tool_name in missing_tools:
                    if not self.tool_registry.has_tool(tool_name):
                        still_missing.append(tool_name)
                
                if still_missing:
                    logger.error(f"âŒ ä»ç„¶ç¼ºå°‘å·¥å…·: {still_missing}")
                else:
                    logger.info("âœ… æ‰€æœ‰å·¥å…·å·²æˆåŠŸæ³¨å†Œ")
            else:
                logger.info("âœ… æ‰€æœ‰å¿…éœ€å·¥å…·å·²æ³¨å†Œ")
                
            # ğŸ”¥ ä¿®å¤ï¼šå®‰å…¨åœ°è®°å½•å½“å‰æ³¨å†Œçš„å·¥å…·
            try:
                if hasattr(self.tool_registry, 'list_tools'):
                    available_tools = list(self.tool_registry.list_tools())
                elif hasattr(self.tool_registry, 'list_all_tools'):
                    available_tools = list(self.tool_registry.list_all_tools())
                elif hasattr(self.tool_registry, '_tools'):
                    available_tools = list(self.tool_registry._tools.keys())
                else:
                    available_tools = ["æ— æ³•è·å–å·¥å…·åˆ—è¡¨"]
                
                logger.debug(f"ğŸ”§ å½“å‰å¯ç”¨å·¥å…·: {available_tools}")
            except Exception as list_error:
                logger.debug(f"âš ï¸ è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {list_error}")
                logger.debug("ğŸ”§ å·¥å…·æ³¨å†Œè¡¨å¯èƒ½ä¸å®Œæ•´ï¼Œä½†ç³»ç»Ÿå°†ç»§ç»­è¿è¡Œ")
            
        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ³¨å†Œæ£€æŸ¥å¤±è´¥: {e}")
            logger.warning("âš ï¸ å°†ä½¿ç”¨å¯å‘å¼éªŒè¯ä½œä¸ºå›é€€")
            
            # ğŸ”¥ æ–°å¢ï¼šæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œæ¢å¤å»ºè®®
            if "list_tools" in str(e):
                logger.info("å»ºè®®ï¼šæ£€æŸ¥ToolRegistryæ˜¯å¦æ­£ç¡®å®ç°äº†list_toolsæ–¹æ³•")
            elif "has_tool" in str(e):
                logger.info("å»ºè®®ï¼šæ£€æŸ¥ToolRegistryæ˜¯å¦æ­£ç¡®å®ç°äº†has_toolæ–¹æ³•")
            else:
                logger.info("å»ºè®®ï¼šæ£€æŸ¥å·¥å…·æ³¨å†Œè¡¨çš„åˆå§‹åŒ–å’Œä¾èµ–æ³¨å…¥")
    
    def _inject_cognitive_dependencies(self):
        """å‘è®¤çŸ¥è°ƒåº¦å™¨æ³¨å…¥æ ¸å¿ƒä¾èµ–ç»„ä»¶"""
        try:
            if (self.cognitive_scheduler and 
                hasattr(self.cognitive_scheduler, 'update_retrospection_dependencies')):
                
                success = self.cognitive_scheduler.update_retrospection_dependencies(
                    path_generator=self.path_generator,
                    mab_converger=self.mab_converger
                )
                
                if success:
                    logger.info("âœ… å›æº¯å¼•æ“ä¾èµ–ç»„ä»¶å·²æˆåŠŸæ³¨å…¥")
                else:
                    logger.warning("âš ï¸ å›æº¯å¼•æ“ä¾èµ–ç»„ä»¶æ³¨å…¥å¤±è´¥")
            
        except Exception as e:
            logger.warning(f"âš ï¸ è®¤çŸ¥è°ƒåº¦å™¨ä¾èµ–æ³¨å…¥å¼‚å¸¸: {e}")
    
    def set_cognitive_scheduler(self, cognitive_scheduler):
        """è®¾ç½®è®¤çŸ¥è°ƒåº¦å™¨å¹¶è‡ªåŠ¨æ³¨å…¥ä¾èµ–ç»„ä»¶"""
        self.cognitive_scheduler = cognitive_scheduler
        if cognitive_scheduler:
            self._inject_cognitive_dependencies()
            logger.info("è®¤çŸ¥è°ƒåº¦å™¨å·²è®¾ç½®å¹¶å®Œæˆä¾èµ–æ³¨å…¥")
    
    def create_plan(self, query: str, memory: Any, context: Optional[Dict[str, Any]] = None) -> Plan:
        """
        åˆ›å»ºæ‰§è¡Œè®¡åˆ’ - å®ç°BasePlanneræ¥å£
        
        å·¥ä½œæµç¨‹ï¼š
        1. æ‰§è¡Œäº”é˜¶æ®µæˆ˜ç•¥å†³ç­– (make_strategic_decision)
        2. åŸºäºäº”é˜¶æ®µå†³ç­–ä¸Šä¸‹æ–‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        3. è¿”å›åŒ…å«æœ€ç»ˆç­”æ¡ˆçš„è®¡åˆ’
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            memory: Agentçš„è®°å¿†å¯¹è±¡
            context: å¯é€‰çš„æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            Plan: æ ‡å‡†æ ¼å¼çš„æ‰§è¡Œè®¡åˆ’
        """
        logger.info(f"NeogenesisPlannerå¼€å§‹äº”é˜¶æ®µå†³ç­–: {query[:50]}...")
        start_time = time.time()
        
        # é€šçŸ¥è®¤çŸ¥è°ƒåº¦å™¨Agentæ­£åœ¨æ´»è·ƒå·¥ä½œ
        if self.cognitive_scheduler:
            self.cognitive_scheduler.notify_activity("task_planning", {
                "query": query[:100],
                "timestamp": start_time,
                "source": "create_plan"
            })
        
        try:
            # æ‰§è¡Œäº”é˜¶æ®µæˆ˜ç•¥å†³ç­–
            logger.info("æ‰§è¡Œäº”é˜¶æ®µæˆ˜ç•¥å†³ç­–")
            strategy_decision = self.make_strategic_decision(
                user_query=query,
                execution_context=context
            )
            
            # åŸºäºäº”é˜¶æ®µä¸Šä¸‹æ–‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            logger.info("åŸºäºäº”é˜¶æ®µä¸Šä¸‹æ–‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            final_answer = self._generate_answer_from_context(query, strategy_decision, context)
            
            # åˆ›å»ºåŒ…å«æœ€ç»ˆç­”æ¡ˆçš„è®¡åˆ’
            chosen_path_type = "æœªçŸ¥"
            if strategy_decision.chosen_path:
                if hasattr(strategy_decision.chosen_path, 'path_type'):
                    chosen_path_type = strategy_decision.chosen_path.path_type
                elif isinstance(strategy_decision.chosen_path, dict):
                    chosen_path_type = strategy_decision.chosen_path.get('path_type', 'æœªçŸ¥')
            
            plan = Plan(
                thought=f"åŸºäºäº”é˜¶æ®µå†³ç­–ï¼Œé€‰æ‹©äº†'{chosen_path_type}'ç­–ç•¥",
                final_answer=final_answer,
                is_direct_answer=True,
                metadata={
                    'strategy_decision': strategy_decision,
                    'has_five_stage_context': True,
                    'execution_time': time.time() - start_time
                }
            )
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            execution_time = time.time() - start_time
            self._update_planner_stats(True, execution_time)
            
            logger.info(f"âœ… äº”é˜¶æ®µå†³ç­–å®Œæˆï¼Œè€—æ—¶ {execution_time:.3f}s")
            return plan
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_planner_stats(False, execution_time)
            
            logger.error(f"âŒ äº”é˜¶æ®µå†³ç­–å¤±è´¥: {e}")
            
            # è¿”å›é”™è¯¯å›é€€è®¡åˆ’
            return Plan(
                thought=f"äº”é˜¶æ®µå†³ç­–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                final_answer=f"æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜: {str(e)}",
                metadata={'error': str(e)}
            )
    
    def validate_plan(self, plan: Plan) -> bool:
        """
        éªŒè¯è®¡åˆ’çš„æœ‰æ•ˆæ€§
        
        Args:
            plan: è¦éªŒè¯çš„è®¡åˆ’
            
        Returns:
            bool: è®¡åˆ’æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not plan.thought:
                return False
            
            # ç›´æ¥å›ç­”æ¨¡å¼
            if plan.is_direct_answer:
                return plan.final_answer is not None and len(plan.final_answer.strip()) > 0
            
            # å·¥å…·æ‰§è¡Œæ¨¡å¼
            if not plan.actions:
                return False
            
            # éªŒè¯æ‰€æœ‰è¡ŒåŠ¨
            for action in plan.actions:
                if not action.tool_name or not isinstance(action.tool_input, dict):
                    return False
                
                # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
                if self.tool_registry and not self.tool_registry.has_tool(action.tool_name):
                    logger.warning(f"âš ï¸ å·¥å…· '{action.tool_name}' æœªåœ¨æ³¨å†Œè¡¨ä¸­æ‰¾åˆ°")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ è®¡åˆ’éªŒè¯å¤±è´¥: {e}")
            return False
    
    def make_strategic_decision(self, user_query: str, execution_context: Optional[Dict[str, Any]] = None) -> StrategyDecision:
        """
        æ‰§è¡Œå®Œæ•´çš„äº”é˜¶æ®µæˆ˜ç•¥å†³ç­–æµç¨‹ï¼Œè¿”å›æ ‡å‡†åŒ–çš„StrategyDecisionå¯¹è±¡
        
        è¿™æ˜¯æ–°çš„ä¸­å¿ƒåŒ–ä¸Šä¸‹æ–‡åè®®çš„æ ¸å¿ƒæ–¹æ³•ï¼Œå°†åŸæœ‰çš„_make_decision_logicé‡æ„ä¸º
        æ ‡å‡†åŒ–çš„æˆ˜ç•¥å†³ç­–æµç¨‹ï¼Œè¾“å‡ºå®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            StrategyDecision: åŒ…å«å®Œæ•´äº”é˜¶æ®µä¸Šä¸‹æ–‡çš„æˆ˜ç•¥å†³ç­–ç»“æœ
        """
        start_time = time.time()
        self.total_rounds += 1
        
        logger.info(f"å¼€å§‹ç¬¬ {self.total_rounds} è½®äº”é˜¶æ®µæˆ˜ç•¥å†³ç­–")
        logger.info(f"æŸ¥è¯¢: {user_query[:50]}...")
        
        # åˆå§‹åŒ–æˆ˜ç•¥å†³ç­–å¯¹è±¡
        strategy_decision = StrategyDecision(
            user_query=user_query,
            round_number=self.total_rounds,
            execution_context=execution_context
        )
        
        try:
            # é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ
            stage1_start = time.time()
            logger.info("é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ")
            
            stage1_context = self._execute_stage1_thinking_seed(user_query, execution_context)
            stage1_context.add_metric("execution_time", time.time() - stage1_start)
            strategy_decision.add_stage_context(1, stage1_context)
            
            if stage1_context.has_errors:
                strategy_decision.add_error("é˜¶æ®µä¸€æ‰§è¡Œå¤±è´¥")
                return self._create_fallback_decision(strategy_decision, "æ€ç»´ç§å­ç”Ÿæˆå¤±è´¥")
            
            # ğŸ” é˜¶æ®µäºŒï¼šç§å­éªŒè¯æ£€æŸ¥ + å¢å¼ºç”Ÿæˆ
            stage2_start = time.time()
            logger.info("ğŸ” é˜¶æ®µäºŒï¼šç§å­éªŒè¯æ£€æŸ¥ä¸å¢å¼ºç”Ÿæˆ")
            logger.info("   æœ¬é˜¶æ®µå°†ï¼š1) éªŒè¯æ€ç»´ç§å­å¯è¡Œæ€§")
            logger.info("            2) å¤šç»´åº¦æœç´¢æœ€æ–°ä¿¡æ¯")
            logger.info("            3) æ•´åˆä¿¡æ¯å¢å¼ºæ€ç»´ç§å­")
            
            # ä½¿ç”¨é‡æ„åçš„ SeedVerifier ç»„ä»¶
            stage2_context = self.seed_verifier.verify(stage1_context, execution_context)
            stage2_context.add_metric("execution_time", time.time() - stage2_start)
            strategy_decision.add_stage_context(2, stage2_context)
            
            if not stage2_context.verification_result:
                strategy_decision.add_warning("ç§å­éªŒè¯å­˜åœ¨é—®é¢˜ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            
            # ğŸ›¤ï¸ é˜¶æ®µä¸‰ï¼šæ€ç»´è·¯å¾„ç”Ÿæˆ
            stage3_start = time.time()
            logger.info("ğŸ›¤ï¸ é˜¶æ®µä¸‰ï¼šæ€ç»´è·¯å¾„ç”Ÿæˆ")
            
            stage3_context = self._execute_stage3_path_generation(stage1_context, stage2_context, execution_context)
            stage3_context.add_metric("execution_time", time.time() - stage3_start)
            strategy_decision.add_stage_context(3, stage3_context)
            
            if stage3_context.path_count == 0:
                strategy_decision.add_error("è·¯å¾„ç”Ÿæˆå¤±è´¥")
                return self._create_fallback_decision(strategy_decision, "æ— æ³•ç”Ÿæˆæ€ç»´è·¯å¾„")
            
            # é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯ä¸å³æ—¶å­¦ä¹ 
            stage4_start = time.time()
            logger.info("é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯ä¸å³æ—¶å­¦ä¹ ")
            
            stage4_context = self._execute_stage4_path_verification(stage3_context, execution_context)
            stage4_context.add_metric("execution_time", time.time() - stage4_start)
            strategy_decision.add_stage_context(4, stage4_context)
            
            # é˜¶æ®µäº”ï¼šMABæœ€ç»ˆå†³ç­–
            stage5_start = time.time()
            logger.info("é˜¶æ®µäº”ï¼šMABæœ€ç»ˆå†³ç­–")
            
            stage5_context = self._execute_stage5_mab_decision(stage4_context, execution_context)
            stage5_context.add_metric("execution_time", time.time() - stage5_start)
            strategy_decision.add_stage_context(5, stage5_context)
            
            if not stage5_context.selected_path:
                strategy_decision.add_error("MABå†³ç­–å¤±è´¥")
                return self._create_fallback_decision(strategy_decision, "æ— æ³•é€‰æ‹©æœ€ä¼˜è·¯å¾„")
            
            # è®¾ç½®æœ€ç»ˆå†³ç­–ç»“æœ
            strategy_decision.chosen_path = stage5_context.selected_path
            strategy_decision.final_reasoning = stage5_context.decision_reasoning
            strategy_decision.confidence_score = stage5_context.selection_confidence
            
            # è®¡ç®—å†³ç­–è´¨é‡æŒ‡æ ‡
            total_time = time.time() - start_time
            strategy_decision.total_execution_time = total_time
            strategy_decision.add_quality_metric("decision_completeness", 1.0 if strategy_decision.is_complete else 0.5)
            strategy_decision.add_quality_metric("average_stage_time", total_time / 5)
            strategy_decision.add_quality_metric("path_diversity", stage3_context.diversity_score)
            
            # logger.info(f"âœ… äº”é˜¶æ®µæˆ˜ç•¥å†³ç­–å®Œæˆ")  # è¯¦ç»†æµç¨‹æ—¥å¿—å·²ç®€åŒ–
            logger.info(f"   é€‰æ‹©è·¯å¾„: {strategy_decision.chosen_path.get('path_id', 'Unknown') if isinstance(strategy_decision.chosen_path, dict) else 'Unknown'}")
            logger.info(f"   ç½®ä¿¡åº¦: {strategy_decision.confidence_score:.3f}")
            logger.info(f"   æ€»è€—æ—¶: {total_time:.3f}s")
            
            return strategy_decision
            
        except Exception as e:
            logger.error(f"âŒ æˆ˜ç•¥å†³ç­–è¿‡ç¨‹å¤±è´¥: {e}")
            strategy_decision.add_error(f"å†³ç­–è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            return self._create_fallback_decision(strategy_decision, f"å†³ç­–è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
    
    def _make_decision_logic(self, user_query: str, deepseek_confidence: float = 0.5, 
                           execution_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        LLMå¢å¼ºçš„å…­é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–é€»è¾‘
        
        æ–°æ¶æ„ï¼š
        é˜¶æ®µé›¶ï¼šLLMæ™ºèƒ½è·¯ç”±åˆ†æ (æ–°å¢)
        é˜¶æ®µä¸€ï¼šå…ˆéªŒæ¨ç† - ç”Ÿæˆæ€ç»´ç§å­
        é˜¶æ®µäºŒï¼šéªŒè¯æ€ç»´ç§å­
        é˜¶æ®µä¸‰ï¼šè·¯å¾„ç”Ÿæˆ
        é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯ä¸é€‰æ‹©
        é˜¶æ®µäº”ï¼šMABå­¦ä¹ ä¸ä¼˜åŒ–
        """
        start_time = time.time()
        self.total_rounds += 1
        
        logger.info(f"ğŸš€ å¼€å§‹ç¬¬ {self.total_rounds} è½®LLMå¢å¼ºçš„å…­é˜¶æ®µæ™ºèƒ½å†³ç­–")
        logger.info(f"   æŸ¥è¯¢: {user_query[:50]}...")
        logger.info(f"   ç½®ä¿¡åº¦: {deepseek_confidence:.2f}")
        
        try:
            # é˜¶æ®µé›¶ï¼šLLMæ™ºèƒ½è·¯ç”±åˆ†æ (æ–°å¢)
            route_analysis_start = time.time()
            route_classification = self.prior_reasoner.classify_and_route(
                user_query=user_query, 
                execution_context=execution_context
            )
            route_analysis_time = time.time() - route_analysis_start
            
            # logger.info(f"é˜¶æ®µé›¶å®Œæˆ: LLMè·¯ç”±åˆ†æ")  # è¯¦ç»†æµç¨‹æ—¥å¿—å·²ç®€åŒ–
            logger.info(f"å¤æ‚åº¦: {route_classification.complexity.value if hasattr(route_classification, 'complexity') else 'unknown'}")
            logger.info(f"é¢†åŸŸ: {route_classification.domain.value if hasattr(route_classification, 'domain') else 'unknown'}")
            logger.info(f"æ„å›¾: {route_classification.intent.value if hasattr(route_classification, 'intent') else 'unknown'}")
            logger.info(f"ç½®ä¿¡åº¦: {route_classification.confidence if hasattr(route_classification, 'confidence') else 0.0:.2f}")
            logger.info(f"è€—æ—¶: {route_analysis_time:.3f}s")
            
            # ğŸ”€ æ ¹æ®è·¯ç”±ç­–ç•¥å†³å®šå¤„ç†æµç¨‹
            if self._should_use_fast_path(route_classification, user_query):
                # logger.info("ä½¿ç”¨å¿«é€Ÿå¤„ç†è·¯å¾„")  # è¯¦ç»†æµç¨‹æ—¥å¿—å·²ç®€åŒ–
                return self._execute_fast_path_decision(
                    user_query, route_classification, start_time, execution_context
                )
            else:
                # logger.info("ä½¿ç”¨å®Œæ•´å…­é˜¶æ®µå¤„ç†æµå¾„")  # è¯¦ç»†æµç¨‹æ—¥å¿—å·²ç®€åŒ–
                return self._execute_full_stage_decision(
                    user_query, route_classification, deepseek_confidence, 
                    start_time, execution_context
                )
                
        except Exception as e:
            logger.error(f"âŒ å†³ç­–è¿‡ç¨‹å¼‚å¸¸: {e}")
            return self._create_error_decision_result(user_query, str(e), time.time() - start_time)

    def _should_use_fast_path(self, route_classification, user_query: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨å¿«é€Ÿå¤„ç†è·¯å¾„
        
        å¿«é€Ÿè·¯å¾„è®¾è®¡åŸåˆ™ï¼šåªå¤„ç†"ä½ å¥½"è¿™ç±»æå…¶ç®€å•ã€æ— éœ€ä¸“ä¸šçŸ¥è¯†çš„è¾“å…¥
        ç»ä¸å¤„ç†ä»»ä½•éœ€è¦æŠ€æœ¯çŸ¥è¯†è§£ç­”çš„é—®é¢˜ï¼Œå“ªæ€•æ˜¯"ä»€ä¹ˆæ˜¯HTTP"è¿™æ ·çœ‹ä¼¼ç®€å•çš„é—®é¢˜
        
        Args:
            route_classification: è·¯ç”±åˆ†ç±»ç»“æœ
            user_query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆç”¨äºä¸¥æ ¼å†…å®¹æ£€æŸ¥ï¼‰
            
        Returns:
            bool: æ˜¯å¦ä½¿ç”¨å¿«é€Ÿè·¯å¾„
        """
        from ..cognitive_engine.reasoner import TaskComplexity, RouteStrategy
        
        # åŸºç¡€æ¡ä»¶æ£€æŸ¥ - ä¿®å¤ï¼šä½¿ç”¨å­—å…¸è®¿é—®
        is_simple = (hasattr(route_classification, 'complexity') and 
                     route_classification.complexity.value in ['simple', 'low'])
        is_direct_response = (hasattr(route_classification, 'route_strategy') and 
                             route_classification.route_strategy.value == 'direct_response')
        is_high_confidence = (hasattr(route_classification, 'confidence') and 
                             route_classification.confidence >= 0.8)
        
        if not (is_simple and is_direct_response and is_high_confidence):
            return False
            
        # ä¸¥æ ¼çš„å†…å®¹è¿‡æ»¤ - æ’é™¤ä»»ä½•éœ€è¦ä¸“ä¸šçŸ¥è¯†çš„æŸ¥è¯¢
        query_lower = user_query.lower().strip()
        
        # å…è®¸çš„æç®€è¾“å…¥ç™½åå• - ä¼˜å…ˆæ£€æŸ¥
        simple_greetings = [
            # åŸºæœ¬é—®å€™è¯­
            "ä½ å¥½", "hi", "hello", "hey", "å¥½", "åœ¨å—", "åœ¨ä¸åœ¨",
            
            # è‡ªæˆ‘ä»‹ç»ç›¸å…³
            "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", "ä»‹ç»ä¸‹ä½ è‡ªå·±", "ä»‹ç»ä½ è‡ªå·±", "è‡ªæˆ‘ä»‹ç»",
            "ä½ æ˜¯è°", "ä½ æ˜¯ä»€ä¹ˆ", "who are you", "what are you",
            "tell me about yourself", "introduce yourself",
            
            # èƒ½åŠ›è¯¢é—®
            "ä½ èƒ½åšä»€ä¹ˆ", "ä½ çš„åŠŸèƒ½", "ä½ æœ‰ä»€ä¹ˆåŠŸèƒ½", "what can you do",
            "ä½ ä¼šä»€ä¹ˆ", "ä½ æ“…é•¿ä»€ä¹ˆ", "ä½ çš„èƒ½åŠ›", "your capabilities",
            
            # ç³»ç»ŸçŠ¶æ€
            "ç³»ç»ŸçŠ¶æ€", "status", "æµ‹è¯•", "test", "ping", "ok", "å¥½çš„", 
            
            # ç¤¼è²Œç”¨è¯­
            "è°¢è°¢", "thank", "å†è§", "bye", "æ²¡äº‹", "æ²¡é—®é¢˜",
            
            # ç®€å•ç¡®è®¤
            "æ˜¯çš„", "å¯¹", "yes", "ç¡®å®š", "å¥½", "è¡Œ"
        ]
        
        # ä¼˜å…ˆæ£€æŸ¥ç™½åå• - å¦‚æœåœ¨ç™½åå•ä¸­ï¼Œç›´æ¥å…è®¸å¿«é€Ÿè·¯å¾„
        is_simple_greeting = any(greeting in query_lower for greeting in simple_greetings)
        
        if is_simple_greeting:
            logger.info(f"âœ… æ£€æµ‹åˆ°ç®€å•é—®å€™è¯­ï¼Œå…è®¸å¿«é€Ÿè·¯å¾„: {user_query[:30]}")
            return True
        
        # å¦‚æœä¸åœ¨ç™½åå•ä¸­ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæŠ€æœ¯æŸ¥è¯¢æ¨¡å¼
        tech_question_patterns = [
            "ä»€ä¹ˆæ˜¯", "what is", "å¦‚ä½•", "how to", "æ€ä¹ˆ", "æ€æ ·", 
            "ä¸ºä»€ä¹ˆ", "why", "åŸç†", "principle", "å·¥ä½œ", "work",
            "å®ç°", "implement", "é…ç½®", "config", "è®¾ç½®", "setup",
            "å®‰è£…", "install", "éƒ¨ç½²", "deploy", "ä¼˜åŒ–", "optimize",
            "è°ƒè¯•", "debug", "é”™è¯¯", "error", "é—®é¢˜", "problem",
            "è§£å†³", "solve", "ä¿®å¤", "fix", "api", "æ•°æ®åº“", "database",
            "åè®®", "protocol", "æ¡†æ¶", "framework", "æ¶æ„", "architecture"
        ]
        
        # å¦‚æœåŒ…å«ä»»ä½•æŠ€æœ¯æŸ¥è¯¢æ¨¡å¼ï¼Œæ‹’ç»å¿«é€Ÿè·¯å¾„
        if any(pattern in query_lower for pattern in tech_question_patterns):
            logger.info(f"ğŸš« æ£€æµ‹åˆ°æŠ€æœ¯æŸ¥è¯¢æ¨¡å¼ï¼Œæ‹’ç»å¿«é€Ÿè·¯å¾„: {user_query[:50]}")
            return False
        
        # å…¶ä»–æƒ…å†µä¹Ÿæ‹’ç»å¿«é€Ÿè·¯å¾„ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        logger.info(f"ğŸš« ä¸ç¬¦åˆå¿«é€Ÿè·¯å¾„ç™½åå•ï¼Œè½¬å…¥å®Œæ•´å¤„ç†: {user_query[:50]}")
        return False

    def _execute_fast_path_decision(self, user_query: str, route_classification, 
                                   start_time: float, execution_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¿«é€Ÿè·¯å¾„å†³ç­– - é€‚ç”¨äºç®€å•ç›´æ¥çš„ä»»åŠ¡
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            route_classification: è·¯ç”±åˆ†ç±»ç»“æœ
            start_time: å¼€å§‹æ—¶é—´
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            Dict: å†³ç­–ç»“æœ
        """
        logger.info("âš¡ æ‰§è¡Œå¿«é€Ÿè·¯å¾„å†³ç­–")
        
        # ç”Ÿæˆç®€åŒ–çš„æ€ç»´ç§å­
        thinking_seed = self.prior_reasoner.get_thinking_seed(user_query, execution_context)
        
        # åˆ›å»ºå•ä¸€çš„å¿«é€Ÿå“åº”è·¯å¾„
        from ..cognitive_engine.data_structures import ReasoningPath
        
        fast_path = ReasoningPath(
            path_id="llm_route_fast_path",
            path_type="direct_answer",
            description=f"åŸºäºLLMè·¯ç”±åˆ†æçš„å¿«é€Ÿå“åº”è·¯å¾„",
            prompt_template=f"åŸºäºLLMè·¯ç”±åˆ†æï¼Œè¿™æ˜¯ä¸€ä¸ª{route_classification.complexity.value if hasattr(route_classification, 'complexity') else 'medium'}ä»»åŠ¡ï¼Œ"
                           f"é¢†åŸŸä¸º{route_classification.domain.value if hasattr(route_classification, 'domain') else 'general'}ï¼Œå»ºè®®ç›´æ¥å›ç­”ã€‚",
            confidence_score=route_classification.confidence if hasattr(route_classification, 'confidence') else 0.7
        )
        
        execution_time = time.time() - start_time
        
        # æ„å»ºå¿«é€Ÿå†³ç­–ç»“æœ
        decision_result = {
            'chosen_path': fast_path,
            'thinking_seed': thinking_seed,
            'reasoning': f"LLMè·¯ç”±åˆ†æç¡®å®šè¿™æ˜¯ç®€å•ä»»åŠ¡ï¼Œé‡‡ç”¨å¿«é€Ÿå¤„ç†è·¯å¾„ã€‚åˆ†æç†ç”±: {route_classification.reasoning}",
            'available_paths': [fast_path],
            'verified_paths': [fast_path],
            'timestamp': time.time(),
            'round_number': self.total_rounds,
            'selection_algorithm': 'llm_route_fast_path',
            'verification_stats': {
                'total_verifications': 1,
                'successful_verifications': 1,
                'verification_time': 0.001  # å¿«é€Ÿè·¯å¾„è·³è¿‡éªŒè¯
            },
            'performance_metrics': {
                'total_time': execution_time,
                'route_analysis_time': execution_time * 0.8,
                'path_generation_time': execution_time * 0.1,
                'mab_time': execution_time * 0.1,
                'fast_path_used': True
            },
            'route_classification': route_classification
        }
        
        logger.info(f"âš¡ å¿«é€Ÿè·¯å¾„å†³ç­–å®Œæˆï¼Œè€—æ—¶: {execution_time:.3f}s")
        return decision_result

    def _execute_full_stage_decision(self, user_query: str, route_classification, 
                                   deepseek_confidence: float, start_time: float,
                                   execution_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´å…­é˜¶æ®µå†³ç­– - é€‚ç”¨äºå¤æ‚ä»»åŠ¡
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            route_classification: è·¯ç”±åˆ†ç±»ç»“æœ
            deepseek_confidence: DeepSeekç½®ä¿¡åº¦
            start_time: å¼€å§‹æ—¶é—´
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            Dict: å†³ç­–ç»“æœ
        """
        logger.info("ğŸ”¬ æ‰§è¡Œå®Œæ•´å…­é˜¶æ®µå†³ç­–")
        
        try:
            # é˜¶æ®µä¸€ï¼šå…ˆéªŒæ¨ç† - ç”Ÿæˆå¢å¼ºæ€ç»´ç§å­
            reasoner_start = time.time()
            
            # æ ¹æ®è·¯ç”±åˆ†æç»“æœå¢å¼ºæ€ç»´ç§å­ç”Ÿæˆ
            enhanced_context = execution_context.copy() if execution_context else {}
            enhanced_context.update({
                # åªä¼ é€’å¯åºåˆ—åŒ–çš„ä¿¡æ¯ï¼Œä¸ä¼ é€’ TriageClassification å¯¹è±¡
                'llm_route_analysis': {
                    'complexity': route_classification.complexity.value if hasattr(route_classification, 'complexity') else 'medium',
                    'domain': route_classification.domain.value if hasattr(route_classification, 'domain') else 'general',
                    'intent': route_classification.intent.value if hasattr(route_classification, 'intent') else 'question',
                    'route_strategy': route_classification.route_strategy.value if hasattr(route_classification, 'route_strategy') else 'direct_response',
                    'confidence': route_classification.confidence if hasattr(route_classification, 'confidence') else 0.7,
                    'reasoning': route_classification.reasoning if hasattr(route_classification, 'reasoning') else 'No reasoning provided'
                },
                'suggested_complexity': route_classification.complexity.value if hasattr(route_classification, 'complexity') else 'medium',
                'suggested_domain': route_classification.domain.value if hasattr(route_classification, 'domain') else 'general',
                'suggested_strategy': route_classification.route_strategy.value if hasattr(route_classification, 'route_strategy') else 'direct_response'
            })
            
            thinking_seed = self.prior_reasoner.get_thinking_seed(user_query, enhanced_context)
            
            # å…¼å®¹æ€§ï¼šè·å–æ—§æ ¼å¼æ•°æ®
            task_confidence = self.prior_reasoner.assess_task_confidence(user_query, execution_context)
            complexity_info = self.prior_reasoner.analyze_task_complexity(user_query)
            
            reasoner_time = time.time() - reasoner_start
            self._update_component_performance('prior_reasoner', reasoner_time)
            
            # æ˜¾ç¤ºAgentçš„çœŸå®æ€è€ƒå†…å®¹
            logger.info("é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ")
            logger.info(f"åŸºäºç”¨æˆ·æŸ¥è¯¢ã€Œ{user_query[:50]}...ã€ï¼Œæˆ‘ç”Ÿæˆäº†ä»¥ä¸‹æ€ç»´ç§å­ï¼š")
            logger.info(f" {thinking_seed[:200]}{'...' if len(thinking_seed) > 200 else ''}")
            logger.info(f"ç§å­é•¿åº¦: {len(thinking_seed)} å­—ç¬¦ï¼Œç”Ÿæˆè€—æ—¶: {reasoner_time:.2f}ç§’")
            
            # ğŸ” é˜¶æ®µäºŒï¼šLLMå¢å¼ºæ€ç»´ç§å­éªŒè¯
            seed_verification_start = time.time()
            seed_verification_result = self._verify_idea_feasibility(
                idea_text=thinking_seed,
                context={
                    'stage': 'thinking_seed',
                    'domain': route_classification.domain.value if hasattr(route_classification, 'domain') else 'general',  # ä½¿ç”¨LLMè·¯ç”±åˆ†æçš„é¢†åŸŸ
                    'complexity': route_classification.complexity.value if hasattr(route_classification, 'complexity') else 'medium',  # ä½¿ç”¨LLMè·¯ç”±åˆ†æçš„å¤æ‚åº¦
                    'route_strategy': route_classification.route_strategy.value if hasattr(route_classification, 'route_strategy') else 'standard_rag',  # ä½¿ç”¨LLMè·¯ç”±ç­–ç•¥
                    'query': user_query,
                    'llm_routing_enabled': True,  # æ ‡è®°å¯ç”¨äº†LLMè·¯ç”±
                    **(execution_context if execution_context else {})
                }
            )
            seed_verification_time = time.time() - seed_verification_start
            
            # åˆ†æç§å­éªŒè¯ç»“æœ
            seed_feasibility = seed_verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
            seed_reward = seed_verification_result.get('reward_score', 0.0)
            
            # æ˜¾ç¤ºç§å­éªŒè¯çš„è¯¦ç»†ç»“æœ
            logger.info("=" * 80)
            logger.info("ğŸ” é˜¶æ®µäºŒï¼šæ€ç»´ç§å­éªŒè¯")
            logger.info("=" * 80)
            logger.info(f"æˆ‘å¯¹ç”Ÿæˆçš„æ€ç»´ç§å­è¿›è¡Œäº†å¯è¡Œæ€§éªŒè¯ï¼š")
            logger.info(f"ğŸ“Š å¯è¡Œæ€§è¯„åˆ†: {seed_feasibility:.2f}/1.0")
            logger.info(f"ğŸ¯ å¥–åŠ±åˆ†æ•°: {seed_reward:+.3f}")
            
            # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºæœç´¢åˆ°çš„URLå’Œè¯¦ç»†ä¿¡æ¯
            search_results = seed_verification_result.get('search_results', [])
            if search_results:
                logger.info("")
                logger.info("ğŸŒ æœç´¢åˆ°çš„éªŒè¯æºï¼š")
                for i, result in enumerate(search_results[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ªç»“æœ
                    title = result.get('title', 'æ— æ ‡é¢˜')
                    url = result.get('url', 'æ— URL')
                    snippet = result.get('snippet', 'æ— æ‘˜è¦')
                    relevance = result.get('relevance_score', 0.0)
                    
                    logger.info(f"   {i}. ğŸ“„ {title}")
                    logger.info(f"      ğŸ”— URL: {url}")
                    logger.info(f"      ğŸ“ æ‘˜è¦: {snippet[:100]}{'...' if len(snippet) > 100 else ''}")
                    logger.info(f"      â­ ç›¸å…³æ€§: {relevance:.2f}")
                    logger.info("")
            else:
                logger.info("âš ï¸ æœªæ‰¾åˆ°æœç´¢ç»“æœ")
            
            # æ˜¾ç¤ºéªŒè¯åˆ†ææ‘˜è¦
            analysis_summary = seed_verification_result.get('analysis_summary', '')
            if analysis_summary:
                logger.info("ğŸ“‹ éªŒè¯åˆ†ææ‘˜è¦ï¼š")
                logger.info(f"   {analysis_summary[:200]}{'...' if len(analysis_summary) > 200 else ''}")
            
            # æ˜¾ç¤ºLLMè¯„ä¼°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            llm_prompt = seed_verification_result.get('llm_evaluation_prompt', '')
            llm_response = seed_verification_result.get('llm_evaluation_response', '')
            if llm_prompt and llm_response:
                logger.info("")
                logger.info("ğŸ§  LLMè¯„ä¼°è¿‡ç¨‹ï¼š")
                logger.info(f"   ğŸ“ è¯„ä¼°æç¤º: {llm_prompt[:150]}{'...' if len(llm_prompt) > 150 else ''}")
                logger.info(f"   ğŸ’­ è¯„ä¼°å“åº”: {llm_response[:200]}{'...' if len(llm_response) > 200 else ''}")
            
            logger.info("")
            logger.info(f"â±ï¸ éªŒè¯è€—æ—¶: {seed_verification_time:.2f}ç§’")
            logger.info("=" * 80)
            
            # ğŸ›¤ï¸ é˜¶æ®µä¸‰ï¼šLLMä¼˜åŒ–è·¯å¾„ç”Ÿæˆ
            generator_start = time.time()
            
            # æ ¹æ®LLMè·¯ç”±åˆ†æä¼˜åŒ–è·¯å¾„ç”Ÿæˆå‚æ•°
            max_paths = self._get_optimal_path_count_for_route(route_classification)
            
            all_reasoning_paths = self.path_generator.generate_paths(
                thinking_seed=thinking_seed, 
                task=user_query,
                max_paths=max_paths
                # æ³¨é‡Šï¼šè·¯ç”±æç¤ºä¿¡æ¯å·²é€šè¿‡enhanced_contextä¼ é€’ç»™æ€ç»´ç§å­ç”Ÿæˆ
            )
            generator_time = time.time() - generator_start
            self._update_component_performance('path_generator', generator_time)
            
            # æ˜¾ç¤ºè·¯å¾„ç”Ÿæˆçš„è¯¦ç»†ç»“æœ
            logger.info("é˜¶æ®µä¸‰ï¼šæ€ç»´è·¯å¾„ç”Ÿæˆ")
            logger.info(f"   åŸºäºéªŒè¯åçš„æ€ç»´ç§å­ï¼Œæˆ‘ç”Ÿæˆäº† {len(all_reasoning_paths)} æ¡å€™é€‰æ€ç»´è·¯å¾„ï¼š")
            for i, path in enumerate(all_reasoning_paths[:3], 1):  # åªæ˜¾ç¤ºå‰3æ¡è·¯å¾„
                path_type = getattr(path, 'path_type', 'æœªçŸ¥ç±»å‹')
                path_desc = getattr(path, 'description', 'æ— æè¿°')[:100]
                logger.info(f"   {i}. ã€{path_type}ã€‘{path_desc}{'...' if len(getattr(path, 'description', '')) > 100 else ''}")
            if len(all_reasoning_paths) > 3:
                logger.info(f"   ... è¿˜æœ‰ {len(all_reasoning_paths) - 3} æ¡è·¯å¾„")
            strategy = route_classification.route_strategy.value if hasattr(route_classification, 'route_strategy') else 'standard_rag'
            logger.info(f"ç”Ÿæˆç­–ç•¥: {strategy}ï¼Œè€—æ—¶: {generator_time:.2f}ç§’")
            
            # é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯å­¦ä¹ 
            path_verification_start = time.time()
            verified_paths = []
            all_infeasible = True
            
            logger.info(f"ğŸ”¬ é˜¶æ®µå››å¼€å§‹: éªŒè¯æ€ç»´è·¯å¾„")
            
            # ç®€åŒ–ç‰ˆè·¯å¾„éªŒè¯ï¼ˆé¿å…å¤æ‚çš„å¹¶è¡Œå¤„ç†ï¼‰
            for i, path in enumerate(all_reasoning_paths, 1):
                logger.debug(f"ğŸ”¬ éªŒè¯è·¯å¾„ {i}/{len(all_reasoning_paths)}: {path.path_type}")
                
                # æ„å»ºè¯¦ç»†çš„è·¯å¾„ç­–ç•¥å†…å®¹ç”¨äºLLMæ•´åˆ
                detailed_path_content = self._build_detailed_path_content(path, user_query)
                
                # éªŒè¯å•ä¸ªè·¯å¾„
                path_verification_result = self._verify_idea_feasibility(
                    idea_text=detailed_path_content,
                    context={
                        'stage': 'reasoning_path',
                        'path_id': path.path_id,
                        'path_type': path.path_type,
                        'query': user_query,
                        'user_query': user_query,  # ç¡®ä¿ä¼ é€’ç”¨æˆ·æŸ¥è¯¢
                        **(execution_context if execution_context else {})
                    }
                )
                
                # æå–éªŒè¯ç»“æœ
                path_feasibility = path_verification_result.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
                path_reward = path_verification_result.get('reward_score', 0.0)
                verification_success = not path_verification_result.get('fallback', False)
                
                # å³æ—¶å­¦ä¹ ï¼šç«‹å³å°†éªŒè¯ç»“æœåé¦ˆç»™MABç³»ç»Ÿ
                if verification_success and path_feasibility > 0.3:
                    # å¯è¡Œçš„è·¯å¾„ - æ­£é¢å­¦ä¹ ä¿¡å·
                    self.mab_converger.update_path_performance(
                        path_id=path.strategy_id,
                        success=True,
                        reward=path_reward
                    )
                    all_infeasible = False
                    logger.debug(f"âœ… è·¯å¾„ {path.path_type} éªŒè¯é€šè¿‡: å¯è¡Œæ€§={path_feasibility:.2f}")
                else:
                    # ä¸å¯è¡Œçš„è·¯å¾„ - è´Ÿé¢å­¦ä¹ ä¿¡å·
                    self.mab_converger.update_path_performance(
                        path_id=path.strategy_id,
                        success=False,
                        reward=path_reward
                    )
                    logger.debug(f"âŒ è·¯å¾„ {path.path_type} éªŒè¯å¤±è´¥: å¯è¡Œæ€§={path_feasibility:.2f}")
                
                # è®°å½•éªŒè¯ç»“æœ
                verified_paths.append({
                    'path': path,
                    'verification_result': path_verification_result,
                    'feasibility_score': path_feasibility,
                    'reward_score': path_reward,
                    'is_feasible': path_feasibility > 0.3
                })
            
            path_verification_time = time.time() - path_verification_start
            feasible_count = sum(1 for vp in verified_paths if vp['is_feasible'])
            
            # æ˜¾ç¤ºè·¯å¾„éªŒè¯çš„è¯¦ç»†ç»“æœ
            logger.info("é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯ä¸å­¦ä¹ ")
            logger.info(f"æˆ‘å¯¹ {len(all_reasoning_paths)} æ¡å€™é€‰è·¯å¾„è¿›è¡Œäº†æ·±åº¦éªŒè¯ï¼š")
            logger.info(f"å¯è¡Œè·¯å¾„: {feasible_count} æ¡")
            logger.info(f"ä¸å¯è¡Œè·¯å¾„: {len(all_reasoning_paths) - feasible_count} æ¡")
            
            # æ˜¾ç¤ºå¯è¡Œè·¯å¾„çš„è¯¦ç»†ä¿¡æ¯
            feasible_paths = [vp for vp in verified_paths if vp['is_feasible']]
            for i, vp in enumerate(feasible_paths[:2], 1):  # åªæ˜¾ç¤ºå‰2æ¡å¯è¡Œè·¯å¾„
                path_info = vp.get('path', {})
                path_type = path_info.get('path_type', 'æœªçŸ¥')
                feasibility = vp.get('feasibility_score', 0.0)
                logger.info(f"{i}. ã€{path_type}ã€‘å¯è¡Œæ€§: {feasibility:.2f}")
            
            logger.info(f"éªŒè¯è€—æ—¶: {path_verification_time:.2f}ç§’")
            
            # é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­–
            final_decision_start = time.time()
            
            if all_infeasible:
                # æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯è¡Œ - è§¦å‘æ™ºèƒ½ç»•é“æ€è€ƒ
                logger.warning("æ‰€æœ‰æ€ç»´è·¯å¾„éƒ½è¢«éªŒè¯ä¸ºä¸å¯è¡Œï¼Œè§¦å‘æ™ºèƒ½ç»•é“æ€è€ƒ")
                chosen_path = self._execute_intelligent_detour_thinking(
                    user_query, thinking_seed, all_reasoning_paths
                )
                selection_algorithm = 'intelligent_detour'
            else:
                # âœ… è‡³å°‘æœ‰å¯è¡Œè·¯å¾„ - ä½¿ç”¨å¢å¼ºçš„MABé€‰æ‹©
                logger.info("âœ… å‘ç°å¯è¡Œè·¯å¾„ï¼Œä½¿ç”¨éªŒè¯å¢å¼ºçš„MABå†³ç­–")
                chosen_path = self.mab_converger.select_best_path(all_reasoning_paths)
                selection_algorithm = 'verification_enhanced_mab'
            
            final_decision_time = time.time() - final_decision_start
            total_mab_time = path_verification_time + final_decision_time
            self._update_component_performance('mab_converger', total_mab_time)
            
            # è®¡ç®—æ€»ä½“å†³ç­–æ—¶é—´
            total_decision_time = time.time() - start_time
            
            # æ„å»ºå†³ç­–ç»“æœ
            decision_result = {
                # åŸºæœ¬ä¿¡æ¯
                'timestamp': time.time(),
                'round_number': self.total_rounds,
                'user_query': user_query,
                'deepseek_confidence': deepseek_confidence,
                'execution_context': execution_context,
                
                # äº”é˜¶æ®µå†³ç­–ç»“æœ
                'thinking_seed': thinking_seed,
                'seed_verification': seed_verification_result,
                'chosen_path': chosen_path,
                'available_paths': all_reasoning_paths,
                'verified_paths': verified_paths,
                
                # å†³ç­–å…ƒä¿¡æ¯
                'reasoning': f"äº”é˜¶æ®µæ™ºèƒ½éªŒè¯-å­¦ä¹ å†³ç­–: {chosen_path.path_type} - {chosen_path.description}",
                'path_count': len(all_reasoning_paths),
                'feasible_path_count': feasible_count,
                'selection_algorithm': selection_algorithm,
                'architecture_version': '5-stage-verification',
                'verification_enabled': True,
                'instant_learning_enabled': True,
                
                # éªŒè¯ç»Ÿè®¡
                'verification_stats': {
                    'seed_feasibility': seed_feasibility,
                    'seed_reward': seed_reward,
                    'paths_verified': len(verified_paths),
                    'feasible_paths': feasible_count,
                    'infeasible_paths': len(verified_paths) - feasible_count,
                    'all_paths_infeasible': all_infeasible,
                    'average_path_feasibility': sum(vp['feasibility_score'] for vp in verified_paths) / len(verified_paths) if verified_paths else 0.0,
                    'total_verification_time': seed_verification_time + path_verification_time
                },
                
                # æ€§èƒ½æŒ‡æ ‡
                'performance_metrics': {
                    'total_time': total_decision_time,
                    'stage1_reasoner_time': reasoner_time,
                    'stage2_seed_verification_time': seed_verification_time,
                    'stage3_generator_time': generator_time,
                    'stage4_path_verification_time': path_verification_time,
                    'stage5_final_decision_time': final_decision_time,
                }
            }
            
            # è®°å½•å†³ç­–å†å²
            self.decision_history.append(decision_result)
            
            # é™åˆ¶å†å²è®°å½•é•¿åº¦
            max_history = 100  # ç®€åŒ–çš„é™åˆ¶
            if len(self.decision_history) > max_history:
                self.decision_history = self.decision_history[-max_history//2:]
            
            # æ˜¾ç¤ºæœ€ç»ˆå†³ç­–çš„è¯¦ç»†ç»“æœ
            logger.info("é˜¶æ®µäº”ï¼šæ™ºèƒ½æœ€ç»ˆå†³ç­–")
            logger.info(f"ç»è¿‡MABç®—æ³•åˆ†æï¼Œæˆ‘é€‰æ‹©äº†æœ€ä¼˜è·¯å¾„ï¼š")
            logger.info(f"é€‰æ‹©è·¯å¾„: ã€{chosen_path.path_type}ã€‘")
            path_desc = getattr(chosen_path, 'description', 'æ— æè¿°')
            logger.info(f"è·¯å¾„æè¿°: {path_desc[:150]}{'...' if len(path_desc) > 150 else ''}")
            logger.info(f"å†³ç­–ç½®ä¿¡åº¦: {getattr(chosen_path, 'confidence_score', deepseek_confidence):.3f}")
            logger.info(f"å†³ç­–è€—æ—¶: {final_decision_time:.2f}ç§’")
            logger.info("")
            # logger.info("äº”é˜¶æ®µæ™ºèƒ½å†³ç­–æµç¨‹å®Œæˆ")  # è¯¦ç»†æµç¨‹æ—¥å¿—å·²ç®€åŒ–
            logger.info(f"æ€»è€—æ—¶: {total_decision_time:.3f}ç§’")
            
            return decision_result
            
        except Exception as e:
            logger.error(f"âŒ å†³ç­–è¿‡ç¨‹å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯å†³ç­–ç»“æœ
            return self._create_error_decision_result(user_query, str(e), time.time() - start_time)
    
    def make_strategic_decision(self, user_query: str, confidence: float = 0.5, 
                              execution_context: Optional[Dict] = None) -> 'StrategyDecision':
        """
        æ‰§è¡Œæˆ˜ç•¥å†³ç­– - NeogenesisPlannerçš„æ ¸å¿ƒèŒè´£
        
        ä¸“æ³¨äº"å†³å®šåšä»€ä¹ˆ"ï¼Œè¾“å‡ºStrategyDecisionä¾›æˆ˜æœ¯è§„åˆ’å™¨ä½¿ç”¨
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            confidence: ç½®ä¿¡åº¦
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            StrategyDecision: æˆ˜ç•¥å†³ç­–ç»“æœ
        """
        from ..shared.data_structures import StrategyDecision
        
        # è°ƒç”¨åŸæœ‰çš„å†³ç­–é€»è¾‘
        decision_result = self._make_decision_logic(user_query, confidence, execution_context)
        
        # è½¬æ¢ä¸ºStrategyDecisionæ ¼å¼ - ä¿®å¤ï¼šåªä½¿ç”¨å­˜åœ¨çš„å­—æ®µ
        strategy_decision = StrategyDecision(
            chosen_path=decision_result.get('chosen_path'),
            final_reasoning=decision_result.get('reasoning', ''),
            user_query=user_query,
            timestamp=decision_result.get('timestamp', time.time()),
            round_number=decision_result.get('round_number', self.total_rounds),
            execution_context=execution_context,
            confidence_score=confidence
        )
        
        # æ·»åŠ è´¨é‡æŒ‡æ ‡
        performance_metrics = decision_result.get('performance_metrics', {})
        for metric_name, value in performance_metrics.items():
            strategy_decision.add_quality_metric(metric_name, value)
        
        # å®‰å…¨æ£€æŸ¥chosen_path
        if strategy_decision.chosen_path:
            logger.info(f"æˆ˜ç•¥å†³ç­–å®Œæˆ: {strategy_decision.chosen_path.path_type}")
        else:
            logger.warning("æˆ˜ç•¥å†³ç­–å®Œæˆï¼Œä½†æœªé€‰æ‹©å…·ä½“è·¯å¾„")
        return strategy_decision
    
    
    def _get_optimal_path_count_for_route(self, route_classification) -> int:
        """
        æ ¹æ®LLMè·¯ç”±åˆ†ç±»è·å–æœ€ä¼˜è·¯å¾„æ•°é‡
        
        Args:
            route_classification: LLMè·¯ç”±åˆ†ç±»ç»“æœ
            
        Returns:
            int: æœ€ä¼˜è·¯å¾„æ•°é‡
        """
        from ..cognitive_engine.reasoner import TaskComplexity, RouteStrategy
        
        # åŸºäºå¤æ‚åº¦çš„åŸºç¡€è·¯å¾„æ•°
        base_count = {
            TaskComplexity.SIMPLE: 3,
            TaskComplexity.MODERATE: 5,
            TaskComplexity.COMPLEX: 6,
            TaskComplexity.EXPERT: 8
        }.get(route_classification.complexity.value if hasattr(route_classification, 'complexity') else 'medium', 6)
        
        # åŸºäºè·¯ç”±ç­–ç•¥çš„è°ƒæ•´
        routing_rec = route_classification.route_strategy.value if hasattr(route_classification, 'route_strategy') else 'standard_rag'
        if routing_rec == 'direct_response':
            return max(2, base_count // 2)  # ç›´æ¥å›ç­”éœ€è¦è¾ƒå°‘è·¯å¾„
        elif routing_rec == 'expert_consultation':
            return min(10, base_count + 2)  # ä¸“å®¶å’¨è¯¢éœ€è¦æ›´å¤šè·¯å¾„
        elif routing_rec == 'multi_stage_processing':
            return min(8, base_count + 1)  # å¤šé˜¶æ®µå¤„ç†éœ€è¦é¢å¤–è·¯å¾„
        else:
            return base_count

    # ==================== æˆ˜ç•¥è§„åˆ’ä¸“ç”¨æ–¹æ³• ====================
    
    def _build_detailed_path_content(self, path, user_query: str) -> str:
        """
        æ„å»ºè¯¦ç»†çš„æ€ç»´è·¯å¾„ç­–ç•¥å†…å®¹ï¼Œç”¨äºLLMæ·±åº¦æ•´åˆ
        
        Args:
            path: ReasoningPathå¯¹è±¡
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            
        Returns:
            str: åŒ…å«è¯¦ç»†ç­–ç•¥å†…å®¹çš„æ–‡æœ¬
        """
        content_parts = []
        
        # åŸºæœ¬ä¿¡æ¯
        content_parts.append(f"**ç­–ç•¥ç±»å‹**: {path.path_type}")
        content_parts.append(f"**ç­–ç•¥æè¿°**: {path.description}")
        
        # æ·»åŠ å…·ä½“çš„æ‰§è¡Œæ¨¡æ¿å†…å®¹
        if hasattr(path, 'prompt_template') and path.prompt_template:
            # æå–æ¨¡æ¿ä¸­çš„å…³é”®ç­–ç•¥æ­¥éª¤
            template = path.prompt_template
            
            # æŸ¥æ‰¾æ­¥éª¤éƒ¨åˆ†
            if "**åˆ†ææ­¥éª¤**" in template or "**åˆ›æ–°æ–¹æ³•**" in template or "**å®ç”¨æ­¥éª¤**" in template:
                # æå–æ­¥éª¤å†…å®¹
                import re
                steps_match = re.search(r'\*\*[^*]+\*\*:\s*(.*?)(?=\n\n|\nåŸºäºæ€ç»´ç§å­|$)', template, re.DOTALL)
                if steps_match:
                    steps_content = steps_match.group(1).strip()
                    content_parts.append(f"**å…·ä½“ç­–ç•¥æ­¥éª¤**:\n{steps_content}")
        
        # æ·»åŠ æ€ç»´æ­¥éª¤ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(path, 'steps') and path.steps:
            steps_text = "\n".join([f"- {step}" for step in path.steps[:5]])  # é™åˆ¶å‰5ä¸ªæ­¥éª¤
            content_parts.append(f"**æ‰§è¡Œæ­¥éª¤**:\n{steps_text}")
        
        # æ·»åŠ å…³é”®è¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(path, 'keywords') and path.keywords:
            keywords_text = ", ".join(path.keywords[:8])  # é™åˆ¶å‰8ä¸ªå…³é”®è¯
            content_parts.append(f"**å…³é”®è¯**: {keywords_text}")
        
        # æ·»åŠ é€‚ç”¨é¢†åŸŸï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(path, 'applicable_domains') and path.applicable_domains:
            domains_text = ", ".join(path.applicable_domains[:3])  # é™åˆ¶å‰3ä¸ªé¢†åŸŸ
            content_parts.append(f"**é€‚ç”¨é¢†åŸŸ**: {domains_text}")
        
        # æ·»åŠ æˆåŠŸæŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(path, 'success_indicators') and path.success_indicators:
            indicators_text = "\n".join([f"- {indicator}" for indicator in path.success_indicators[:3]])
            content_parts.append(f"**æˆåŠŸæŒ‡æ ‡**:\n{indicators_text}")
        
        # ç»„åˆæ‰€æœ‰å†…å®¹
        detailed_content = "\n\n".join(content_parts)
        
        # æ·»åŠ ç”¨æˆ·æŸ¥è¯¢ä¸Šä¸‹æ–‡
        final_content = f"""é’ˆå¯¹ç”¨æˆ·æŸ¥è¯¢ã€Œ{user_query}ã€çš„æ€ç»´è·¯å¾„ç­–ç•¥ï¼š

{detailed_content}

è¯·åŸºäºä»¥ä¸Šå…·ä½“ç­–ç•¥å†…å®¹å’Œç”¨æˆ·æŸ¥è¯¢ï¼ŒéªŒè¯è¯¥æ€ç»´è·¯å¾„çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚"""
        
        return final_content
    
    def _verify_idea_feasibility(self, idea_text: str, context: Dict[str, Any], 
                                streaming_output = None) -> Dict[str, Any]:
        """
        éªŒè¯æƒ³æ³•å¯è¡Œæ€§ï¼ˆå¢å¼ºç‰ˆå®ç°ï¼‰- ä¿®å¤å¥–åŠ±ä¸º0çš„é—®é¢˜
        
        è¿™é‡Œè°ƒç”¨å·¥å…·ç³»ç»Ÿä¸­çš„idea_verificationå·¥å…·ï¼Œå¹¶ç¡®ä¿æ€»æ˜¯è¿”å›åˆç†çš„å¥–åŠ±å€¼
        """
        try:
            # ğŸ”¥ è¯¦ç»†æ—¥å¿—ï¼šæ£€æŸ¥å·¥å…·æ³¨å†Œè¡¨çŠ¶æ€
            logger.info(f"ğŸ” [éªŒè¯] æ£€æŸ¥å·¥å…·æ³¨å†Œè¡¨çŠ¶æ€")
            logger.info(f"ğŸ” [éªŒè¯] tool_registryå­˜åœ¨: {self.tool_registry is not None}")
            
            if self.tool_registry:
                has_tool = self.tool_registry.has_tool("idea_verification")
                logger.info(f"ğŸ” [éªŒè¯] idea_verificationå·¥å…·å­˜åœ¨: {has_tool}")
                
                # åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…·
                try:
                    if hasattr(self.tool_registry, 'tools'):
                        all_tools = list(self.tool_registry.tools.keys())
                    elif hasattr(self.tool_registry, '_tools'):
                        all_tools = list(self.tool_registry._tools.keys())
                    else:
                        all_tools = []
                    logger.info(f"ğŸ” [éªŒè¯] å·²æ³¨å†Œå·¥å…·åˆ—è¡¨: {all_tools}")
                except Exception as e:
                    logger.warning(f"âš ï¸ [éªŒè¯] æ— æ³•è·å–å·¥å…·åˆ—è¡¨: {e}")
            else:
                logger.warning(f"âš ï¸ [éªŒè¯] tool_registryä¸ºNoneï¼Œæ— æ³•è°ƒç”¨å·¥å…·")
            
            if self.tool_registry and self.tool_registry.has_tool("idea_verification"):
                # ä¿®å¤ï¼šæ­£ç¡®ä¼ é€’ç”¨æˆ·æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡
                user_query = context.get('query', '')
                logger.info(f"âœ… [éªŒè¯] å‡†å¤‡è°ƒç”¨idea_verificationå·¥å…·")
                logger.info(f"ğŸ” [éªŒè¯] idea_text: {idea_text[:50]}...")
                logger.info(f"ğŸ” [éªŒè¯] user_query: {user_query}")
                logger.info(f"ğŸ” [éªŒè¯] streaming_output: {streaming_output is not None}")
                
                # æ„å»ºå·¥å…·ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«streaming_outputï¼‰
                tool_context = {"user_query": user_query}
                if streaming_output is not None:
                    tool_context['_streaming_output'] = streaming_output
                
                result = execute_tool(
                    "idea_verification", 
                    idea_text=idea_text,  # ä½¿ç”¨idea_textå‚æ•°å
                    context=tool_context  # ä¼ é€’ç”¨æˆ·æŸ¥è¯¢å’Œstreaming_output
                )
                
                logger.info(f"ğŸ” [éªŒè¯] execute_toolè¿”å›: success={result.success}")
                
                if result.success:
                    logger.info(f"âœ… [éªŒè¯] å·¥å…·æ‰§è¡ŒæˆåŠŸ")
                    # ç¡®ä¿å·¥å…·è¿”å›çš„æ•°æ®åŒ…å«reward_score
                    data = result.data
                    if 'reward_score' not in data:
                        # åŸºäºfeasibility_scoreè®¡ç®—reward_score
                        feasibility_score = data.get('feasibility_analysis', {}).get('feasibility_score', 0.5)
                        data['reward_score'] = self._calculate_reward_from_feasibility(feasibility_score)
                        logger.info(f"ğŸ¯ [éªŒè¯] åŸºäºå¯è¡Œæ€§è®¡ç®—å¥–åŠ±: {data['reward_score']:.3f}")
                    return data
                else:
                    logger.warning(f"âš ï¸ [éªŒè¯] å·¥å…·æ‰§è¡Œå¤±è´¥: {result.error_message}")
            else:
                logger.warning(f"âš ï¸ [éªŒè¯] idea_verificationå·¥å…·ä¸å¯ç”¨ï¼Œä½¿ç”¨å›é€€é€»è¾‘")
            
            # å›é€€å®ç° - ä½¿ç”¨æ›´åˆç†çš„å¥–åŠ±è®¡ç®—
            logger.info(f"ğŸ”„ [éªŒè¯] ä½¿ç”¨å›é€€éªŒè¯é€»è¾‘")
            feasibility_score = 0.7
            reward_score = self._calculate_reward_from_feasibility(feasibility_score)
            
            return {
                'feasibility_analysis': {'feasibility_score': feasibility_score},
                'reward_score': reward_score,
                'fallback': True
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ æƒ³æ³•éªŒè¯å¤±è´¥: {e}")
            
            # å³ä½¿å¤±è´¥ä¹Ÿè¦ç»™åˆç†çš„å¥–åŠ±å€¼ï¼Œè€Œä¸æ˜¯0
            feasibility_score = 0.5
            reward_score = self._calculate_reward_from_feasibility(feasibility_score, is_error=True)
            
            return {
                'feasibility_analysis': {'feasibility_score': feasibility_score},
                'reward_score': reward_score,
                'fallback': True
            }
    
    def _calculate_reward_from_feasibility(self, feasibility_score: float, is_error: bool = False) -> float:
        """
        åŸºäºå¯è¡Œæ€§åˆ†æ•°è®¡ç®—å¥–åŠ±å€¼
        
        Args:
            feasibility_score: å¯è¡Œæ€§åˆ†æ•° (0.0-1.0)
            is_error: æ˜¯å¦æ˜¯é”™è¯¯æƒ…å†µ
            
        Returns:
            float: å¥–åŠ±å€¼ (-1.0 åˆ° 1.0)
        """
        try:
            if is_error:
                # é”™è¯¯æƒ…å†µä¸‹ç»™äºˆå°çš„è´Ÿå¥–åŠ±ï¼Œä½†ä¸æ˜¯é›¶
                return -0.1
            
            # å°†å¯è¡Œæ€§åˆ†æ•°è½¬æ¢ä¸ºå¥–åŠ±å€¼
            # å¯è¡Œæ€§ > 0.7: æ­£å¥–åŠ±
            # å¯è¡Œæ€§ 0.3-0.7: å°æ­£å¥–åŠ±
            # å¯è¡Œæ€§ < 0.3: è´Ÿå¥–åŠ±
            
            if feasibility_score >= 0.7:
                # é«˜å¯è¡Œæ€§ï¼š0.2 åˆ° 0.8 çš„æ­£å¥–åŠ±
                reward = 0.2 + (feasibility_score - 0.7) * 2.0  # (0.7-1.0) -> (0.2-0.8)
            elif feasibility_score >= 0.3:
                # ä¸­ç­‰å¯è¡Œæ€§ï¼š0.1 åˆ° 0.2 çš„å°æ­£å¥–åŠ±
                reward = 0.1 + (feasibility_score - 0.3) * 0.25  # (0.3-0.7) -> (0.1-0.2)
            else:
                # ä½å¯è¡Œæ€§ï¼š-0.3 åˆ° 0.1 çš„å¥–åŠ±
                reward = -0.3 + feasibility_score * 1.33  # (0.0-0.3) -> (-0.3-0.1)
            
            # ç¡®ä¿å¥–åŠ±å€¼åœ¨åˆç†èŒƒå›´å†…
            reward = max(-1.0, min(1.0, reward))
            
            # ç¡®ä¿å¥–åŠ±å€¼ä¸ä¸ºé›¶ï¼ˆé™¤éæ˜¯æ˜ç¡®çš„å¤±è´¥ï¼‰
            if reward == 0.0:
                reward = 0.05 if feasibility_score >= 0.5 else -0.05
            
            logger.debug(f"å¥–åŠ±è®¡ç®—: å¯è¡Œæ€§={feasibility_score:.3f} -> å¥–åŠ±={reward:.3f}")
            return reward
            
        except Exception as e:
            logger.warning(f"âš ï¸ å¥–åŠ±è®¡ç®—å¤±è´¥: {e}")
            return 0.1  # é»˜è®¤å°æ­£å¥–åŠ±
    
    def _execute_intelligent_detour_thinking(self, user_query: str, thinking_seed: str, 
                                           all_paths: List[ReasoningPath]) -> ReasoningPath:
        """
        æ‰§è¡Œæ™ºèƒ½ç»•é“æ€è€ƒï¼ˆç®€åŒ–ç‰ˆå®ç°ï¼‰
        
        å½“æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯è¡Œæ—¶ï¼Œåˆ›å»ºä¸€ä¸ªå¤‡é€‰è·¯å¾„
        """
        logger.info("æ‰§è¡Œæ™ºèƒ½ç»•é“æ€è€ƒ")
        
        # åˆ›å»ºä¸€ä¸ªåˆ›æ–°è·¯å¾„ä½œä¸ºç»•é“æ–¹æ¡ˆ
        detour_path = ReasoningPath(
            path_id=f"detour_{int(time.time())}",
            path_type="åˆ›æ–°ç»•é“æ€è€ƒ",
            description=f"é’ˆå¯¹'{user_query}'çš„åˆ›æ–°è§£å†³æ–¹æ¡ˆï¼Œçªç ´å¸¸è§„æ€ç»´é™åˆ¶",
            prompt_template="é‡‡ç”¨åˆ›æ–°æ€ç»´ï¼Œå¯»æ‰¾ç‹¬ç‰¹çš„è§£å†³è§’åº¦",
            strategy_id="creative_detour",
            instance_id=f"creative_detour_{int(time.time())}"
        )
        
        return detour_path
    
    def _update_component_performance(self, component_name: str, execution_time: float):
        """æ›´æ–°ç»„ä»¶æ€§èƒ½ç»Ÿè®¡"""
        if component_name in self.performance_stats['component_performance']:
            component_stats = self.performance_stats['component_performance'][component_name]
            component_stats['calls'] += 1
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            current_avg = component_stats['avg_time']
            call_count = component_stats['calls']
            component_stats['avg_time'] = (current_avg * (call_count - 1) + execution_time) / call_count
    
    def _update_planner_stats(self, success: bool, execution_time: float):
        """æ›´æ–°è§„åˆ’å™¨ç»Ÿè®¡"""
        self.performance_stats['total_decisions'] += 1
        
        # æ›´æ–°å¹³å‡å†³ç­–æ—¶é—´
        current_avg = self.performance_stats['avg_decision_time']
        total_decisions = self.performance_stats['total_decisions']
        
        if total_decisions == 1:
            self.performance_stats['avg_decision_time'] = execution_time
        else:
            self.performance_stats['avg_decision_time'] = (
                current_avg * (total_decisions - 1) + execution_time
            ) / total_decisions
    
    def _create_error_decision_result(self, user_query: str, error_msg: str, execution_time: float) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å†³ç­–ç»“æœ"""
        return {
            'timestamp': time.time(),
            'round_number': self.total_rounds,
            'user_query': user_query,
            'chosen_path': None,
            'available_paths': [],
            'verified_paths': [],
            'reasoning': f"å†³ç­–å¤±è´¥: {error_msg}",
            'fallback_used': True,
            'error': error_msg,
            'performance_metrics': {
                'total_time': execution_time,
                'error': True
            }
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–è§„åˆ’å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'name': self.name,
            'total_rounds': self.total_rounds,
            'performance_stats': self.performance_stats.copy(),
            'decision_history_length': len(self.decision_history),
            'components': {
                'prior_reasoner': type(self.prior_reasoner).__name__,
                'path_generator': type(self.path_generator).__name__,
                'mab_converger': type(self.mab_converger).__name__
            }
        }
    
    # ==================== æ–°å¢ï¼šä¸­å¿ƒåŒ–ä¸Šä¸‹æ–‡åè®®è¾…åŠ©æ–¹æ³• ====================
    
    def _execute_stage1_thinking_seed(self, user_query: str, execution_context: Optional[Dict], enable_streaming: bool = False) -> ThinkingSeedContext:
        """æ‰§è¡Œé˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ç”Ÿæˆ"""
        context = ThinkingSeedContext(user_query=user_query, execution_context=execution_context)
        
        try:
            # ä½¿ç”¨PriorReasonerç”Ÿæˆæ€ç»´ç§å­
            seed_result = self.prior_reasoner.generate_thinking_seed(
                user_query=user_query,
                execution_context=execution_context,
                enable_streaming=enable_streaming
            )
            
            context.thinking_seed = seed_result.get("thinking_seed", "")
            context.reasoning_process = seed_result.get("reasoning", "")
            context.confidence_score = seed_result.get("confidence", 0.5)
            context.generation_method = "prior_reasoning"
            context.seed_type = "basic"
            
            logger.info(f"æ€ç»´ç§å­: {context.thinking_seed[:100]}...")
            
        except Exception as e:
            logger.error(f"   âŒ æ€ç»´ç§å­ç”Ÿæˆå¤±è´¥: {e}")
            context.add_error(f"ç§å­ç”Ÿæˆå¤±è´¥: {str(e)}")
            context.thinking_seed = f"åŸºäºæŸ¥è¯¢çš„åŸºç¡€åˆ†æ: {user_query}"
            context.confidence_score = 0.3
        
        return context
    
    def _execute_stage2_seed_verification(self, 
                                         stage1_context: ThinkingSeedContext,
                                         execution_context: Optional[Dict],
                                         streaming_output = None) -> SeedVerificationContext:
        """
        æ‰§è¡Œé˜¶æ®µäºŒï¼šç§å­éªŒè¯ä¸å¢å¼º
        
        Args:
            stage1_context: é˜¶æ®µä¸€ä¸Šä¸‹æ–‡
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            streaming_output: æµå¼è¾“å‡ºå¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            SeedVerificationContext: ç§å­éªŒè¯ä¸Šä¸‹æ–‡
        """
        try:
            logger.info("ğŸ” å¼€å§‹é˜¶æ®µäºŒï¼šç§å­éªŒè¯ä¸å¢å¼º")
            
            # ä½¿ç”¨ SeedVerifier è¿›è¡ŒéªŒè¯
            if self.seed_verifier:
                stage2_context = self.seed_verifier.verify(
                    stage1_context=stage1_context,
                    execution_context=execution_context,
                    streaming_output=streaming_output
                )
                return stage2_context
            else:
                # å¦‚æœæ²¡æœ‰ seed_verifierï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„éªŒè¯ä¸Šä¸‹æ–‡
                logger.warning("âš ï¸ SeedVerifier ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–éªŒè¯")
                context = SeedVerificationContext(
                    user_query=stage1_context.user_query,
                    execution_context=execution_context
                )
                context.verification_result = True
                context.feasibility_score = 0.6
                context.verification_method = "simplified_no_verifier"
                context.verification_evidence = ["SeedVerifier ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–éªŒè¯"]
                context.enhanced_thinking_seed = stage1_context.thinking_seed
                return context
                
        except Exception as e:
            logger.error(f"âŒ é˜¶æ®µäºŒæ‰§è¡Œå¼‚å¸¸: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            
            # åˆ›å»ºå¼‚å¸¸å›é€€ä¸Šä¸‹æ–‡
            context = SeedVerificationContext(
                user_query=stage1_context.user_query,
                execution_context=execution_context
            )
            context.verification_result = True  # ä¸é˜»æ­¢æµç¨‹ç»§ç»­
            context.feasibility_score = 0.3
            context.verification_method = "exception_fallback"
            context.verification_evidence = [f"éªŒè¯å¼‚å¸¸: {str(e)}", "ä½¿ç”¨å¼‚å¸¸å›é€€éªŒè¯"]
            context.add_error(f"éªŒè¯å¼‚å¸¸: {str(e)}")
            context.enhanced_thinking_seed = stage1_context.thinking_seed
            return context
    
    def _extract_key_concepts_from_seed(self, thinking_seed: str, max_concepts: int = 5) -> List[str]:
        """
        ä»æ€ç»´ç§å­ä¸­æå–å…³é”®æ¦‚å¿µ
        
        Args:
            thinking_seed: æ€ç»´ç§å­æ–‡æœ¬
            max_concepts: æœ€å¤šæå–çš„æ¦‚å¿µæ•°é‡
            
        Returns:
            List[str]: æå–çš„å…³é”®æ¦‚å¿µåˆ—è¡¨
        """
        import re
        
        key_concepts = []
        
        # æ–¹æ³•1: æå–ä¸“æœ‰åè¯å’ŒæŠ€æœ¯æœ¯è¯­ï¼ˆè‹±æ–‡å¤§å†™å¼€å¤´çš„è¯ç»„ï¼‰
        # åŒ¹é…å¦‚ "AlphaGo", "ChatGPT", "Deep Learning" ç­‰
        capitalized_terms = re.findall(r'\b[A-Z][a-zA-Z]*(?:\s+[A-Z][a-zA-Z]*)*\b', thinking_seed)
        key_concepts.extend(capitalized_terms[:3])
        
        # æ–¹æ³•2: æå–ä¸­æ–‡ä¸“ä¸šæœ¯è¯­ï¼ˆé€šè¿‡å…³é”®æ ‡è®°è¯è¯†åˆ«ï¼‰
        # åŒ¹é…å¦‚ "å¼ºåŒ–å­¦ä¹ "ã€"ç¥ç»ç½‘ç»œ"ã€"æœºå™¨å­¦ä¹ " ç­‰
        cn_tech_patterns = [
            r'(\w{2,6}å­¦ä¹ )',  # å­¦ä¹ ç›¸å…³
            r'(\w{2,6}ç®—æ³•)',  # ç®—æ³•ç›¸å…³
            r'(\w{2,6}ç³»ç»Ÿ)',  # ç³»ç»Ÿç›¸å…³
            r'(\w{2,6}æŠ€æœ¯)',  # æŠ€æœ¯ç›¸å…³
            r'(\w{2,6}ç½‘ç»œ)',  # ç½‘ç»œç›¸å…³
            r'(\w{2,6}æ¨¡å‹)',  # æ¨¡å‹ç›¸å…³
            r'(\w{2,6}æ¡†æ¶)',  # æ¡†æ¶ç›¸å…³
        ]
        
        for pattern in cn_tech_patterns:
            matches = re.findall(pattern, thinking_seed)
            key_concepts.extend(matches)
        
        # æ–¹æ³•3: æå–å¼•å·ä¸­çš„é‡ç‚¹å†…å®¹
        quoted_terms = re.findall(r'[ã€Œã€""]([^ã€ã€""]+)[ã€ã€""]', thinking_seed)
        key_concepts.extend(quoted_terms[:2])
        
        # å»é‡å¹¶ä¿ç•™é¡ºåº
        seen = set()
        unique_concepts = []
        for concept in key_concepts:
            concept_clean = concept.strip()
            if concept_clean and len(concept_clean) > 1 and concept_clean not in seen:
                seen.add(concept_clean)
                unique_concepts.append(concept_clean)
        
        # é™åˆ¶æ•°é‡
        result = unique_concepts[:max_concepts]
        
        # å¦‚æœæå–ä¸åˆ°ï¼Œä½¿ç”¨ç§å­çš„å‰30ä¸ªå­—ç¬¦ä½œä¸ºå…³é”®æ¦‚å¿µ
        if not result:
            seed_snippet = thinking_seed[:30].strip()
            if seed_snippet:
                result = [seed_snippet]
        
        logger.info(f"ğŸ” ä»ç§å­ä¸­æå–äº† {len(result)} ä¸ªå…³é”®æ¦‚å¿µ: {result}")
        return result
    
    def _llm_select_search_dimensions(self, thinking_seed: str, user_query: str, 
                                     key_concepts: List[str]) -> List[str]:
        """
        ä½¿ç”¨LLMæ™ºèƒ½é€‰æ‹©éœ€è¦æœç´¢çš„ç»´åº¦
        
        Args:
            thinking_seed: æ€ç»´ç§å­
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            key_concepts: å…³é”®æ¦‚å¿µåˆ—è¡¨
            
        Returns:
            List[str]: é€‰æ‹©çš„æœç´¢ç»´åº¦åˆ—è¡¨
        """
        import re
        
        try:
            # å¦‚æœæœ‰è¯­ä¹‰åˆ†æå™¨ï¼Œä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½é€‰æ‹©
            if self.semantic_analyzer:
                logger.info("ğŸ§  ä½¿ç”¨LLMæ™ºèƒ½é€‰æ‹©æœç´¢ç»´åº¦...")
                
                dimension_selection_prompt = f"""æˆ‘æ­£åœ¨åˆ†æç”¨æˆ·çš„æŸ¥è¯¢å’Œæˆ‘ç”Ÿæˆçš„æ€ç»´ç§å­ï¼Œéœ€è¦å†³å®šä»å“ªäº›ç»´åº¦è¿›è¡Œç½‘ç»œæœç´¢éªŒè¯ã€‚

**ç”¨æˆ·æŸ¥è¯¢ï¼š**
{user_query}

**æˆ‘çš„æ€ç»´ç§å­ï¼š**
{thinking_seed[:300]}

**æå–çš„å…³é”®æ¦‚å¿µï¼š**
{', '.join(key_concepts)}

**å¯é€‰çš„æœç´¢ç»´åº¦ï¼š**
1. å®é™…ä¾‹å­ - æœç´¢çœŸå®æ¡ˆä¾‹å’Œåº”ç”¨å®ä¾‹
2. å®æ–½æ¡ˆä¾‹ - æœç´¢å…·ä½“çš„å®æ–½æ–¹æ¡ˆå’Œåº”ç”¨åœºæ™¯
3. æ½œåœ¨é£é™© - æœç´¢å¯èƒ½çš„é—®é¢˜ã€æŒ‘æˆ˜å’Œé£é™©
4. ç›¸å…³ç ”ç©¶ - æœç´¢å­¦æœ¯è®ºæ–‡å’Œç ”ç©¶æˆæœï¼ˆé€‚ç”¨äºå­¦æœ¯/æŠ€æœ¯é—®é¢˜ï¼‰
5. æœ€æ–°è¿›å±• - æœç´¢æœ€æ–°çš„å‘å±•åŠ¨æ€å’Œè¶‹åŠ¿
6. å¯¹æ¯”åˆ†æ - æœç´¢ä¸åŒæ–¹æ¡ˆçš„å¯¹æ¯”å’Œä¼˜ç¼ºç‚¹
7. ä¸“å®¶è§‚ç‚¹ - æœç´¢ä¸“å®¶è¯„ä»·å’Œæƒå¨è§‚ç‚¹

**è¯·ä½ æ¨¡æ‹ŸAgentçš„æ€è€ƒè¿‡ç¨‹ï¼Œç”¨è‡ªç„¶çš„è¯­è¨€åˆ†æå¹¶é€‰æ‹©æœç´¢ç»´åº¦ã€‚è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š**

è®©æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªé—®é¢˜ã€‚å¯¹äºç”¨æˆ·å…³äº"XXX"çš„æŸ¥è¯¢ï¼Œè¿™æ˜¯ä¸€ä¸ªã€æŠ€æœ¯ç†è®º/å®è·µæ“ä½œ/è¯„ä¼°å†³ç­–/çŸ¥è¯†äº†è§£ã€‘ç±»é—®é¢˜ã€‚

åŸºäºæˆ‘çš„æ€ç»´ç§å­åˆ†æï¼Œæˆ‘è®¤ä¸ºä»ä»¥ä¸‹Xä¸ªç»´åº¦è¿›è¡Œæœç´¢éªŒè¯æ›´åˆé€‚ï¼š
- å®é™…ä¾‹å­ï¼ˆå› ä¸ºéœ€è¦äº†è§£çœŸå®åº”ç”¨åœºæ™¯ï¼‰
- æœ€æ–°è¿›å±•ï¼ˆå› ä¸ºéœ€è¦2025å¹´çš„æœ€æ–°ä¿¡æ¯ï¼‰
- æ½œåœ¨é£é™©ï¼ˆå› ä¸ºéœ€è¦è¯„ä¼°å¯è¡Œæ€§ï¼‰
...

ç°åœ¨è®©æˆ‘å¼€å§‹æœç´¢è¿™äº›ç»´åº¦ã€‚

---
**è¦æ±‚ï¼š**
1. å¿…é¡»æ˜ç¡®è¯´æ˜é—®é¢˜ç±»å‹ï¼ˆæŠ€æœ¯ç†è®º/å®è·µæ“ä½œ/è¯„ä¼°å†³ç­–/çŸ¥è¯†äº†è§£ç­‰ï¼‰
2. å¿…é¡»é€‰æ‹©3-5ä¸ªç»´åº¦ï¼Œä¸è¦å¤ªå¤šä¹Ÿä¸è¦å¤ªå°‘
3. æ¯ä¸ªç»´åº¦è¦ç®€çŸ­è¯´æ˜é€‰æ‹©ç†ç”±ï¼ˆæ‹¬å·å†…ï¼‰
4. é¿å…é€‰æ‹©ä¸ç›¸å…³çš„ç»´åº¦ï¼ˆæ¯”å¦‚å®è·µé—®é¢˜ä¸éœ€è¦å­¦æœ¯è®ºæ–‡ï¼‰
5. æœ€åä¸€å¥å›ºå®šè¯´"ç°åœ¨è®©æˆ‘å¼€å§‹æœç´¢è¿™äº›ç»´åº¦"
"""

                # ç›´æ¥è°ƒç”¨LLMè¿›è¡Œç»´åº¦é€‰æ‹©ï¼ˆç»•è¿‡SemanticAnalyzerçš„JSONè§£æï¼‰
                logger.info("ğŸ§  ä½¿ç”¨LLMç›´æ¥è¿›è¡Œç»´åº¦é€‰æ‹©...")
                
                # ä½¿ç”¨PriorReasonerçš„LLMç®¡ç†å™¨ç›´æ¥è°ƒç”¨
                if hasattr(self.prior_reasoner, 'llm_manager') and self.prior_reasoner.llm_manager:
                    try:
                        llm_response = self.prior_reasoner.llm_manager.call_api(
                            prompt=dimension_selection_prompt,
                            temperature=0.7,
                            max_tokens=1000
                        )
                        
                        if llm_response and isinstance(llm_response, str):
                            logger.info("")
                            logger.info("ğŸ§  LLMç»´åº¦é€‰æ‹©åˆ†æè¿‡ç¨‹ï¼š")
                            logger.info("-" * 60)
                            
                            # æ˜¾ç¤ºLLMçš„å®Œæ•´åˆ†æè¿‡ç¨‹
                            analysis_lines = llm_response.strip().split('\n')
                            for line in analysis_lines[:10]:  # æ˜¾ç¤ºå‰10è¡Œå…³é”®åˆ†æ
                                if line.strip():
                                    logger.info(f"   {line.strip()}")
                            
                            logger.info("-" * 60)
                            
                            # è§£æLLMè¿”å›çš„ç»´åº¦åˆ—è¡¨
                            selected_dimensions = []
                            all_dimension_names = [
                                "å®é™…ä¾‹å­", "å®æ–½æ¡ˆä¾‹", "æ½œåœ¨é£é™©", "ç›¸å…³ç ”ç©¶",
                                "æœ€æ–°è¿›å±•", "å¯¹æ¯”åˆ†æ", "ä¸“å®¶è§‚ç‚¹"
                            ]
                            
                            # ä»LLMå“åº”ä¸­æå–ç»´åº¦åç§°
                            analysis_content = llm_response.lower()
                            logger.info("ğŸ” è§£æLLMé€‰æ‹©çš„ç»´åº¦ï¼š")
                            
                            for line in analysis_lines:
                                line_clean = line.strip().strip('- ').strip('* ').strip()
                                # åŒ¹é…ç»´åº¦åç§°ï¼ˆå¯èƒ½åœ¨æ‹¬å·å‰ï¼‰
                                for dim_name in all_dimension_names:
                                    if dim_name in line_clean:
                                        if dim_name not in selected_dimensions:
                                            selected_dimensions.append(dim_name)
                                            logger.info(f"   âœ… é€‰æ‹©ç»´åº¦: {dim_name}")
                                            
                                            # æå–ç†ç”±ï¼ˆæ‹¬å·å†…çš„å†…å®¹ï¼‰
                                            reason_match = re.search(r'ï¼ˆ([^ï¼‰]+)ï¼‰|\(([^)]+)\)', line_clean)
                                            if reason_match:
                                                reason = reason_match.group(1) or reason_match.group(2)
                                                logger.info(f"      ğŸ’¡ é€‰æ‹©ç†ç”±: {reason}")
                                        break
                            
                            if selected_dimensions and len(selected_dimensions) >= 2:
                                logger.info(f"")
                                logger.info(f"ğŸ¯ LLMæœ€ç»ˆé€‰æ‹©: {selected_dimensions}")
                                logger.info(f"ğŸ“Š é€‰æ‹©æ•°é‡: {len(selected_dimensions)} ä¸ªç»´åº¦")
                                return selected_dimensions
                            else:
                                logger.warning("âš ï¸ LLMè¿”å›çš„ç»´åº¦æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨å›é€€ç­–ç•¥")
                        else:
                            logger.warning("âš ï¸ LLMå“åº”æ— æ•ˆï¼Œä½¿ç”¨å›é€€ç­–ç•¥")
                            
                    except Exception as e:
                        logger.warning(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥: {e}")
                else:
                    logger.warning("âš ï¸ LLMç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨å›é€€ç­–ç•¥")
                
            else:
                logger.info("âš ï¸ è¯­ä¹‰åˆ†æå™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨å¯å‘å¼ç»´åº¦é€‰æ‹©")
                
        except Exception as e:
            logger.warning(f"âš ï¸ LLMç»´åº¦é€‰æ‹©å¤±è´¥: {e}")
        
        # å›é€€ç­–ç•¥ï¼šåŸºäºå…³é”®è¯çš„å¯å‘å¼é€‰æ‹©
        query_lower = user_query.lower()
        seed_lower = thinking_seed.lower()
        combined_text = query_lower + " " + seed_lower
        
        selected = ["å®é™…ä¾‹å­", "æœ€æ–°è¿›å±•", "æ½œåœ¨é£é™©"]  # åŸºç¡€ç»´åº¦
        
        # æ£€æµ‹å­¦æœ¯/æŠ€æœ¯å…³é”®è¯
        if any(kw in combined_text for kw in ['ç ”ç©¶', 'è®ºæ–‡', 'ç®—æ³•', 'ç†è®º', 'research', 'algorithm']):
            if "ç›¸å…³ç ”ç©¶" not in selected:
                selected.append("ç›¸å…³ç ”ç©¶")
        
        # æ£€æµ‹å®è·µå…³é”®è¯
        if any(kw in combined_text for kw in ['å¦‚ä½•', 'æ€ä¹ˆ', 'å®ç°', 'æ“ä½œ', 'how to']):
            if "å®æ–½æ¡ˆä¾‹" not in selected:
                selected.append("å®æ–½æ¡ˆä¾‹")
        
        # æ£€æµ‹å¯¹æ¯”éœ€æ±‚
        if any(kw in combined_text for kw in ['å¯¹æ¯”', 'æ¯”è¾ƒ', 'åŒºåˆ«', 'compare', 'vs']):
            if "å¯¹æ¯”åˆ†æ" not in selected:
                selected.append("å¯¹æ¯”åˆ†æ")
        
        logger.info(f"ğŸ“‹ å¯å‘å¼é€‰æ‹©äº† {len(selected)} ä¸ªæœç´¢ç»´åº¦: {selected}")
        return selected
    
    def _prompt_user_dimension_selection(self, llm_selected: List[str], 
                                        all_dimensions: List[str]) -> List[str]:
        """
        æç¤ºç”¨æˆ·ç¡®è®¤æˆ–è°ƒæ•´æœç´¢ç»´åº¦é€‰æ‹©
        
        Args:
            llm_selected: LLMé€‰æ‹©çš„ç»´åº¦
            all_dimensions: æ‰€æœ‰å¯ç”¨ç»´åº¦
            
        Returns:
            List[str]: æœ€ç»ˆç¡®å®šçš„ç»´åº¦åˆ—è¡¨
        """
        try:
            # è®¡ç®—æœªé€‰æ‹©çš„ç»´åº¦
            not_selected = [d for d in all_dimensions if d not in llm_selected]
            
            # å±•ç¤ºé€‰æ‹©ç»“æœ
            logger.info("=" * 60)
            logger.info("ğŸ¤– Agentæ™ºèƒ½åˆ†æå®Œæˆï¼Œæœç´¢ç»´åº¦å»ºè®®ï¼š")
            logger.info("=" * 60)
            logger.info("")
            logger.info("âœ… Agentå»ºè®®æœç´¢ä»¥ä¸‹ç»´åº¦ï¼š")
            for i, dim in enumerate(llm_selected, 1):
                logger.info(f"   {i}. {dim}")
            
            if not_selected:
                logger.info("")
                logger.info("â¸ï¸  æš‚æœªé€‰æ‹©çš„ç»´åº¦ï¼š")
                for i, dim in enumerate(not_selected, 1):
                    logger.info(f"   {len(llm_selected) + i}. {dim}")
            
            logger.info("")
            logger.info("ğŸ’¡ æ‚¨å¯ä»¥ï¼š")
            logger.info("   - ç›´æ¥å›è½¦ï¼šä½¿ç”¨Agentçš„å»ºè®®")
            logger.info("   - è¾“å…¥æ•°å­—ï¼ˆå¦‚ 5,6ï¼‰ï¼šè¡¥å……é¢å¤–çš„æœç´¢ç»´åº¦")
            logger.info("   - è¾“å…¥è‡ªå®šä¹‰ç»´åº¦åç§°ï¼šæ·»åŠ è‡ªå®šä¹‰æœç´¢ç»´åº¦")
            logger.info("")
            
            # è®¾ç½®è¶…æ—¶ç­‰å¾…ç”¨æˆ·è¾“å…¥
            import sys
            import select
            
            # Windowsç³»ç»Ÿéœ€è¦ç‰¹æ®Šå¤„ç†
            if sys.platform == 'win32':
                # Windowsä¸Šä½¿ç”¨msvcrt
                try:
                    import msvcrt
                    import time
                    
                    logger.info("â±ï¸  ç­‰å¾…5ç§’æ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼ˆWindowsï¼‰...")
                    start_time = time.time()
                    user_input = ""
                    
                    while time.time() - start_time < 5:
                        if msvcrt.kbhit():
                            char = msvcrt.getwche()
                            if char == '\r':  # Enteré”®
                                break
                            elif char == '\b':  # é€€æ ¼é”®
                                if user_input:
                                    user_input = user_input[:-1]
                                    sys.stdout.write('\b \b')
                            else:
                                user_input += char
                        time.sleep(0.1)
                    
                    print()  # æ¢è¡Œ
                    
                except ImportError:
                    # å¦‚æœmsvcrtä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨inputä½†ä¸ç­‰å¾…
                    logger.info("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é€‰æ‹©ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤ï¼‰ï¼š")
                    user_input = ""
            else:
                # Unix/Linuxç³»ç»Ÿä½¿ç”¨select
                logger.info("â±ï¸  ç­‰å¾…5ç§’æ¥æ”¶ç”¨æˆ·è¾“å…¥...")
                ready, _, _ = select.select([sys.stdin], [], [], 5)
                if ready:
                    user_input = sys.stdin.readline().strip()
                else:
                    user_input = ""
            
            # å¤„ç†ç”¨æˆ·è¾“å…¥
            if not user_input or user_input.strip() == "":
                logger.info("âœ… ä½¿ç”¨Agenté»˜è®¤é€‰æ‹©")
                return llm_selected
            
            # è§£æç”¨æˆ·è¾“å…¥
            final_dimensions = llm_selected.copy()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å­—é€‰æ‹©
            if any(c.isdigit() or c == ',' for c in user_input):
                # è§£ææ•°å­—
                numbers = []
                for part in user_input.replace('ï¼Œ', ',').split(','):
                    try:
                        num = int(part.strip())
                        if 1 <= num <= len(all_dimensions):
                            numbers.append(num)
                    except ValueError:
                        continue
                
                # æ·»åŠ é€‰æ‹©çš„ç»´åº¦
                all_dims_list = llm_selected + not_selected
                for num in numbers:
                    dim_name = all_dims_list[num - 1]
                    if dim_name not in final_dimensions:
                        final_dimensions.append(dim_name)
                        logger.info(f"â• æ·»åŠ ç»´åº¦: {dim_name}")
            else:
                # ä½œä¸ºè‡ªå®šä¹‰ç»´åº¦åç§°
                custom_dim = user_input.strip()
                if custom_dim and custom_dim not in final_dimensions:
                    final_dimensions.append(custom_dim)
                    logger.info(f"â• æ·»åŠ è‡ªå®šä¹‰ç»´åº¦: {custom_dim}")
            
            logger.info(f"âœ… æœ€ç»ˆæœç´¢ç»´åº¦: {final_dimensions}")
            logger.info("=" * 60)
            
            return final_dimensions
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç”¨æˆ·äº¤äº’å¤±è´¥: {e}")
            logger.info("âœ… ä½¿ç”¨Agenté»˜è®¤é€‰æ‹©")
            return llm_selected
    
    def _perform_multidimensional_verification_search(self, key_concepts: List[str], 
                                                    user_query: str,
                                                    thinking_seed: str = "",
                                                    enable_user_interaction: bool = False) -> Dict[str, List[Dict]]:
        """
        æ‰§è¡Œå¤šç»´åº¦éªŒè¯æœç´¢ï¼ˆLLMæ™ºèƒ½é€‰æ‹©ç»´åº¦ï¼‰
        
        Args:
            key_concepts: å…³é”®æ¦‚å¿µåˆ—è¡¨
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            thinking_seed: æ€ç»´ç§å­ï¼ˆç”¨äºLLMåˆ†æï¼‰
            
        Returns:
            Dict[str, List[Dict]]: æŒ‰ç»´åº¦ç»„ç»‡çš„æœç´¢ç»“æœ
        """
        from datetime import datetime
        
        # è·å–å½“å‰å¹´ä»½
        current_year = datetime.now().year
        logger.info(f"ğŸ“… å½“å‰å¹´ä»½: {current_year}")
        
        # é€‰æ‹©ä¸»è¦å…³é”®æ¦‚å¿µï¼ˆå–å‰2ä¸ªï¼Œé¿å…æŸ¥è¯¢è¿‡é•¿ï¼‰
        main_concepts = key_concepts[:2] if len(key_concepts) >= 2 else key_concepts
        concept_query = " ".join(main_concepts) if main_concepts else user_query[:30]
        
        # ğŸ§  ä½¿ç”¨LLMæ™ºèƒ½é€‰æ‹©æœç´¢ç»´åº¦
        selected_dimension_names = self._llm_select_search_dimensions(
            thinking_seed=thinking_seed,
            user_query=user_query,
            key_concepts=key_concepts
        )
        
        # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„æœç´¢ç»´åº¦
        all_dimension_names = [
            "å®é™…ä¾‹å­", "å®æ–½æ¡ˆä¾‹", "æ½œåœ¨é£é™©", "ç›¸å…³ç ”ç©¶",
            "æœ€æ–°è¿›å±•", "å¯¹æ¯”åˆ†æ", "ä¸“å®¶è§‚ç‚¹"
        ]
        
        # ğŸ‘¤ å¦‚æœå¯ç”¨ç”¨æˆ·äº¤äº’ï¼Œè®©ç”¨æˆ·ç¡®è®¤æˆ–è°ƒæ•´é€‰æ‹©
        if enable_user_interaction:
            selected_dimension_names = self._prompt_user_dimension_selection(
                llm_selected=selected_dimension_names,
                all_dimensions=all_dimension_names
            )
        
        # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„æœç´¢ç»´åº¦åŠå…¶æŸ¥è¯¢æ¨¡æ¿
        all_search_dimensions = {
            "å®é™…ä¾‹å­": f"{concept_query} å®é™…ä¾‹å­ æ¡ˆä¾‹ {current_year}",
            "å®æ–½æ¡ˆä¾‹": f"{concept_query} å®æ–½ åº”ç”¨æ¡ˆä¾‹ {current_year}",
            "æ½œåœ¨é£é™©": f"{concept_query} é£é™© é—®é¢˜ æŒ‘æˆ˜",
            "ç›¸å…³ç ”ç©¶": f"{concept_query} ç ”ç©¶ è®ºæ–‡ {current_year}",
            "æœ€æ–°è¿›å±•": f"{concept_query} æœ€æ–°è¿›å±• {current_year}",
            "å¯¹æ¯”åˆ†æ": f"{concept_query} å¯¹æ¯” æ¯”è¾ƒ ä¼˜ç¼ºç‚¹",
            "ä¸“å®¶è§‚ç‚¹": f"{concept_query} ä¸“å®¶ è§‚ç‚¹ è¯„ä»·"
        }
        
        # æ„å»ºæœ€ç»ˆçš„æœç´¢ç»´åº¦å­—å…¸ï¼ˆåŒ…æ‹¬è‡ªå®šä¹‰ç»´åº¦ï¼‰
        search_dimensions = {}
        for dim_name in selected_dimension_names:
            if dim_name in all_search_dimensions:
                search_dimensions[dim_name] = all_search_dimensions[dim_name]
            else:
                # ç”¨æˆ·è‡ªå®šä¹‰ç»´åº¦
                search_dimensions[dim_name] = f"{concept_query} {dim_name} {current_year}"
                logger.info(f"ğŸ†• ä½¿ç”¨è‡ªå®šä¹‰æœç´¢ç»´åº¦: {dim_name}")
        
        multidim_results = {}
        
        logger.info("")
        logger.info("=" * 80)
        logger.info("ğŸ” å¼€å§‹æ‰§è¡Œå¤šç»´åº¦éªŒè¯æœç´¢")
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š è®¡åˆ’æœç´¢ {len(search_dimensions)} ä¸ªç»´åº¦")
        logger.info("")
        
        for i, (dimension, query) in enumerate(search_dimensions.items(), 1):
            try:
                logger.info(f"ğŸ” [{i}/{len(search_dimensions)}] æœç´¢ç»´åº¦: {dimension}")
                logger.info(f"   ğŸ“ æœç´¢æŸ¥è¯¢: {query}")
                logger.info(f"   â³ æ­£åœ¨æœç´¢...")
                
                # ä½¿ç”¨ web_search å·¥å…·æ‰§è¡Œæœç´¢
                search_result = execute_tool(
                    "web_search",
                    query=query,
                    max_results=3
                )
                
                if search_result and search_result.success:
                    # æå–æœç´¢ç»“æœ
                    results_data = search_result.data
                    search_results = results_data.get("results", [])
                    
                    multidim_results[dimension] = search_results
                    logger.info(f"   âœ… æœç´¢æˆåŠŸ: æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
                    
                    # æ˜¾ç¤ºå‰2ä¸ªç»“æœçš„æ ‡é¢˜å’ŒURL
                    if search_results:
                        logger.info(f"   ğŸ“„ æœç´¢ç»“æœé¢„è§ˆ:")
                        for j, result in enumerate(search_results[:2], 1):
                            title = result.get('title', 'æ— æ ‡é¢˜')
                            url = result.get('url', 'æ— URL')
                            logger.info(f"      {j}. {title}")
                            logger.info(f"         ğŸ”— {url}")
                    logger.info("")
                else:
                    logger.warning(f"   âš ï¸ æœç´¢å¤±è´¥æˆ–æ— ç»“æœ")
                    multidim_results[dimension] = []
                    logger.info("")
                    
            except Exception as e:
                logger.warning(f"   âŒ æœç´¢å¼‚å¸¸: {e}")
                multidim_results[dimension] = []
                logger.info("")
        
        # ç»Ÿè®¡æ€»ç»“æœæ•°
        total_results = sum(len(results) for results in multidim_results.values())
        logger.info(f"ğŸ¯ å¤šç»´åº¦æœç´¢å®Œæˆï¼Œå…±è·å¾— {total_results} ä¸ªç»“æœ")
        
        return multidim_results
    
    def _ask_user_for_additional_search(self, completed_dimensions: List[str], 
                                        user_query: str, key_concepts: List[str]) -> List[str]:
        """
        åœ¨åˆå§‹æœç´¢å®Œæˆåï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦è¦è¡¥å……å…¶ä»–ç»´åº¦
        
        Args:
            completed_dimensions: å·²å®Œæˆçš„æœç´¢ç»´åº¦
            user_query: ç”¨æˆ·æŸ¥è¯¢
            key_concepts: å…³é”®æ¦‚å¿µ
            
        Returns:
            List[str]: ç”¨æˆ·é€‰æ‹©çš„è¡¥å……ç»´åº¦
        """
        from datetime import datetime
        current_year = datetime.now().year
        concept_query = " ".join(key_concepts[:2]) if key_concepts else user_query[:30]
        
        # å®šä¹‰æ‰€æœ‰ç»´åº¦åŠå…¶æœç´¢å†…å®¹
        all_dimensions = {
            "å®é™…ä¾‹å­": f"{concept_query} å®é™…ä¾‹å­ æ¡ˆä¾‹ {current_year}",
            "å®æ–½æ¡ˆä¾‹": f"{concept_query} å®æ–½ åº”ç”¨æ¡ˆä¾‹ {current_year}",
            "æ½œåœ¨é£é™©": f"{concept_query} é£é™© é—®é¢˜ æŒ‘æˆ˜",
            "ç›¸å…³ç ”ç©¶": f"{concept_query} ç ”ç©¶ è®ºæ–‡ {current_year}",
            "æœ€æ–°è¿›å±•": f"{concept_query} æœ€æ–°è¿›å±• {current_year}",
            "å¯¹æ¯”åˆ†æ": f"{concept_query} å¯¹æ¯” æ¯”è¾ƒ ä¼˜ç¼ºç‚¹",
            "ä¸“å®¶è§‚ç‚¹": f"{concept_query} ä¸“å®¶ è§‚ç‚¹ è¯„ä»·"
        }
        
        # æœªå®Œæˆçš„ç»´åº¦
        remaining_dimensions = {k: v for k, v in all_dimensions.items() 
                              if k not in completed_dimensions}
        
        if not remaining_dimensions:
            print("\nâœ… æ‰€æœ‰æœç´¢ç»´åº¦å·²å®Œæˆï¼Œæ— éœ€è¡¥å……", flush=True)
            return []
        
        print("\n" + "="*80, flush=True)
        print("ğŸ“Š åˆå§‹æœç´¢å·²å®Œæˆ", flush=True)
        print("="*80, flush=True)
        print(f"\nâœ… å·²å®Œæˆçš„æœç´¢ç»´åº¦ ({len(completed_dimensions)}ä¸ª):", flush=True)
        for i, dim in enumerate(completed_dimensions, 1):
            print(f"   {i}. {dim}", flush=True)
        
        print(f"\nâ¸ï¸  å¯è¡¥å……çš„æœç´¢ç»´åº¦ ({len(remaining_dimensions)}ä¸ª):", flush=True)
        dim_list = list(remaining_dimensions.keys())
        for i, dim in enumerate(dim_list, 1):
            search_query = remaining_dimensions[dim]
            print(f"   {i}. ã€{dim}ã€‘", flush=True)
            print(f"      ğŸ” å°†æœç´¢: {search_query}", flush=True)
        
        print("\nğŸ’¡ æ‚¨å¯ä»¥ï¼š", flush=True)
        print("   - ç›´æ¥å›è½¦: ä¸è¡¥å……ï¼Œç»§ç»­ä¸‹ä¸€æ­¥", flush=True)
        print("   - è¾“å…¥æ•°å­— (å¦‚: 1,3): é€‰æ‹©è¦è¡¥å……çš„ç»´åº¦", flush=True)
        print("   - è¾“å…¥ 'all': è¡¥å……æ‰€æœ‰å‰©ä½™ç»´åº¦", flush=True)
        print("   - è¾“å…¥è‡ªå®šä¹‰å†…å®¹: è‡ªå®šä¹‰æœç´¢æŸ¥è¯¢", flush=True)
        print(flush=True)
        
        try:
            user_input = input("è¯·é€‰æ‹© [é»˜è®¤: è·³è¿‡]: ").strip()
            
            if not user_input:
                print("âœ… è·³è¿‡è¡¥å……æœç´¢", flush=True)
                return []
            
            if user_input.lower() == 'all':
                print(f"âœ… è¡¥å……æ‰€æœ‰ {len(dim_list)} ä¸ªç»´åº¦", flush=True)
                return dim_list
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å­—é€‰æ‹©
            if any(c.isdigit() or c == ',' for c in user_input):
                selected = []
                for part in user_input.replace('ï¼Œ', ',').split(','):
                    try:
                        num = int(part.strip())
                        if 1 <= num <= len(dim_list):
                            selected.append(dim_list[num - 1])
                    except ValueError:
                        continue
                if selected:
                    print(f"âœ… è¡¥å……é€‰æ‹©çš„ {len(selected)} ä¸ªç»´åº¦: {', '.join(selected)}", flush=True)
                    return selected
            
            # è‡ªå®šä¹‰æœç´¢
            print(f"âœ… æ·»åŠ è‡ªå®šä¹‰æœç´¢: {user_input}", flush=True)
            return [f"è‡ªå®šä¹‰: {user_input}"]
            
        except (KeyboardInterrupt, EOFError):
            print("\nâœ… è·³è¿‡è¡¥å……æœç´¢", flush=True)
            return []
    
    def _perform_additional_search(self, dimensions: List[str], 
                                   key_concepts: List[str],
                                   user_query: str) -> Dict[str, List[Dict]]:
        """æ‰§è¡Œç”¨æˆ·é€‰æ‹©çš„è¡¥å……æœç´¢"""
        from datetime import datetime
        current_year = datetime.now().year
        concept_query = " ".join(key_concepts[:2]) if key_concepts else user_query[:30]
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        search_queries = {}
        for dim in dimensions:
            if dim.startswith("è‡ªå®šä¹‰:"):
                # ç”¨æˆ·è‡ªå®šä¹‰æœç´¢
                custom_query = dim.replace("è‡ªå®šä¹‰:", "").strip()
                search_queries[dim] = custom_query
            else:
                # é¢„å®šä¹‰ç»´åº¦
                all_dimensions = {
                    "å®é™…ä¾‹å­": f"{concept_query} å®é™…ä¾‹å­ æ¡ˆä¾‹ {current_year}",
                    "å®æ–½æ¡ˆä¾‹": f"{concept_query} å®æ–½ åº”ç”¨æ¡ˆä¾‹ {current_year}",
                    "æ½œåœ¨é£é™©": f"{concept_query} é£é™© é—®é¢˜ æŒ‘æˆ˜",
                    "ç›¸å…³ç ”ç©¶": f"{concept_query} ç ”ç©¶ è®ºæ–‡ {current_year}",
                    "æœ€æ–°è¿›å±•": f"{concept_query} æœ€æ–°è¿›å±• {current_year}",
                    "å¯¹æ¯”åˆ†æ": f"{concept_query} å¯¹æ¯” æ¯”è¾ƒ ä¼˜ç¼ºç‚¹",
                    "ä¸“å®¶è§‚ç‚¹": f"{concept_query} ä¸“å®¶ è§‚ç‚¹ è¯„ä»·"
                }
                search_queries[dim] = all_dimensions.get(dim, f"{concept_query} {dim}")
        
        # æ‰§è¡Œæœç´¢ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
        results = {}
        for dim, query in search_queries.items():
            print(f"\nğŸ” æœç´¢ ã€{dim}ã€‘", flush=True)
            print(f"   ğŸ“ æŸ¥è¯¢: {query}", flush=True)
            try:
                search_result = execute_tool("web_search", query=query, max_results=3)
                if search_result and search_result.success:
                    results[dim] = search_result.data.get("results", [])
                    print(f"   âœ… æ‰¾åˆ° {len(results[dim])} ä¸ªç»“æœ", flush=True)
                else:
                    results[dim] = []
                    print(f"   âš ï¸ æœç´¢å¤±è´¥", flush=True)
            except Exception as e:
                results[dim] = []
                print(f"   âŒ æœç´¢å¼‚å¸¸: {e}", flush=True)
        
        return results
    
    def _enhance_thinking_seed_with_search_results(self, 
                                                   original_seed: str,
                                                   user_query: str,
                                                   verification_data: Dict[str, Any],
                                                   multidim_results: Dict[str, List[Dict]]) -> str:
        """
        åŸºäºæœç´¢ç»“æœå¢å¼ºæ€ç»´ç§å­
        
        Args:
            original_seed: åŸå§‹æ€ç»´ç§å­
            user_query: ç”¨æˆ·æŸ¥è¯¢
            verification_data: éªŒè¯æ•°æ®
            multidim_results: å¤šç»´åº¦æœç´¢ç»“æœ
            
        Returns:
            str: å¢å¼ºåçš„æ€ç»´ç§å­
        """
        try:
            logger.info("ğŸš€ å¼€å§‹å¢å¼ºæ€ç»´ç§å­ç”Ÿæˆ...")
            
            # å¦‚æœæ²¡æœ‰è¯­ä¹‰åˆ†æå™¨ï¼Œè¿”å›åŸå§‹ç§å­
            if not self.semantic_analyzer:
                logger.warning("âš ï¸ è¯­ä¹‰åˆ†æå™¨ä¸å¯ç”¨ï¼Œæ— æ³•å¢å¼ºæ€ç»´ç§å­")
                return original_seed
            
            # æ„å»ºæœç´¢ç»“æœæ‘˜è¦
            search_summary = self._build_search_results_summary(multidim_results)
            
            # æå–éªŒè¯åˆ†ææ‘˜è¦
            analysis_summary = verification_data.get("analysis_summary", "")
            
            # æ„å»ºå¢å¼ºæç¤ºè¯
            enhancement_prompt = f"""æˆ‘æ˜¯ä¸€ä¸ªæ™ºèƒ½æ¨ç†Agentï¼Œç°åœ¨éœ€è¦åŸºäºæ–°è·å–çš„ä¿¡æ¯æ¥å¢å¼ºæˆ‘çš„æ€ç»´ç§å­ã€‚

**ç”¨æˆ·åŸå§‹æŸ¥è¯¢ï¼š**
{user_query}

**æˆ‘çš„åˆå§‹æ€ç»´ç§å­ï¼š**
{original_seed}

**éªŒè¯åˆ†æç»“æœï¼š**
{analysis_summary if analysis_summary else "æš‚æ— è¯¦ç»†åˆ†æ"}

**å¤šç»´åº¦æœç´¢è·å–çš„æœ€æ–°ä¿¡æ¯ï¼š**
{search_summary}

**ä»»åŠ¡è¦æ±‚ï¼š**
è¯·ä½ ä½œä¸ºAgentï¼Œæ•´åˆä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå¢å¼ºç‰ˆçš„æ€ç»´ç§å­ã€‚å¢å¼ºåçš„æ€ç»´ç§å­åº”è¯¥ï¼š

1. **ä¿ç•™åŸå§‹æ ¸å¿ƒæ€æƒ³** - ä¸è¦å®Œå…¨æŠ›å¼ƒåˆå§‹ç§å­çš„æ ¸å¿ƒè§‚ç‚¹
2. **èå…¥æœ€æ–°ä¿¡æ¯** - å°†æœç´¢ç»“æœä¸­çš„å…³é”®äº‹å®ã€æ¡ˆä¾‹ã€æ•°æ®èå…¥æ€è€ƒ
3. **ä¿®æ­£æ½œåœ¨é”™è¯¯** - å¦‚æœæœç´¢ç»“æœæ˜¾ç¤ºåŸå§‹ç§å­æœ‰è¯¯ï¼Œè¿›è¡Œä¿®æ­£
4. **å¢åŠ æ·±åº¦å’Œå¹¿åº¦** - åŸºäºå¤šç»´åº¦ä¿¡æ¯ï¼Œè®©æ€è€ƒæ›´å…¨é¢
5. **ä¿æŒè¿è´¯æ€§** - ç¡®ä¿å¢å¼ºåçš„å†…å®¹é€»è¾‘è¿è´¯ã€è‡ªç„¶æµç•…

**è¾“å‡ºæ ¼å¼ï¼š**
è¯·ç›´æ¥è¾“å‡ºå¢å¼ºåçš„æ€ç»´ç§å­å†…å®¹ï¼Œä¸è¦æ·»åŠ "å¢å¼ºåçš„æ€ç»´ç§å­ï¼š"ç­‰å‰ç¼€ï¼Œç›´æ¥ä»¥æ€ç»´å†…å®¹å¼€å§‹ã€‚

---
ç°åœ¨ï¼Œè®©æˆ‘æ•´åˆè¿™äº›ä¿¡æ¯ï¼Œç”Ÿæˆå¢å¼ºçš„æ€ç»´ç§å­ï¼š
"""

            # ç›´æ¥è°ƒç”¨LLMè¿›è¡Œæ€ç»´ç§å­å¢å¼ºï¼ˆç»•è¿‡SemanticAnalyzerçš„JSONè§£æï¼‰
            logger.info("ğŸ“ æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œæ€ç»´ç§å­å¢å¼º...")
            logger.info("   ğŸ¤– LLMæ­£åœ¨åˆ†ææœç´¢ç»“æœå¹¶æ•´åˆä¿¡æ¯...")
            logger.info("   â³ é¢„è®¡è€—æ—¶: 3-5ç§’")
            
            # ä½¿ç”¨PriorReasonerçš„LLMç®¡ç†å™¨ç›´æ¥è°ƒç”¨
            if hasattr(self.prior_reasoner, 'llm_manager') and self.prior_reasoner.llm_manager:
                try:
                    enhanced_seed = self.prior_reasoner.llm_manager.call_api(
                        prompt=enhancement_prompt,
                        temperature=0.7,
                        max_tokens=1200
                    )
                    
                    if enhanced_seed and isinstance(enhanced_seed, str) and len(enhanced_seed.strip()) > 20:
                        enhanced_seed = enhanced_seed.strip()
                        logger.info("âœ… LLMå¢å¼ºå®Œæˆï¼")
                        logger.info("")
                        logger.info("ğŸ“Š å¢å¼ºç»Ÿè®¡:")
                        logger.info(f"   ğŸ“ åŸå§‹é•¿åº¦: {len(original_seed)} å­—ç¬¦")
                        logger.info(f"   ğŸ“ å¢å¼ºåé•¿åº¦: {len(enhanced_seed)} å­—ç¬¦")
                        logger.info(f"   ğŸ“ˆ å¢é•¿æ¯”ä¾‹: {len(enhanced_seed) / len(original_seed):.2f}x")
                        logger.info("")
                        logger.info("ğŸ“ å¢å¼ºåç§å­é¢„è§ˆ:")
                        logger.info(f"   {enhanced_seed[:200]}{'...' if len(enhanced_seed) > 200 else ''}")
                        return enhanced_seed
                    else:
                        logger.warning("âš ï¸ LLMè¿”å›çš„å¢å¼ºç§å­æ— æ•ˆï¼Œä½¿ç”¨åŸå§‹ç§å­")
                        logger.info("   (å¯èƒ½åŸå› ï¼šLLMå“åº”æ ¼å¼å¼‚å¸¸æˆ–å†…å®¹è¿‡çŸ­)")
                        return original_seed
                        
                except Exception as e:
                    logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
                    logger.info("   (å›é€€åˆ°åŸå§‹ç§å­)")
                    return original_seed
            else:
                logger.warning("âš ï¸ LLMç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹ç§å­")
                logger.info("   (æ— æ³•è¿›è¡Œæ™ºèƒ½å¢å¼º)")
                return original_seed
                
        except Exception as e:
            logger.error(f"âŒ æ€ç»´ç§å­å¢å¼ºå¤±è´¥: {e}")
            return original_seed
    
    def _build_search_results_summary(self, multidim_results: Dict[str, List[Dict]]) -> str:
        """
        æ„å»ºå¤šç»´åº¦æœç´¢ç»“æœçš„æ‘˜è¦æ–‡æœ¬
        
        Args:
            multidim_results: å¤šç»´åº¦æœç´¢ç»“æœ
            
        Returns:
            str: æœç´¢ç»“æœæ‘˜è¦
        """
        summary_parts = []
        
        if not multidim_results:
            return "æš‚æ— æœç´¢ç»“æœ"
        
        for dimension, results in multidim_results.items():
            if results and len(results) > 0:
                summary_parts.append(f"\nã€{dimension}ã€‘")
                for i, result in enumerate(results[:3], 1):  # æ¯ä¸ªç»´åº¦æœ€å¤š3æ¡
                    title = result.get('title', 'æ— æ ‡é¢˜')
                    snippet = result.get('snippet', 'æ— æ‘˜è¦')
                    # é™åˆ¶é•¿åº¦
                    snippet_short = snippet[:150] + "..." if len(snippet) > 150 else snippet
                    summary_parts.append(f"{i}. {title}")
                    summary_parts.append(f"   {snippet_short}")
        
        if not summary_parts:
            return "æœç´¢ç»“æœä¸ºç©º"
        
        return "\n".join(summary_parts)
    
    def _execute_stage3_path_generation(self, stage1_context: ThinkingSeedContext,
                                      stage2_context: SeedVerificationContext,
                                      execution_context: Optional[Dict]) -> PathGenerationContext:
        """æ‰§è¡Œé˜¶æ®µä¸‰ï¼šæ€ç»´è·¯å¾„ç”Ÿæˆ"""
        context = PathGenerationContext(
            user_query=stage1_context.user_query,
            execution_context=execution_context
        )
        
        try:
            # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨å¢å¼ºåçš„æ€ç»´ç§å­ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            thinking_seed_to_use = stage1_context.thinking_seed
            if hasattr(stage2_context, 'enhanced_thinking_seed') and stage2_context.enhanced_thinking_seed:
                thinking_seed_to_use = stage2_context.enhanced_thinking_seed
                logger.info("âœ… ä½¿ç”¨é˜¶æ®µäºŒå¢å¼ºåçš„æ€ç»´ç§å­ç”Ÿæˆè·¯å¾„")
                logger.info(f"å¢å¼ºç§å­æ‘˜è¦: {thinking_seed_to_use[:100]}...")
            else:
                logger.info("ä½¿ç”¨é˜¶æ®µä¸€åŸå§‹æ€ç»´ç§å­ç”Ÿæˆè·¯å¾„")
            
            # ä½¿ç”¨PathGeneratorç”Ÿæˆå¤šæ ·åŒ–è·¯å¾„
            paths_result = self.path_generator.generate_reasoning_paths(
                thinking_seed=thinking_seed_to_use,
                user_query=stage1_context.user_query,
                max_paths=4,
                execution_context=execution_context
            )
            
            if paths_result and "paths" in paths_result:
                context.generated_paths = paths_result["paths"]
                context.path_count = len(context.generated_paths)
                context.diversity_score = paths_result.get("diversity_score", 0.0)
                context.generation_strategy = "llm_driven_multi_path"
                
                # è®¡ç®—è·¯å¾„è´¨é‡è¯„åˆ†
                for path in context.generated_paths:
                    if hasattr(path, 'path_id') and hasattr(path, 'success_rate'):
                        context.path_quality_scores[path.path_id] = path.success_rate
                
                logger.info(f"   âœ… ç”Ÿæˆ {context.path_count} æ¡æ€ç»´è·¯å¾„")
                logger.info(f"å¤šæ ·æ€§è¯„åˆ†: {context.diversity_score:.3f}")
            else:
                context.add_error("è·¯å¾„ç”Ÿæˆç»“æœä¸ºç©º")
                logger.error("   âŒ è·¯å¾„ç”Ÿæˆå¤±è´¥ï¼šç»“æœä¸ºç©º")
                
        except Exception as e:
            logger.error(f"   âŒ è·¯å¾„ç”Ÿæˆå¼‚å¸¸: {e}")
            context.add_error(f"è·¯å¾„ç”Ÿæˆå¼‚å¸¸: {str(e)}")
        
        return context
    
    def _execute_stage4_path_verification(self, stage3_context: PathGenerationContext,
                                        execution_context: Optional[Dict]) -> PathVerificationContext:
        """
        æ‰§è¡Œé˜¶æ®µå››ï¼šè·¯å¾„ç­–ç•¥éªŒè¯ä¸å³æ—¶å­¦ä¹ ï¼ˆåŸºäºç­–ç•¥çš„æœç´¢éªŒè¯ï¼‰
        
        æ ¸å¿ƒåŠŸèƒ½ï¼š
        1. é’ˆå¯¹æ¯ä¸ªç­–ç•¥ï¼ˆç³»ç»Ÿåˆ†æå‹ã€åˆ›æ–°çªç ´å‹ç­‰ï¼‰ç”Ÿæˆç‰¹å®šçš„æœç´¢æŸ¥è¯¢
        2. æ‰§è¡Œæœç´¢ï¼ŒéªŒè¯è¯¥ç­–ç•¥åœ¨è§£å†³æ­¤é—®é¢˜æ—¶çš„æœ‰æ•ˆæ€§
        3. ä½¿ç”¨LLMè¯„ä¼°æœç´¢ç»“æœå¯¹ç­–ç•¥çš„æ”¯æŒåº¦
        4. ä½¿ç”¨Contextual Banditè¿›è¡Œæ‰“åˆ†å’Œå³æ—¶å­¦ä¹ 
        5. æ›´æ–°MABç³»ç»Ÿçš„ç­–ç•¥æ€§èƒ½ç»Ÿè®¡
        
        ä¸é˜¶æ®µ2çš„åŒºåˆ«ï¼š
        - é˜¶æ®µ2ï¼šéªŒè¯æ€ç»´ç§å­æœ¬èº«çš„å¯è¡Œæ€§
        - é˜¶æ®µ4ï¼šéªŒè¯å…·ä½“ç­–ç•¥ï¼ˆå¦‚"ç³»ç»Ÿåˆ†æå‹"ï¼‰è§£å†³é—®é¢˜çš„æœ‰æ•ˆæ€§
        """
        context = PathVerificationContext(
            user_query=stage3_context.user_query,
            execution_context=execution_context
        )
        
        verification_start_time = time.time()
        
        try:
            # å¡«å……è·¯å¾„ä¿¡æ¯
            context.populate_from_reasoning_paths(stage3_context.generated_paths)
            
            logger.info(f"ğŸ”¬ é˜¶æ®µå››ï¼šç­–ç•¥éªŒè¯ä¸å³æ—¶å­¦ä¹ ")
            logger.info(f"   å¾…éªŒè¯ç­–ç•¥æ•°: {len(stage3_context.generated_paths)}")
            
            # ç»Ÿè®¡å˜é‡
            verified_count = 0
            feasible_count = 0
            total_effectiveness_score = 0.0
            learning_updates_count = 0
            
            # éªŒè¯æ¯ä¸ªç­–ç•¥è·¯å¾„çš„æœ‰æ•ˆæ€§
            for i, path in enumerate(stage3_context.generated_paths, 1):
                if not hasattr(path, 'path_id'):
                    logger.warning(f"âš ï¸ è·¯å¾„ {i} ç¼ºå°‘path_idï¼Œè·³è¿‡")
                    continue
                
                path_type = getattr(path, 'path_type', 'unknown')
                strategy_id = getattr(path, 'strategy_id', path.path_id)
                prompt_template = getattr(path, 'prompt_template', '')
                
                logger.info(f"\n{'='*80}")
                logger.info(f"ğŸ” éªŒè¯ç­–ç•¥ {i}/{len(stage3_context.generated_paths)}: ã€{path_type}ã€‘")
                logger.info(f"{'='*80}")
                
                try:
                    # âœ¨ æ­¥éª¤1ï¼šåŸºäºç­–ç•¥ç±»å‹å’Œæç¤ºè¯ï¼Œç”Ÿæˆé’ˆå¯¹æ€§çš„æœç´¢æŸ¥è¯¢
                    search_queries = self._generate_strategy_specific_search_queries(
                        path=path,
                        user_query=stage3_context.user_query,
                        execution_context=execution_context
                    )
                    
                    if not search_queries:
                        logger.warning(f"âš ï¸ æœªèƒ½ä¸ºç­–ç•¥ {path_type} ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼Œä½¿ç”¨å›é€€è¯„åˆ†")
                        effectiveness_score = 0.5
                        reward_score = 0.1
                        search_results = []
                    else:
                        # âœ¨ æ­¥éª¤2ï¼šæ‰§è¡Œæœç´¢ï¼Œæ”¶é›†è¯¥ç­–ç•¥çš„æ”¯æŒè¯æ®
                        search_results = self._execute_strategy_verification_search(
                            search_queries=search_queries,
                            path_type=path_type
                        )
                        
                        # âœ¨ æ­¥éª¤3ï¼šä½¿ç”¨LLMè¯„ä¼°ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼ˆåŸºäºæœç´¢ç»“æœï¼‰
                        effectiveness_score, evaluation_details = self._evaluate_strategy_effectiveness(
                            path=path,
                            user_query=stage3_context.user_query,
                            search_results=search_results,
                            execution_context=execution_context
                        )
                        
                        # âœ¨ æ­¥éª¤4ï¼šä½¿ç”¨Contextual Banditè®¡ç®—å¥–åŠ±åˆ†æ•°
                        reward_score = self._calculate_contextual_bandit_reward(
                            effectiveness_score=effectiveness_score,
                            path_type=path_type,
                            evaluation_details=evaluation_details
                        )
                        
                        # ğŸ¯ æ˜¾ç¤º Contextual Bandit å¥–åŠ±è®¡ç®—è¯¦æƒ…
                        logger.info("")
                        logger.info("="*80)
                        logger.info("ğŸ¯ Contextual Bandit å¥–åŠ±è®¡ç®—")
                        logger.info("="*80)
                        logger.info(f"ğŸ“Š è¾“å…¥å‚æ•°:")
                        logger.info(f"   â€¢ ç­–ç•¥ç±»å‹: {path_type}")
                        logger.info(f"   â€¢ æœ‰æ•ˆæ€§è¯„åˆ†: {effectiveness_score:.3f}")
                        logger.info(f"   â€¢ è¯„ä¼°æ–¹æ³•: {evaluation_details.get('method', 'unknown')}")
                        logger.info(f"")
                        logger.info(f"ğŸ§® å¥–åŠ±è®¡ç®—è¿‡ç¨‹:")
                        # æ˜¾ç¤ºå¥–åŠ±æ˜ å°„é€»è¾‘
                        if effectiveness_score >= 0.7:
                            base_range = f"[0.3, 0.9]"
                            reward_level = "é«˜æ•ˆç­–ç•¥ - æ­£å¥–åŠ±"
                        elif effectiveness_score >= 0.5:
                            base_range = f"[0.1, 0.3]"
                            reward_level = "ä¸­ç­‰æ•ˆæœ - å°æ­£å¥–åŠ±"
                        elif effectiveness_score >= 0.3:
                            base_range = f"[-0.1, 0.0]"
                            reward_level = "æ•ˆæœä¸ä½³ - å°è´Ÿå¥–åŠ±"
                        else:
                            base_range = f"[-0.3, -0.1]"
                            reward_level = "æ— æ•ˆç­–ç•¥ - è´Ÿå¥–åŠ±"
                        
                        logger.info(f"   â€¢ å¥–åŠ±çº§åˆ«: {reward_level}")
                        logger.info(f"   â€¢ åŸºç¡€å¥–åŠ±èŒƒå›´: {base_range}")
                        logger.info(f"   â€¢ æœ€ç»ˆå¥–åŠ±åˆ†æ•°: {reward_score:.3f}")
                        logger.info("="*80)
                        logger.info("")
                    
                    # âœ¨ æ­¥éª¤5ï¼šå³æ—¶å­¦ä¹  - æ›´æ–°MABç³»ç»Ÿ
                    if hasattr(self, 'mab_converger') and self.mab_converger:
                        try:
                            is_effective = effectiveness_score > 0.5
                            
                            # è·å–æ›´æ–°å‰çš„ MAB ç»Ÿè®¡ä¿¡æ¯
                            mab_stats_before = None
                            if strategy_id in self.mab_converger.path_arms:
                                arm = self.mab_converger.path_arms[strategy_id]
                                mab_stats_before = {
                                    'pulls': arm.total_uses,
                                    'successes': arm.success_count,
                                    'total_reward': arm.total_reward,
                                    'avg_reward': arm.total_reward / arm.total_uses if arm.total_uses > 0 else 0.0
                                }
                            
                            # æ›´æ–°ç­–ç•¥æ€§èƒ½ç»Ÿè®¡
                            self.mab_converger.update_path_performance(
                                path_id=strategy_id,
                                success=is_effective,
                                reward=reward_score,
                                source="strategy_verification"  # æ ‡è®°æ¥æº
                            )
                            learning_updates_count += 1
                            
                            # è·å–æ›´æ–°åçš„ MAB ç»Ÿè®¡ä¿¡æ¯
                            if strategy_id in self.mab_converger.path_arms:
                                arm = self.mab_converger.path_arms[strategy_id]
                                mab_stats_after = {
                                    'pulls': arm.total_uses,
                                    'successes': arm.success_count,
                                    'total_reward': arm.total_reward,
                                    'avg_reward': arm.total_reward / arm.total_uses if arm.total_uses > 0 else 0.0
                                }
                                
                                # æ˜¾ç¤º MAB æ›´æ–°è¯¦æƒ…
                                status = "âœ… æœ‰æ•ˆ" if is_effective else "âŒ æ•ˆæœä¸ä½³"
                                logger.info("")
                                logger.info("="*80)
                                logger.info("ğŸ° Contextual Bandit (MAB) å³æ—¶å­¦ä¹ æ›´æ–°")
                                logger.info("="*80)
                                logger.info(f"ç­–ç•¥éªŒè¯ç»“æœ: {status} - {path_type}")
                                logger.info(f"")
                                logger.info(f"ğŸ“ˆ MAB ç»Ÿè®¡å˜åŒ–:")
                                if mab_stats_before:
                                    logger.info(f"   æ›´æ–°å‰:")
                                    logger.info(f"      â€¢ æ‹‰å–æ¬¡æ•°: {mab_stats_before['pulls']}")
                                    logger.info(f"      â€¢ æˆåŠŸæ¬¡æ•°: {mab_stats_before['successes']}")
                                    logger.info(f"      â€¢ ç´¯è®¡å¥–åŠ±: {mab_stats_before['total_reward']:.3f}")
                                    logger.info(f"      â€¢ å¹³å‡å¥–åŠ±: {mab_stats_before['avg_reward']:.3f}")
                                    logger.info(f"")
                                logger.info(f"   æ›´æ–°å:")
                                logger.info(f"      â€¢ æ‹‰å–æ¬¡æ•°: {mab_stats_after['pulls']} (+1)")
                                logger.info(f"      â€¢ æˆåŠŸæ¬¡æ•°: {mab_stats_after['successes']} ({'+1' if is_effective else '+0'})")
                                logger.info(f"      â€¢ ç´¯è®¡å¥–åŠ±: {mab_stats_after['total_reward']:.3f} ({reward_score:+.3f})")
                                logger.info(f"      â€¢ å¹³å‡å¥–åŠ±: {mab_stats_after['avg_reward']:.3f}")
                                logger.info(f"")
                                logger.info(f"ğŸ’¡ å­¦ä¹ æ•ˆæœ:")
                                logger.info(f"   â€¢ æœ¬æ¬¡åé¦ˆ: {'æˆåŠŸ âœ“' if is_effective else 'å¤±è´¥ âœ—'}")
                                logger.info(f"   â€¢ å¥–åŠ±å€¼: {reward_score:+.3f}")
                                logger.info(f"   â€¢ åé¦ˆæ¥æº: strategy_verification (é˜¶æ®µå››ç­–ç•¥éªŒè¯)")
                                success_rate = mab_stats_after['successes']/mab_stats_after['pulls']*100 if mab_stats_after['pulls'] > 0 else 0.0
                                logger.info(f"   â€¢ æˆåŠŸç‡: {success_rate:.1f}%")
                                logger.info("="*80)
                            else:
                                logger.info(f"{status}: {path_type}")
                                logger.info(f"   â€¢ æœ‰æ•ˆæ€§è¯„åˆ†: {effectiveness_score:.3f}")
                                logger.info(f"   â€¢ å¥–åŠ±åˆ†æ•°: {reward_score:.3f}")
                                logger.info(f"   â€¢ MABå·²æ›´æ–°")
                            
                            if is_effective:
                                feasible_count += 1
                                
                        except Exception as mab_error:
                            logger.warning(f"âš ï¸ MABæ›´æ–°å¤±è´¥: {mab_error}")
                    else:
                        logger.warning("âš ï¸ MABæ”¶æ•›å™¨ä¸å¯ç”¨")
                    
                    # è®°å½•éªŒè¯ç»“æœ
                    verification_result = {
                        "path_id": path.path_id,
                        "feasibility": effectiveness_score,  # ä½¿ç”¨æœ‰æ•ˆæ€§åˆ†æ•°
                        "confidence": effectiveness_score,
                        "verified": True,
                        "path_type": path_type,
                        "description": getattr(path, 'description', ''),
                        "reward_score": reward_score,
                        "search_queries": search_queries,
                        "search_results_count": len(search_results),
                        "is_feasible": effectiveness_score > 0.5,
                        "verification_method": "strategy_based_search"
                    }
                    
                    context.add_verification_result(path.path_id, verification_result)
                    context.verified_paths.append(verification_result)
                    context.verification_confidence[path.path_id] = effectiveness_score
                    context.path_rankings.append((path.path_id, effectiveness_score))
                    
                    # ç¡®ä¿è·¯å¾„ä¿¡æ¯å®Œæ•´
                    if path.path_id not in context.path_types:
                        context.add_path_info(
                            path_id=path.path_id,
                            path_type=path_type,
                            description=getattr(path, 'description', ''),
                            metadata={
                                'strategy_id': strategy_id,
                                'effectiveness_score': effectiveness_score,
                                'reward_score': reward_score,
                                'search_queries_count': len(search_queries),
                                'verification_method': 'strategy_based_search'
                            }
                        )
                    
                    verified_count += 1
                    total_effectiveness_score += effectiveness_score
                    
                except Exception as verification_error:
                    logger.error(f"âŒ ç­–ç•¥éªŒè¯å¤±è´¥: {verification_error}")
                    import traceback
                    logger.debug(traceback.format_exc())
                    
                    # å›é€€ç»“æœ
                    fallback_result = {
                        "path_id": path.path_id,
                        "feasibility": 0.5,
                        "confidence": 0.3,
                        "verified": False,
                        "path_type": path_type,
                        "description": getattr(path, 'description', ''),
                        "reward_score": 0.0,
                        "verification_error": str(verification_error),
                        "is_feasible": False
                    }
                    context.add_verification_result(path.path_id, fallback_result)
                    context.verified_paths.append(fallback_result)
            
            # æ’åºè·¯å¾„ï¼ˆæŒ‰æœ‰æ•ˆæ€§åˆ†æ•°ï¼‰
            context.path_rankings.sort(key=lambda x: x[1], reverse=True)
            
            # ç»Ÿè®¡å’Œè¾“å‡º
            verification_time = time.time() - verification_start_time
            avg_effectiveness = total_effectiveness_score / verified_count if verified_count > 0 else 0.0
            
            logger.info("")
            logger.info(f"âœ… é˜¶æ®µå››å®Œæˆ (è€—æ—¶: {verification_time:.3f}s)")
            logger.info(f"   ğŸ“Š éªŒè¯ç»Ÿè®¡:")
            logger.info(f"      â€¢ æ€»ç­–ç•¥æ•°: {len(stage3_context.generated_paths)}")
            logger.info(f"      â€¢ å·²éªŒè¯: {verified_count}")
            logger.info(f"      â€¢ æœ‰æ•ˆç­–ç•¥: {feasible_count}")
            logger.info(f"      â€¢ ä½æ•ˆç­–ç•¥: {verified_count - feasible_count}")
            logger.info(f"      â€¢ å¹³å‡æœ‰æ•ˆæ€§: {avg_effectiveness:.3f}")
            logger.info(f"      â€¢ MABå­¦ä¹ æ›´æ–°: {learning_updates_count} æ¬¡")
            
            # æ˜¾ç¤º Contextual Bandit æ•´ä½“ç»Ÿè®¡
            if hasattr(self, 'mab_converger') and self.mab_converger:
                logger.info("")
                logger.info("="*80)
                logger.info("ğŸ° Contextual Bandit (MAB) æ•´ä½“å­¦ä¹ çŠ¶å†µ")
                logger.info("="*80)
                try:
                    # ç»Ÿè®¡æ‰€æœ‰ç­–ç•¥çš„ MAB æ•°æ®
                    mab_summary = []
                    for path_id in context.path_types.keys():
                        if path_id in self.mab_converger.path_arms:
                            arm = self.mab_converger.path_arms[path_id]
                            path_type = context.path_types.get(path_id, 'æœªçŸ¥')
                            total_uses = arm.total_uses
                            mab_summary.append({
                                'path_type': path_type,
                                'path_id': path_id,
                                'pulls': total_uses,
                                'successes': arm.success_count,
                                'total_reward': arm.total_reward,
                                'avg_reward': arm.total_reward / total_uses if total_uses > 0 else 0.0,
                                'success_rate': arm.success_count / total_uses if total_uses > 0 else 0.0
                            })
                    
                    if mab_summary:
                        # æŒ‰å¹³å‡å¥–åŠ±æ’åº
                        mab_summary.sort(key=lambda x: x['avg_reward'], reverse=True)
                        
                        logger.info(f"ğŸ“Š ç­–ç•¥å­¦ä¹ è¡¨ç° (æŒ‰å¹³å‡å¥–åŠ±æ’åº):")
                        logger.info("")
                        for i, item in enumerate(mab_summary, 1):
                            logger.info(f"{i}. ã€{item['path_type']}ã€‘")
                            logger.info(f"   â€¢ å°è¯•æ¬¡æ•°: {item['pulls']}")
                            logger.info(f"   â€¢ æˆåŠŸæ¬¡æ•°: {item['successes']}")
                            logger.info(f"   â€¢ æˆåŠŸç‡: {item['success_rate']*100:.1f}%")
                            logger.info(f"   â€¢ ç´¯è®¡å¥–åŠ±: {item['total_reward']:.3f}")
                            logger.info(f"   â€¢ å¹³å‡å¥–åŠ±: {item['avg_reward']:.3f}")
                            logger.info("")
                        
                        logger.info(f"ğŸ’¡ å­¦ä¹ æ´å¯Ÿ:")
                        best_strategy = mab_summary[0]
                        worst_strategy = mab_summary[-1]
                        logger.info(f"   â€¢ æœ€ä½³ç­–ç•¥: {best_strategy['path_type']} (å¹³å‡å¥–åŠ±: {best_strategy['avg_reward']:.3f})")
                        logger.info(f"   â€¢ æœ€å·®ç­–ç•¥: {worst_strategy['path_type']} (å¹³å‡å¥–åŠ±: {worst_strategy['avg_reward']:.3f})")
                        
                        total_pulls = sum(item['pulls'] for item in mab_summary)
                        total_successes = sum(item['successes'] for item in mab_summary)
                        overall_success_rate = total_successes / total_pulls if total_pulls > 0 else 0.0
                        logger.info(f"   â€¢ æ•´ä½“æˆåŠŸç‡: {overall_success_rate*100:.1f}%")
                        logger.info(f"   â€¢ æœ¬è½®å­¦ä¹ æ›´æ–°: {learning_updates_count} æ¬¡")
                        
                    else:
                        logger.info("æš‚æ—  MAB å­¦ä¹ æ•°æ®")
                    
                    logger.info("="*80)
                    
                except Exception as mab_summary_error:
                    logger.warning(f"âš ï¸ ç”Ÿæˆ MAB ç»Ÿè®¡æ‘˜è¦å¤±è´¥: {mab_summary_error}")
            
            logger.info("")
            
            # æ˜¾ç¤ºç­–ç•¥æ’å
            if context.path_rankings:
                logger.info(f"   ğŸ† ç­–ç•¥æœ‰æ•ˆæ€§æ’å:")
                for rank, (path_id, score) in enumerate(context.path_rankings[:3], 1):
                    path_type = context.path_types.get(path_id, 'æœªçŸ¥')
                    logger.info(f"      {rank}. {path_type} (æœ‰æ•ˆæ€§: {score:.3f})")
            
            # è®°å½•æŒ‡æ ‡
            context.add_metric("verified_paths_count", verified_count)
            context.add_metric("feasible_paths_count", feasible_count)
            context.add_metric("average_feasibility_score", avg_effectiveness)
            context.add_metric("mab_learning_updates", learning_updates_count)
            context.add_metric("verification_time", verification_time)
            
            if feasible_count == 0:
                logger.warning("âš ï¸ æ‰€æœ‰ç­–ç•¥éªŒè¯æ•ˆæœä¸ä½³")
                context.add_warning("æ‰€æœ‰ç­–ç•¥æœ‰æ•ˆæ€§è¯„åˆ†åä½")
                
        except Exception as e:
            logger.error(f"âŒ ç­–ç•¥éªŒè¯å¼‚å¸¸: {e}")
            import traceback
            logger.error(traceback.format_exc())
            context.add_error(f"ç­–ç•¥éªŒè¯å¼‚å¸¸: {str(e)}")
        
        return context
    
    def _generate_strategy_specific_search_queries(self, path, user_query: str, 
                                                   execution_context: Optional[Dict]) -> List[str]:
        """
        åŸºäºç­–ç•¥ç±»å‹å’Œæç¤ºè¯ï¼Œç”Ÿæˆé’ˆå¯¹æ€§çš„æœç´¢æŸ¥è¯¢
        
        Args:
            path: ReasoningPathå¯¹è±¡ï¼ŒåŒ…å«ç­–ç•¥ä¿¡æ¯
            user_query: ç”¨æˆ·åŸå§‹é—®é¢˜
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            List[str]: æœç´¢æŸ¥è¯¢åˆ—è¡¨ï¼ˆ1-3ä¸ªï¼‰
        """
        try:
            path_type = getattr(path, 'path_type', 'unknown')
            prompt_template = getattr(path, 'prompt_template', '')
            description = getattr(path, 'description', '')
            
            logger.info(f"ğŸ” ä¸ºç­–ç•¥ã€{path_type}ã€‘ç”Ÿæˆæœç´¢æŸ¥è¯¢...")
            
            # è·å–å½“å‰æ—¶é—´
            from datetime import datetime
            current_year = datetime.now().year
            
            # æ„å»ºLLMæç¤ºè¯
            planning_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæœç´¢æŸ¥è¯¢ä¸“å®¶ã€‚ç°åœ¨éœ€è¦éªŒè¯ä¸€ä¸ªé—®é¢˜è§£å†³ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

ğŸ“‹ **ä»»åŠ¡èƒŒæ™¯**:
- ç”¨æˆ·é—®é¢˜: {user_query}
- ç­–ç•¥ç±»å‹: {path_type}
- ç­–ç•¥æè¿°: {description}
- ç­–ç•¥æç¤ºè¯: {prompt_template[:200]}...

ğŸ¯ **ä½ çš„ä»»åŠ¡**:
åŸºäºè¿™ä¸ªç­–ç•¥ç±»å‹ï¼Œç”Ÿæˆ2-3ä¸ªæœç´¢æŸ¥è¯¢ï¼Œç”¨äºéªŒè¯è¯¥ç­–ç•¥åœ¨è§£å†³æ­¤ç±»é—®é¢˜æ—¶çš„æœ‰æ•ˆæ€§ã€‚

**æœç´¢æŸ¥è¯¢åº”è¯¥å…³æ³¨**:
1. è¯¥ç­–ç•¥åœ¨ç±»ä¼¼é—®é¢˜ä¸­çš„æˆåŠŸæ¡ˆä¾‹
2. è¯¥ç­–ç•¥çš„æ–¹æ³•è®ºå’Œæœ€ä½³å®è·µ
3. ä¸“å®¶å¯¹è¯¥ç­–ç•¥çš„è¯„ä»·å’Œå»ºè®®

**é‡è¦**:
- æŸ¥è¯¢è¦å…·ä½“ã€å¯æ‰§è¡Œ
- å¦‚æœæ¶‰åŠæ—¶é—´ï¼Œä½¿ç”¨{current_year}å¹´
- æ¯ä¸ªæŸ¥è¯¢ä¸€è¡Œï¼Œä¸è¦ç¼–å·

è¯·ç›´æ¥è¾“å‡ºæœç´¢æŸ¥è¯¢ï¼ˆä¸€è¡Œä¸€ä¸ªï¼‰ï¼Œä¸è¦å…¶ä»–è§£é‡Šï¼š"""
            
            # è°ƒç”¨LLMç”ŸæˆæŸ¥è¯¢
            if not hasattr(self, 'llm_manager') or not self.llm_manager:
                logger.warning("âš ï¸ LLMç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨å¯å‘å¼æ–¹æ³•ç”ŸæˆæŸ¥è¯¢")
                return self._generate_fallback_search_queries(path_type, user_query, current_year)
            
            logger.debug("ğŸ¤– è°ƒç”¨LLMç”Ÿæˆæœç´¢æŸ¥è¯¢...")
            
            # ä½¿ç”¨LLMç”Ÿæˆ
            response = self.llm_manager.call_api(
                prompt=planning_prompt,
                temperature=0.7,
                max_tokens=300
            )
            
            # æå–å“åº”å†…å®¹
            content = ""
            if isinstance(response, dict) and 'content' in response:
                content = response['content']
            elif isinstance(response, str):
                content = response
            elif hasattr(response, 'content'):
                content = response.content
            
            if not content:
                logger.warning("âš ï¸ LLMæœªè¿”å›æœ‰æ•ˆå†…å®¹ï¼Œä½¿ç”¨å›é€€æ–¹æ³•")
                return self._generate_fallback_search_queries(path_type, user_query, current_year)
            
            # è§£ææŸ¥è¯¢ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰
            queries = []
            for line in content.strip().split('\n'):
                line = line.strip()
                # ç§»é™¤å¯èƒ½çš„ç¼–å·
                line = line.lstrip('0123456789.-:ï¼šã€ï¼‰) ')
                if line and len(line) > 10:
                    queries.append(line)
            
            # é™åˆ¶æ•°é‡
            queries = queries[:3]
            
            if queries:
                logger.info(f"âœ… ç”Ÿæˆäº† {len(queries)} ä¸ªæœç´¢æŸ¥è¯¢:")
                for i, q in enumerate(queries, 1):
                    logger.info(f"   {i}. {q}")
                return queries
            else:
                logger.warning("âš ï¸ æœªèƒ½ä»LLMå“åº”ä¸­æå–æŸ¥è¯¢ï¼Œä½¿ç”¨å›é€€æ–¹æ³•")
                return self._generate_fallback_search_queries(path_type, user_query, current_year)
                
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæœç´¢æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            # ä½¿ç”¨å›é€€æ–¹æ³•
            from datetime import datetime
            return self._generate_fallback_search_queries(
                getattr(path, 'path_type', 'unknown'), 
                user_query, 
                datetime.now().year
            )
    
    def _generate_fallback_search_queries(self, path_type: str, user_query: str, 
                                         current_year: int) -> List[str]:
        """å¯å‘å¼ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼ˆå½“LLMä¸å¯ç”¨æ—¶ï¼‰"""
        queries = []
        
        # æ ¹æ®ç­–ç•¥ç±»å‹è°ƒæ•´å…³é”®è¯
        strategy_keywords = {
            "ç³»ç»Ÿåˆ†æå‹": "ç³»ç»Ÿåˆ†ææ–¹æ³•",
            "åˆ›æ–°çªç ´å‹": "åˆ›æ–°æ€ç»´æ–¹æ³•",
            "æ‰¹åˆ¤è´¨ç–‘å‹": "æ‰¹åˆ¤æ€§æ€ç»´",
            "å®ç”¨ç›´æ¥å‹": "å®ç”¨è§£å†³æ–¹æ¡ˆ",
            "å¹³è¡¡ç»¼åˆå‹": "ç»¼åˆåˆ†ææ–¹æ³•"
        }
        
        keyword = strategy_keywords.get(path_type, "é—®é¢˜è§£å†³æ–¹æ³•")
        
        # ç”ŸæˆåŸºç¡€æŸ¥è¯¢
        queries.append(f"{user_query[:40]} {keyword} {current_year}")
        queries.append(f"{keyword} æˆåŠŸæ¡ˆä¾‹ æœ€ä½³å®è·µ")
        
        return queries[:3]
    
    def _execute_strategy_verification_search(self, search_queries: List[str], 
                                             path_type: str) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œç­–ç•¥éªŒè¯æœç´¢
        
        Args:
            search_queries: æœç´¢æŸ¥è¯¢åˆ—è¡¨
            path_type: ç­–ç•¥ç±»å‹
            
        Returns:
            List[Dict]: æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            all_results = []
            
            logger.info(f"\nğŸ” æ‰§è¡Œç­–ç•¥éªŒè¯æœç´¢ ({len(search_queries)} ä¸ªæŸ¥è¯¢)...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœç´¢å·¥å…·
            if not hasattr(self, 'tool_registry') or not self.tool_registry:
                logger.warning("âš ï¸ å·¥å…·æ³¨å†Œè¡¨ä¸å¯ç”¨")
                return []
            
            if not self.tool_registry.has_tool("web_search"):
                logger.warning("âš ï¸ web_searchå·¥å…·ä¸å¯ç”¨")
                return []
            
            # æ‰§è¡Œæ¯ä¸ªæŸ¥è¯¢
            for i, query in enumerate(search_queries, 1):
                try:
                    print(f"\n{'â”€'*80}")
                    print(f"ğŸ” æœç´¢æŸ¥è¯¢ {i}/{len(search_queries)}: {query}")
                    print(f"{'â”€'*80}")
                    
                    # è°ƒç”¨æœç´¢å·¥å…·
                    search_result = self.tool_registry.execute_tool(
                        name="web_search",
                        query=query
                    )
                    
                    if search_result and search_result.success:
                        result_data = search_result.data
                        
                        # æå–ç»“æœ
                        if isinstance(result_data, dict) and 'results' in result_data:
                            results_list = result_data['results']
                            print(f"âœ… æ‰¾åˆ° {len(results_list)} æ¡ç»“æœ")
                            
                            # æ˜¾ç¤ºå‰2æ¡
                            for j, item in enumerate(results_list[:2], 1):
                                if isinstance(item, dict):
                                    title = item.get('title', 'æ— æ ‡é¢˜')
                                    url = item.get('url', '')
                                    print(f"  {j}. ğŸ“„ {title[:60]}")
                                    print(f"     ğŸ”— {url[:70]}")
                            
                            all_results.extend(results_list)
                        else:
                            print(f"âš ï¸  æœç´¢ç»“æœæ ¼å¼æœªçŸ¥")
                    else:
                        error_msg = search_result.error_message if search_result else "æœªçŸ¥é”™è¯¯"
                        print(f"âŒ æœç´¢å¤±è´¥: {error_msg}")
                        
                except Exception as search_error:
                    print(f"âŒ æœç´¢å¼‚å¸¸: {str(search_error)}")
                    logger.error(f"æœç´¢å¼‚å¸¸: {search_error}")
                    continue
            
            print(f"\n{'='*80}")
            print(f"âœ… ç­–ç•¥éªŒè¯æœç´¢å®Œæˆ: å…±è·å¾— {len(all_results)} æ¡ç»“æœ")
            print(f"{'='*80}\n")
            
            logger.info(f"âœ… æœç´¢å®Œæˆï¼Œå…± {len(all_results)} æ¡ç»“æœ")
            return all_results
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œæœç´¢å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return []
    
    def _evaluate_strategy_effectiveness(self, path, user_query: str, 
                                        search_results: List[Dict[str, Any]],
                                        execution_context: Optional[Dict]) -> Tuple[float, Dict[str, Any]]:
        """
        ä½¿ç”¨LLMè¯„ä¼°ç­–ç•¥çš„æœ‰æ•ˆæ€§
        
        Args:
            path: ReasoningPathå¯¹è±¡
            user_query: ç”¨æˆ·é—®é¢˜
            search_results: æœç´¢ç»“æœ
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            Tuple[float, Dict]: (æœ‰æ•ˆæ€§åˆ†æ•°, è¯„ä¼°è¯¦æƒ…)
        """
        try:
            path_type = getattr(path, 'path_type', 'unknown')
            prompt_template = getattr(path, 'prompt_template', '')
            
            logger.info(f"ğŸ¤– ä½¿ç”¨LLMè¯„ä¼°ç­–ç•¥æœ‰æ•ˆæ€§...")
            
            # å¦‚æœæ²¡æœ‰æœç´¢ç»“æœï¼Œç»™åŸºç¡€åˆ†æ•°
            if not search_results:
                logger.warning("âš ï¸ æ— æœç´¢ç»“æœï¼Œä½¿ç”¨åŸºç¡€è¯„åˆ†")
                return 0.5, {"reason": "no_search_results"}
            
            # æ„å»ºæœç´¢ç»“æœæ‘˜è¦
            results_summary = self._build_search_results_summary_for_llm(search_results[:5])
            
            # æ„å»ºLLMè¯„ä¼°æç¤ºè¯
            evaluation_prompt = f"""ä½ æ˜¯ä¸€ä¸ªç­–ç•¥æœ‰æ•ˆæ€§è¯„ä¼°ä¸“å®¶ã€‚

**ç”¨æˆ·é—®é¢˜**: {user_query}

**å¾…è¯„ä¼°ç­–ç•¥**: {path_type}
- ç­–ç•¥æè¿°: {getattr(path, 'description', '')}
- ç­–ç•¥æ–¹æ³•: {prompt_template[:150]}

**æœç´¢åˆ°çš„è¯æ®**:
{results_summary}

**è¯„ä¼°ä»»åŠ¡**:
åŸºäºæœç´¢åˆ°çš„è¯æ®ï¼Œè¯„ä¼°è¯¥ç­–ç•¥è§£å†³æ­¤é—®é¢˜çš„æœ‰æ•ˆæ€§ã€‚

**è¯„ä¼°æ ‡å‡†**:
1. è¯¥ç­–ç•¥æ˜¯å¦æœ‰æˆåŠŸæ¡ˆä¾‹æ”¯æŒ
2. è¯¥ç­–ç•¥æ˜¯å¦é€‚ç”¨äºæ­¤ç±»é—®é¢˜
3. æœç´¢ç»“æœæ˜¯å¦éªŒè¯äº†ç­–ç•¥çš„å¯è¡Œæ€§
4. æ˜¯å¦æœ‰ä¸“å®¶æ¨èæˆ–æœ€ä½³å®è·µæ”¯æŒ

**è¾“å‡ºæ ¼å¼**:
æœ‰æ•ˆæ€§è¯„åˆ†: [0.0-1.0ä¹‹é—´çš„æ•°å­—]
è¯„ä¼°ç†ç”±: [ä¸€å¥è¯è¯´æ˜ç†ç”±]

è¯·ç›´æ¥è¾“å‡ºè¯„åˆ†å’Œç†ç”±ï¼š"""
            
            # è°ƒç”¨LLM
            if not hasattr(self, 'llm_manager') or not self.llm_manager:
                logger.warning("âš ï¸ LLMç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨å¯å‘å¼è¯„åˆ†")
                return self._calculate_heuristic_effectiveness(search_results), {"method": "heuristic"}
            
            print("\n" + "="*80)
            print("ğŸ¤– LLMç­–ç•¥æœ‰æ•ˆæ€§è¯„ä¼°:")
            print("="*80)
            
            response = self.llm_manager.call_api(
                prompt=evaluation_prompt,
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ï¼Œæ›´å®¢è§‚
                max_tokens=500
            )
            
            # æå–å“åº”å†…å®¹
            content = ""
            if isinstance(response, dict) and 'content' in response:
                content = response['content']
            elif isinstance(response, str):
                content = response
            elif hasattr(response, 'content'):
                content = response.content
            
            if not content:
                logger.warning("âš ï¸ LLMæœªè¿”å›æœ‰æ•ˆå†…å®¹")
                return self._calculate_heuristic_effectiveness(search_results), {"method": "fallback"}
            
            print(content)
            print("="*80 + "\n")
            
            # è§£æè¯„åˆ†
            import re
            score_match = re.search(r'(?:æœ‰æ•ˆæ€§è¯„åˆ†|è¯„åˆ†)[:ï¼š\s]*([0-9.]+)', content)
            if score_match:
                score = float(score_match.group(1))
                score = max(0.0, min(1.0, score))  # é™åˆ¶åœ¨0-1èŒƒå›´
                logger.info(f"âœ… LLMè¯„ä¼°åˆ†æ•°: {score:.3f}")
                
                # æå–ç†ç”±
                reason_match = re.search(r'(?:è¯„ä¼°ç†ç”±|ç†ç”±)[:ï¼š\s]*(.+?)(?:\n|$)', content)
                reason = reason_match.group(1).strip() if reason_match else content[:100]
                
                return score, {
                    "method": "llm_evaluation",
                    "reason": reason,
                    "full_response": content
                }
            else:
                logger.warning("âš ï¸ æ— æ³•ä»LLMå“åº”ä¸­æå–è¯„åˆ†")
                return self._calculate_heuristic_effectiveness(search_results), {
                    "method": "parse_failed",
                    "llm_response": content
                }
                
        except Exception as e:
            logger.error(f"âŒ ç­–ç•¥æœ‰æ•ˆæ€§è¯„ä¼°å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return 0.5, {"method": "error", "error": str(e)}
    
    def _build_search_results_summary_for_llm(self, results: List[Dict[str, Any]]) -> str:
        """æ„å»ºæœç´¢ç»“æœæ‘˜è¦ä¾›LLMè¯„ä¼°"""
        if not results:
            return "ï¼ˆæ— æœç´¢ç»“æœï¼‰"
        
        summary_lines = []
        for i, result in enumerate(results[:5], 1):
            title = result.get('title', 'æ— æ ‡é¢˜')
            snippet = result.get('snippet', result.get('content', ''))[:150]
            summary_lines.append(f"{i}. {title}\n   æ‘˜è¦: {snippet}")
        
        return "\n\n".join(summary_lines)
    
    def _calculate_heuristic_effectiveness(self, search_results: List[Dict[str, Any]]) -> float:
        """å¯å‘å¼è®¡ç®—æœ‰æ•ˆæ€§åˆ†æ•°ï¼ˆå½“LLMä¸å¯ç”¨æ—¶ï¼‰"""
        if not search_results:
            return 0.3
        
        # åŸºäºç»“æœæ•°é‡çš„ç®€å•è¯„åˆ†
        result_count = len(search_results)
        if result_count >= 5:
            return 0.7
        elif result_count >= 3:
            return 0.6
        elif result_count >= 1:
            return 0.5
        else:
            return 0.3
    
    def _calculate_contextual_bandit_reward(self, effectiveness_score: float,
                                           path_type: str,
                                           evaluation_details: Dict[str, Any]) -> float:
        """
        ä½¿ç”¨Contextual Banditæœºåˆ¶è®¡ç®—å¥–åŠ±åˆ†æ•°
        
        Args:
            effectiveness_score: ç­–ç•¥æœ‰æ•ˆæ€§åˆ†æ•° (0.0-1.0)
            path_type: ç­–ç•¥ç±»å‹
            evaluation_details: è¯„ä¼°è¯¦æƒ…
            
        Returns:
            float: å¥–åŠ±åˆ†æ•° (-1.0 åˆ° 1.0)
        """
        try:
            # ğŸ¯ Contextual Banditæ ¸å¿ƒï¼šåŸºäºä¸Šä¸‹æ–‡è°ƒæ•´å¥–åŠ±
            
            # åŸºç¡€å¥–åŠ±ï¼šä»æœ‰æ•ˆæ€§åˆ†æ•°æ˜ å°„åˆ°å¥–åŠ±å€¼
            if effectiveness_score >= 0.7:
                # é«˜æ•ˆç­–ç•¥ï¼šæ­£å¥–åŠ±
                base_reward = 0.3 + (effectiveness_score - 0.7) * 2.0  # 0.3-0.9
            elif effectiveness_score >= 0.5:
                # ä¸­ç­‰æ•ˆæœï¼šå°æ­£å¥–åŠ±
                base_reward = 0.1 + (effectiveness_score - 0.5) * 1.0  # 0.1-0.3
            elif effectiveness_score >= 0.3:
                # æ•ˆæœä¸ä½³ï¼šå°è´Ÿå¥–åŠ±
                base_reward = -0.1 + (effectiveness_score - 0.3) * 0.5  # -0.1-0.0
            else:
                # æ— æ•ˆç­–ç•¥ï¼šè´Ÿå¥–åŠ±
                base_reward = -0.3 + effectiveness_score * 0.67  # -0.3åˆ°-0.1
            
            # ğŸ¯ ä¸Šä¸‹æ–‡è°ƒæ•´ï¼šæ ¹æ®è¯„ä¼°æ–¹æ³•è°ƒæ•´æƒé‡
            method = evaluation_details.get('method', 'unknown')
            if method == 'llm_evaluation':
                # LLMè¯„ä¼°æ›´å¯ä¿¡ï¼Œä¿æŒåŸå¥–åŠ±
                context_adjustment = 0.0
            elif method == 'heuristic':
                # å¯å‘å¼è¯„ä¼°ä¸å¤ªå¯ä¿¡ï¼Œé™ä½å¥–åŠ±å¹…åº¦
                context_adjustment = -0.1
            else:
                # å…¶ä»–æƒ…å†µï¼Œè½»å¾®é™ä½
                context_adjustment = -0.05
            
            # æœ€ç»ˆå¥–åŠ±
            final_reward = base_reward + context_adjustment
            final_reward = max(-1.0, min(1.0, final_reward))
            
            # ç¡®ä¿ä¸ä¸ºé›¶ï¼ˆMABå­¦ä¹ éœ€è¦ï¼‰
            if final_reward == 0.0:
                final_reward = 0.05 if effectiveness_score >= 0.5 else -0.05
            
            logger.debug(f"å¥–åŠ±è®¡ç®—: æœ‰æ•ˆæ€§={effectiveness_score:.3f}, åŸºç¡€={base_reward:.3f}, è°ƒæ•´={context_adjustment:.3f}, æœ€ç»ˆ={final_reward:.3f}")
            
            return final_reward
            
        except Exception as e:
            logger.warning(f"âš ï¸ å¥–åŠ±è®¡ç®—å¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•æ˜ å°„
            return 0.1 if effectiveness_score >= 0.5 else -0.1
    
    def _execute_stage5_mab_decision(self, stage4_context: PathVerificationContext,
                                   execution_context: Optional[Dict]) -> MABDecisionContext:
        """æ‰§è¡Œé˜¶æ®µäº”ï¼šMABæœ€ç»ˆå†³ç­– - çœŸæ­£ä½¿ç”¨MABConvergerç®—æ³•"""
        context = MABDecisionContext(
            user_query=stage4_context.user_query,
            execution_context=execution_context
        )
        
        try:
            # ä½¿ç”¨çœŸæ­£çš„MABConvergerè¿›è¡Œå†³ç­–
            if hasattr(self, 'mab_converger') and self.mab_converger:
                logger.info("ä½¿ç”¨çœŸæ­£çš„MABConvergerè¿›è¡Œç¬¬äº”é˜¶æ®µå†³ç­–")
                
                # ä»stage4_contextä¸­é‡å»ºReasoningPathå¯¹è±¡ï¼ˆç¡®ä¿å¿…éœ€å­—æ®µå®Œæ•´ï¼‰
                reasoning_paths = []
                for path_id, score in stage4_context.path_rankings:
                    # åˆ›å»ºReasoningPathå¯¹è±¡
                    try:
                        from neogenesis_system.cognitive_engine.data_structures import ReasoningPath
                        path_type = stage4_context.path_types.get(path_id, "å®ç”¨åŠ¡å®å‹")
                        description = stage4_context.path_descriptions.get(path_id, f"åŸºäº{path_type}çš„æ€ç»´è·¯å¾„")
                        confidence = stage4_context.verification_confidence.get(path_id, score)
                        prompt_template = f"é‡‡ç”¨{path_type}çš„æ–¹æ³•æ¥åˆ†æå’Œè§£å†³é—®é¢˜ã€‚{description}"
                        reasoning_path = ReasoningPath(
                            path_id=path_id,
                            path_type=path_type,
                            description=description,
                            prompt_template=prompt_template,
                            strategy_id=path_id,
                            instance_id=f"stage5_{path_id}_{int(time.time())}"
                        )
                        # å°†ç½®ä¿¡åº¦å†™å…¥å±æ€§ï¼ˆéæ„é€ å‚æ•°ï¼‰
                        reasoning_path.confidence_score = confidence
                        reasoning_paths.append(reasoning_path)
                    except Exception:
                        # é™çº§ä¸ºç®€å•å¯¹è±¡ï¼ˆç»´æŒå±æ€§è®¿é—®è¯­ä¹‰ï¼‰
                        confidence = stage4_context.verification_confidence.get(path_id, score)
                        simple_path = type('SimpleReasoningPath', (), {
                            'path_id': path_id,
                            'path_type': stage4_context.path_types.get(path_id, "å®ç”¨åŠ¡å®å‹"),
                            'description': stage4_context.path_descriptions.get(path_id, "åŸºç¡€æ€ç»´è·¯å¾„"),
                            'prompt_template': f"é‡‡ç”¨{stage4_context.path_types.get(path_id, 'å®ç”¨åŠ¡å®å‹')}æ–¹æ³•åˆ†æé—®é¢˜",
                            'confidence_score': confidence,
                            'strategy_id': path_id,
                            'instance_id': f"stage5_{path_id}_{int(time.time())}"
                        })()
                        reasoning_paths.append(simple_path)
                
                if reasoning_paths:
                    # è°ƒç”¨çœŸæ­£çš„MABç®—æ³•
                    selected_path = self.mab_converger.select_best_path(
                        paths=reasoning_paths,
                        algorithm='auto'  # è®©MABè‡ªåŠ¨é€‰æ‹©æœ€ä½³ç®—æ³•
                    )
                    
                    # è·å–MABç»Ÿè®¡ä¿¡æ¯
                    mab_stats = {
                        "total_selections": getattr(self.mab_converger, 'total_path_selections', 0),
                        "algorithm_used": getattr(self.mab_converger, '_last_algorithm_used', 'thompson_sampling'),
                        "exploration_rate": 0.15,  # é»˜è®¤å€¼
                        "convergence_level": 0.5   # é»˜è®¤å€¼
                    }
                    
                    # è®¾ç½®ä¸Šä¸‹æ–‡ç»“æœï¼ˆä¿æŒå¯¹è±¡è¯­ä¹‰ï¼Œé¿å…ä¸‹æ¸¸.dictè®¿é—®é”™è¯¯ï¼‰
                    context.selected_path = selected_path
                    context.selection_confidence = getattr(selected_path, 'confidence_score', 0.5)
                    context.selection_algorithm = mab_stats["algorithm_used"]
                    context.decision_reasoning = f"MABç®—æ³•({mab_stats['algorithm_used']})é€‰æ‹©æœ€ä¼˜è·¯å¾„: {getattr(context.selected_path, 'path_id', 'unknown')}"
                    context.mab_statistics = mab_stats
                    
                    # è®°å½•å¤‡é€‰é€‰æ‹©
                    for path in reasoning_paths[1:3]:  # è®°å½•å‰2ä¸ªå¤‡é€‰
                        alt_info = {
                            "path_id": getattr(path, 'path_id', 'unknown'),
                            "confidence": getattr(path, 'confidence_score', 0.5)
                        }
                        context.alternative_choices.append((alt_info, getattr(path, 'confidence_score', 0.5)))
                    
                    logger.info(f"MABç®—æ³•é€‰æ‹©: {getattr(context.selected_path, 'path_id', 'unknown')} (ç®—æ³•: {context.selection_algorithm})")
                    logger.info(f"é€‰æ‹©ç½®ä¿¡åº¦: {context.selection_confidence:.3f}")
                    
                else:
                    context.add_error("æ— æ³•åˆ›å»ºReasoningPathå¯¹è±¡")
                    logger.error("   âŒ MABå†³ç­–å¤±è´¥ï¼šæ— æ³•åˆ›å»ºè·¯å¾„å¯¹è±¡")
            else:
                # å›é€€åˆ°ç®€å•é€‰æ‹©é€»è¾‘
                logger.warning("âš ï¸ MABConvergerä¸å¯ç”¨ï¼Œä½¿ç”¨å›é€€å†³ç­–é€»è¾‘")
                available = []
                for path_id, score in stage4_context.path_rankings:
                    confidence = stage4_context.verification_confidence.get(path_id, 0.5)
                    available.append((path_id, score, confidence))
                
                if available:
                    best_path_id, best_score, best_conf = max(available, key=lambda x: x[1])
                    # æ„é€ ä¸€ä¸ªç®€å•çš„å¯¹è±¡ï¼Œä¿æŒå±æ€§è®¿é—®è¯­ä¹‰
                    simple_selected = type('SelectedPath', (), {
                        'path_id': best_path_id,
                        'path_type': stage4_context.path_types.get(best_path_id, 'unknown'),
                        'description': stage4_context.path_descriptions.get(best_path_id, ''),
                        'confidence_score': best_conf
                    })()
                    context.selected_path = simple_selected
                    context.selection_confidence = best_conf
                    context.selection_algorithm = "fallback_max_score"
                    context.decision_reasoning = f"å›é€€é€»è¾‘é€‰æ‹©æœ€é«˜è¯„åˆ†è·¯å¾„: {best_path_id}"
                    
                    logger.info(f"   âœ… å›é€€é€‰æ‹©è·¯å¾„: {best_path_id}")
                    logger.info(f"é€‰æ‹©ç½®ä¿¡åº¦: {context.selection_confidence:.3f}")
                else:
                    context.add_error("æ²¡æœ‰å¯ç”¨è·¯å¾„è¿›è¡Œå†³ç­–")
                    logger.error("   âŒ å†³ç­–å¤±è´¥ï¼šæ— å¯ç”¨è·¯å¾„")
                
        except Exception as e:
            logger.error(f"   âŒ ç¬¬äº”é˜¶æ®µMABå†³ç­–å¼‚å¸¸: {e}")
            context.add_error(f"MABå†³ç­–å¼‚å¸¸: {str(e)}")
        
        return context
    
    def _create_fallback_decision(self, strategy_decision: StrategyDecision, error_message: str) -> StrategyDecision:
        """åˆ›å»ºå›é€€å†³ç­–"""
        strategy_decision.add_error(error_message)
        strategy_decision.confidence_score = 0.1
        strategy_decision.final_reasoning = f"å†³ç­–è¿‡ç¨‹å¤±è´¥ï¼Œä½¿ç”¨å›é€€ç­–ç•¥: {error_message}"
        
        # åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„å›é€€è·¯å¾„
        fallback_path = {
            "path_id": "fallback_direct_response",
            "path_type": "ç›´æ¥å›ç­”",
            "description": "å›é€€åˆ°ç›´æ¥å›ç­”æ¨¡å¼"
        }
        strategy_decision.chosen_path = fallback_path
        
        return strategy_decision
    
    def _validate_mab_converger_initialization(self):
        """å¢å¼ºç‰ˆï¼šéªŒè¯MABConvergerçš„åˆå§‹åŒ–çŠ¶æ€"""
        if not self.mab_converger:
            logger.error("âŒ MABConvergeræœªåˆå§‹åŒ–")
            raise ValueError("MABConvergerä¸èƒ½ä¸ºNone")
        
        # ä¿®å¤ï¼šæ£€æŸ¥å¿…è¦çš„æ–¹æ³•ï¼ˆåŒ…å«å…¼å®¹æ€§æ–¹æ³•ï¼‰
        required_methods = ['select_best_path', 'get_path_statistics']
        optional_methods = ['update_path_feedback', 'update_path_performance']  # ä¸¤ä¸ªéƒ½æ”¯æŒ
        missing_methods = []
        
        for method_name in required_methods:
            if not hasattr(self.mab_converger, method_name):
                missing_methods.append(method_name)
        
        # æ£€æŸ¥å¯é€‰æ–¹æ³•ï¼ˆè‡³å°‘è¦æœ‰ä¸€ä¸ªï¼‰
        has_feedback_method = any(
            hasattr(self.mab_converger, method) for method in optional_methods
        )
        
        if not has_feedback_method:
            missing_methods.extend(optional_methods)
        
        if missing_methods:
            logger.warning(f"âš ï¸ MABConvergerç¼ºå°‘æ–¹æ³•: {missing_methods}")
            # æ–°å¢ï¼šæä¾›ä¿®å¤å»ºè®®
            if 'update_path_feedback' in missing_methods:
                logger.info("ğŸ’¡ å»ºè®®ï¼šå·²æ·»åŠ update_path_feedbackæ–¹æ³•ä½œä¸ºupdate_path_performanceçš„åˆ«å")
        else:
            logger.info("âœ… MABConvergeræ–¹æ³•éªŒè¯é€šè¿‡")
        
        # æ£€æŸ¥åŸºæœ¬å±æ€§
        required_attrs = ['path_arms', 'total_path_selections']
        missing_attrs = []
        
        for attr_name in required_attrs:
            if not hasattr(self.mab_converger, attr_name):
                missing_attrs.append(attr_name)
        
        if missing_attrs:
            logger.warning(f"âš ï¸ MABConvergerç¼ºå°‘å±æ€§: {missing_attrs}")
        else:
            logger.info("âœ… MABConvergerå±æ€§éªŒè¯é€šè¿‡")
        
        # åˆå§‹åŒ–æ£€æŸ¥é€šè¿‡
        logger.info("âœ… MABConvergeråˆå§‹åŒ–éªŒè¯é€šè¿‡")
        
        # å¢å¼ºç‰ˆï¼šå®‰å…¨åœ°è®°å½•MABçŠ¶æ€
        try:
            total_selections = getattr(self.mab_converger, 'total_path_selections', 0)
            path_arms_count = len(getattr(self.mab_converger, 'path_arms', {}))
            tool_arms_count = len(getattr(self.mab_converger, 'tool_arms', {}))
            
            logger.info(f"MABçŠ¶æ€: {total_selections}æ¬¡é€‰æ‹©, {path_arms_count}ä¸ªå†³ç­–è‡‚")
            if tool_arms_count > 0:
                logger.debug(f"å·¥å…·å†³ç­–è‡‚: {tool_arms_count}ä¸ª")
                
        except Exception as e:
            logger.debug(f"   âš ï¸ æ— æ³•è·å–MABè¯¦ç»†çŠ¶æ€: {e}")
            logger.debug("   MABç»„ä»¶å¯èƒ½ä¸å®Œæ•´ï¼Œä½†ç³»ç»Ÿå°†ç»§ç»­è¿è¡Œ")
    
    def _generate_answer_from_context(self, query: str, strategy_decision: 'StrategyDecision', 
                                     context: Optional[Dict[str, Any]] = None) -> str:
        """
        åŸºäºäº”é˜¶æ®µä¸Šä¸‹æ–‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        
        è¿™ä¸ªæ–¹æ³•æ•´åˆå‰å››é˜¶æ®µçš„æ‰€æœ‰ä¿¡æ¯ï¼š
        - é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­ï¼ˆthinking_seedï¼‰
        - é˜¶æ®µäºŒï¼šç§å­éªŒè¯ç»“æœï¼ˆæœç´¢ä¿¡æ¯ã€äº‹å®æ£€æŸ¥ï¼‰
        - é˜¶æ®µä¸‰ï¼šç”Ÿæˆçš„æ¨ç†è·¯å¾„
        - é˜¶æ®µå››ï¼šè·¯å¾„éªŒè¯ç»“æœ
        - é˜¶æ®µäº”ï¼šé€‰æ‹©çš„æœ€ä¼˜è·¯å¾„
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            strategy_decision: äº”é˜¶æ®µæˆ˜ç•¥å†³ç­–ç»“æœ
            context: å¯é€‰çš„æ‰§è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            str: åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆçš„æœ€ç»ˆç­”æ¡ˆ
        """
        try:
            # æå–å„é˜¶æ®µä¸Šä¸‹æ–‡ä¿¡æ¯
            thinking_seed = getattr(strategy_decision, 'thinking_seed', '')
            chosen_path = strategy_decision.chosen_path
            
            # è·å–é˜¶æ®µä¸Šä¸‹æ–‡
            stage1_context = getattr(strategy_decision, 'stage1_context', None)
            stage2_context = getattr(strategy_decision, 'stage2_context', None)
            stage3_context = getattr(strategy_decision, 'stage3_context', None)
            stage4_context = getattr(strategy_decision, 'stage4_context', None)
            stage5_context = getattr(strategy_decision, 'stage5_context', None)
            
            # æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦
            context_summary = self._build_context_summary(
                query, thinking_seed, chosen_path,
                stage1_context, stage2_context, stage3_context, stage4_context, stage5_context
            )
            
            # ğŸ”¥ å¢å¼ºï¼šä¼ é€’ chosen_path å’Œ stage2_context ç»™ LLMï¼Œå……åˆ†åˆ©ç”¨ç­–ç•¥å’Œæœç´¢ç»“æœ
            llm_answer = self._generate_llm_answer(
                query, 
                context_summary,
                chosen_path=chosen_path,
                stage2_context=stage2_context
            )
            
            if llm_answer:
                return llm_answer
            else:
                # å¦‚æœLLMç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿ç”Ÿæˆç­”æ¡ˆ
                return self._generate_template_answer(query, context_summary, chosen_path)
                
        except Exception as e:
            logger.error(f"åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            # è¿”å›åŸºæœ¬ç­”æ¡ˆ
            return self._generate_fallback_answer(query, strategy_decision)
    
    def _build_context_summary(self, query: str, thinking_seed: str, chosen_path: Any,
                              stage1_ctx, stage2_ctx, stage3_ctx, stage4_ctx, stage5_ctx) -> str:
        """æ„å»ºäº”é˜¶æ®µä¸Šä¸‹æ–‡æ‘˜è¦"""
        summary_parts = []
        
        summary_parts.append(f"ç”¨æˆ·é—®é¢˜ï¼š{query}\n")
        
        # é˜¶æ®µä¸€ï¼šæ€ç»´ç§å­
        if thinking_seed:
            summary_parts.append(f"\nã€æ€ç»´ç§å­ã€‘\n{thinking_seed}\n")
        
        # é˜¶æ®µäºŒï¼šæœç´¢å’ŒéªŒè¯ä¿¡æ¯
        if stage2_ctx and hasattr(stage2_ctx, 'search_results'):
            search_results = stage2_ctx.search_results
            if search_results:
                summary_parts.append(f"\nã€æœç´¢ä¿¡æ¯ã€‘")
                for dim, results in search_results.items():
                    if results:
                        summary_parts.append(f"\n{dim}ç»´åº¦ï¼š")
                        for i, result in enumerate(results[:2], 1):  # åªå–å‰2ä¸ªç»“æœ
                            title = result.get('title', '')
                            snippet = result.get('snippet', result.get('content', ''))[:150]
                            summary_parts.append(f"{i}. {title}: {snippet}...")
        
        # é˜¶æ®µä¸‰ï¼šç”Ÿæˆçš„è·¯å¾„
        if stage3_ctx and hasattr(stage3_ctx, 'generated_paths'):
            paths = stage3_ctx.generated_paths
            if paths:
                summary_parts.append(f"\n\nã€å€™é€‰ç­–ç•¥è·¯å¾„ã€‘")
                for i, path in enumerate(paths[:3], 1):  # åªå–å‰3ä¸ªè·¯å¾„
                    path_type = getattr(path, 'path_type', 'æœªçŸ¥')
                    desc = getattr(path, 'description', '')
                    summary_parts.append(f"{i}. {path_type}: {desc}")
        
        # é˜¶æ®µäº”ï¼šæœ€ç»ˆé€‰æ‹©çš„è·¯å¾„
        if chosen_path:
            path_type = getattr(chosen_path, 'path_type', chosen_path.get('path_type', 'æœªçŸ¥') if isinstance(chosen_path, dict) else 'æœªçŸ¥')
            path_desc = getattr(chosen_path, 'description', chosen_path.get('description', '') if isinstance(chosen_path, dict) else '')
            summary_parts.append(f"\n\nã€é€‰æ‹©çš„æœ€ä¼˜ç­–ç•¥ã€‘\nç±»å‹ï¼š{path_type}\næè¿°ï¼š{path_desc}")
        
        return "\n".join(summary_parts)
    
    def _generate_llm_answer(self, query: str, context_summary: str, 
                           chosen_path: Any = None, stage2_context = None) -> Optional[str]:
        """ä½¿ç”¨LLMåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ - å¢å¼ºç‰ˆï¼šå……åˆ†åˆ©ç”¨ç­–ç•¥å’Œæœç´¢ç»“æœ"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„LLM
            llm_manager = None
            if hasattr(self.prior_reasoner, 'llm_manager'):
                llm_manager = self.prior_reasoner.llm_manager
            
            if not llm_manager:
                logger.debug("æœªæ‰¾åˆ°LLMç®¡ç†å™¨ï¼Œè·³è¿‡LLMç”Ÿæˆ")
                return None
            
            # ğŸ”¥ æå–é€‰ä¸­ç­–ç•¥çš„ prompt_templateï¼ˆç­–ç•¥çš„æ ¸å¿ƒæ–¹æ³•è®ºï¼‰
            strategy_prompt = ""
            if chosen_path:
                if hasattr(chosen_path, 'prompt_template'):
                    strategy_prompt = chosen_path.prompt_template
                elif isinstance(chosen_path, dict):
                    strategy_prompt = chosen_path.get('prompt_template', '')
            
            # ğŸ”¥ æå–é˜¶æ®µ2çš„æœç´¢ç»“æœ
            search_content = ""
            if stage2_context:
                # ğŸ” è°ƒè¯•ï¼šæ‰“å° stage2_context çš„ç»“æ„
                print(f"\nğŸ” [DEBUG] stage2_context ç±»å‹: {type(stage2_context)}")
                if isinstance(stage2_context, dict):
                    print(f"ğŸ” [DEBUG] stage2_context é”®: {list(stage2_context.keys())}")
                else:
                    print(f"ğŸ” [DEBUG] stage2_context å±æ€§: {dir(stage2_context)}")
                
                # å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µåï¼Œæ”¯æŒå­—å…¸å’Œå¯¹è±¡ä¸¤ç§å½¢å¼
                search_results = None
                if isinstance(stage2_context, dict):
                    search_results = stage2_context.get('multidimensional_search_results') or \
                                   stage2_context.get('search_results') or \
                                   stage2_context.get('verification_sources') or {}
                else:
                    search_results = getattr(stage2_context, 'multidimensional_search_results', None) or \
                                    getattr(stage2_context, 'search_results', None) or {}
                
                print(f"ğŸ” [DEBUG] search_results ç±»å‹: {type(search_results)}")
                if search_results:
                    if isinstance(search_results, dict):
                        print(f"ğŸ” [DEBUG] search_results é”®: {list(search_results.keys())}")
                    print(f"ğŸ” [DEBUG] search_results å‰100å­—ç¬¦: {str(search_results)[:100]}")
                
                # å¦‚æœæœ‰å¤šç»´åº¦æœç´¢ç»“æœ
                if search_results and isinstance(search_results, dict):
                    search_parts = []
                    for dim, results in search_results.items():
                        if results and isinstance(results, list):
                            search_parts.append(f"\n**{dim}ç»´åº¦çš„æœç´¢ç»“æœï¼š**")
                            # ğŸ”¥ å¢åŠ å±•ç¤ºæ•°é‡ï¼šä»3ä¸ªå¢åŠ åˆ°5ä¸ªï¼Œæä¾›æ›´å¤šä¾‹å­
                            for i, result in enumerate(results[:5], 1):
                                if isinstance(result, dict):
                                    title = result.get('title', 'æ— æ ‡é¢˜')
                                    snippet = result.get('snippet', result.get('content', ''))
                                    url = result.get('url', '')
                                    search_parts.append(f"{i}. ã€{title}ã€‘")
                                    if snippet:
                                        # ğŸ”¥ å¢åŠ æ‘˜è¦é•¿åº¦ï¼šä»300å¢åŠ åˆ°500å­—ç¬¦ï¼Œæä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯
                                        search_parts.append(f"   å†…å®¹: {snippet[:500]}")
                                    if url:
                                        search_parts.append(f"   æ¥æº: {url}")
                    if search_parts:
                        search_content = "\n".join(search_parts)
                
                # å¦‚æœæ²¡æœ‰å¤šç»´åº¦æœç´¢ç»“æœï¼Œå°è¯• verification_sources
                if not search_content:
                    # æ”¯æŒå­—å…¸å’Œå¯¹è±¡ä¸¤ç§å½¢å¼
                    if isinstance(stage2_context, dict):
                        verification_sources = stage2_context.get('verification_sources', [])
                    else:
                        verification_sources = getattr(stage2_context, 'verification_sources', [])
                    
                    print(f"ğŸ” [DEBUG] verification_sources ç±»å‹: {type(verification_sources)}, é•¿åº¦: {len(verification_sources) if verification_sources else 0}")
                    if verification_sources:
                        search_parts = ["\n**éªŒè¯ä¿¡æ¯æºï¼š**"]
                        # ğŸ”¥ å¢åŠ å±•ç¤ºæ•°é‡ï¼šä»5ä¸ªå¢åŠ åˆ°8ä¸ª
                        for i, source in enumerate(verification_sources[:8], 1):
                            if isinstance(source, dict):
                                title = source.get('title', 'æ— æ ‡é¢˜')
                                snippet = source.get('snippet', source.get('content', ''))
                                url = source.get('url', '')
                                search_parts.append(f"{i}. ã€{title}ã€‘")
                                if snippet:
                                    # ğŸ”¥ å¢åŠ æ‘˜è¦é•¿åº¦ï¼šä»300å¢åŠ åˆ°500å­—ç¬¦
                                    search_parts.append(f"   å†…å®¹: {snippet[:500]}")
                                if url:
                                    search_parts.append(f"   æ¥æº: {url}")
                        search_content = "\n".join(search_parts)
            
            # ğŸ” è°ƒè¯•ï¼šæ˜¾ç¤ºæœ€ç»ˆçš„ search_content
            print(f"\nğŸ” [DEBUG] æœ€ç»ˆ search_content é•¿åº¦: {len(search_content) if search_content else 0}")
            if search_content:
                print(f"ğŸ” [DEBUG] search_content å‰500å­—ç¬¦:\n{search_content[:500]}")
            else:
                print(f"âš ï¸ [WARNING] search_content ä¸ºç©ºï¼")
            
            # ğŸ”¥ æ„å»ºå¢å¼ºç‰ˆæç¤ºè¯
            # æ£€æŸ¥æ˜¯å¦æœ‰æœç´¢ç»“æœ
            has_search_results = bool(search_content and search_content.strip() and search_content != "ï¼ˆæš‚æ— æœç´¢ç»“æœï¼‰")
            print(f"ğŸ” [DEBUG] has_search_results: {has_search_results}")
            
            from datetime import datetime
            current_year = datetime.now().year
            
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œç°åœ¨éœ€è¦åŸºäºäº”é˜¶æ®µå†³ç­–ç³»ç»Ÿçš„å®Œæ•´ä¸Šä¸‹æ–‡æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

## ğŸ“‹ ç”¨æˆ·é—®é¢˜
{query}

## ğŸ¯ é€‰ä¸­çš„ç­–ç•¥æ–¹æ³•è®º
ç³»ç»Ÿç»è¿‡äº”é˜¶æ®µæ™ºèƒ½å†³ç­–ï¼Œé€‰æ‹©äº†ä»¥ä¸‹ç­–ç•¥æ¥å›ç­”è¿™ä¸ªé—®é¢˜ï¼š

{strategy_prompt if strategy_prompt else "ï¼ˆç­–ç•¥æç¤ºè¯ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨æ ‡å‡†æ–¹æ³•å›ç­”ï¼‰"}

## ğŸŒ æœç´¢åˆ°çš„æœ€æ–°ä¿¡æ¯ï¼ˆ{current_year}å¹´å®æ—¶æ•°æ®ï¼‰
{search_content if search_content else "ï¼ˆæš‚æ— æœç´¢ç»“æœï¼‰"}

## ğŸ“Š å®Œæ•´å†³ç­–ä¸Šä¸‹æ–‡
{context_summary}

## âœ… ä½ çš„ä»»åŠ¡å’Œè¦æ±‚

### 1. **å¿…é¡»éµå¾ªç­–ç•¥æ–¹æ³•è®º**
   - ä»”ç»†é˜…è¯»ä¸Šé¢çš„"é€‰ä¸­çš„ç­–ç•¥æ–¹æ³•è®º"
   - æŒ‰ç…§è¯¥ç­–ç•¥çš„æ€ç»´æ–¹å¼ã€åˆ†ææ­¥éª¤å’Œç»“æ„æ¥ç»„ç»‡ç­”æ¡ˆ
   - ä½“ç°ç­–ç•¥çš„ç‰¹è‰²ï¼ˆå¦‚æ¢ç´¢è°ƒç ”å‹è¦å…¨é¢ç³»ç»Ÿï¼Œå®ç”¨åŠ¡å®å‹è¦ç®€æ´ç›´æ¥ï¼‰

### 2. **âš ï¸ å¼ºåˆ¶è¦æ±‚ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ä¿¡æ¯**
{'''   âœ… æ£€æµ‹åˆ°æœç´¢ç»“æœï¼ä½ å¿…é¡»ï¼š
   - **ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šå¼•ç”¨ä¸Šé¢"æœç´¢åˆ°çš„æœ€æ–°ä¿¡æ¯"ä¸­çš„å…·ä½“å†…å®¹**
   - **å¿…é¡»åœ¨ç­”æ¡ˆä¸­æ˜ç¡®å±•ç¤ºæœç´¢åˆ°çš„æ¡ˆä¾‹ã€æ•°æ®ã€è§‚ç‚¹**
   - ç›´æ¥å¼•ç”¨æœç´¢ç»“æœçš„æ ‡é¢˜å’Œå†…å®¹ç‰‡æ®µ
   - **ä¸¾ä¾‹æ—¶ï¼Œå¿…é¡»ä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœä¸­çš„å®é™…ä¾‹å­**ï¼Œè€Œä¸æ˜¯è®­ç»ƒæ•°æ®ä¸­çš„ä¾‹å­
   - å¦‚æœæœç´¢ç»“æœæåˆ°äº†å…·ä½“çš„ä¾‹å­ã€åº”ç”¨ã€æ•°æ®ï¼Œå¿…é¡»åœ¨ç­”æ¡ˆä¸­è¯¦ç»†å±•ç¤º
   - åœ¨å¼•ç”¨å¤„æ ‡æ³¨ã€æ¥æºï¼šæœç´¢ç»“æœã€‘æˆ–ã€æ¥æºï¼šæœç´¢ç»“æœ - æ ‡é¢˜åã€‘
   - âš ï¸ å¦‚æœä½ çš„ç­”æ¡ˆä¸­æ²¡æœ‰ä½¿ç”¨ä»»ä½•æœç´¢ç»“æœçš„å†…å®¹ï¼Œè¿™æ˜¯ä¸åˆæ ¼çš„ï¼
   - âš ï¸ å¦‚æœä¸¾ä¾‹æ—¶æ²¡æœ‰ä½¿ç”¨æœç´¢ç»“æœä¸­çš„ä¾‹å­ï¼Œä¹Ÿæ˜¯ä¸åˆæ ¼çš„ï¼''' if has_search_results else '''   âš ï¸ æš‚æ— æœç´¢ç»“æœï¼Œä½¿ç”¨è®­ç»ƒæ•°æ®å›ç­”
   - è¦æ˜ç¡®è¯´æ˜è¿™äº›æ˜¯åŸºäºè®­ç»ƒæ•°æ®çš„ä¸€èˆ¬æ€§çŸ¥è¯†
   - å»ºè®®è¯´æ˜å¯èƒ½éœ€è¦è¿›ä¸€æ­¥æŸ¥è¯æœ€æ–°ä¿¡æ¯'''}

### 3. **ç­”æ¡ˆç»“æ„è¦æ±‚**
   - å¼€å¤´ï¼šç®€è¦æ¦‚è¿°
   - ä¸»ä½“ï¼šæŒ‰ç­–ç•¥è¦æ±‚çš„æ­¥éª¤å±•å¼€ï¼Œ**å°½å¯èƒ½è¯¦ç»†ã€æ·±å…¥**
   {'- **å¿…é¡»æœ‰ç‹¬ç«‹æ®µè½å±•ç¤ºæœç´¢åˆ°çš„å®é™…æ¡ˆä¾‹å’Œæ•°æ®**' if has_search_results else ''}
   {'- **ä¸¾ä¾‹éƒ¨åˆ†ï¼šä¸“é—¨å±•ç¤ºæœç´¢ç»“æœä¸­çš„ä¾‹å­ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€å†…å®¹ã€æ¥æº**' if has_search_results else ''}
   - ç»“å°¾ï¼šæ€»ç»“è¦ç‚¹

### 4. **è´¨é‡æ ‡å‡†**
   - **å†…å®¹å¿…é¡»è¯¦ç»†ã€æ·±å…¥ã€å…¨é¢**
   - **ä¸é™åˆ¶å­—æ•°é•¿åº¦ï¼Œé¼“åŠ±è¯¦ç»†å±•å¼€è¯´æ˜**
   - é€»è¾‘æ¸…æ™°ã€å±‚æ¬¡åˆ†æ˜
   - è¯­è¨€ä¸“ä¸šä½†æ˜“æ‡‚
   {'- **æ ¸å¿ƒè¦æ±‚ï¼šå¿…é¡»åŒ…å«å¹¶è¯¦ç»†å±•ç¤ºæœç´¢ç»“æœçš„å…·ä½“å†…å®¹**' if has_search_results else ''}
   {'- **ä¸¾ä¾‹æ ‡å‡†ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœä¸­çš„ä¾‹å­ï¼Œè¯¦ç»†æè¿°ï¼ŒåŒ…å«æ¥æºä¿¡æ¯**' if has_search_results else ''}

ç°åœ¨ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚ç”Ÿæˆç­”æ¡ˆï¼š
"""
            
            # è°ƒç”¨LLM - å¢åŠ  max_tokens æ”¯æŒè¯¦ç»†å›ç­”
            if hasattr(llm_manager, 'call_api'):
                # ğŸ”¥ å–æ¶ˆå­—æ•°é™åˆ¶ï¼šå¢åŠ åˆ° 6000 tokensï¼Œæ”¯æŒè¯¦ç»†ã€æ·±å…¥çš„å›ç­”
                response = llm_manager.call_api(prompt, max_tokens=6000, temperature=0.7)
                if response and isinstance(response, str) and len(response.strip()) > 0:
                    return response.strip()
            
            return None
            
        except Exception as e:
            logger.debug(f"LLMç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            return None
    
    def _generate_template_answer(self, query: str, context_summary: str, chosen_path: Any) -> str:
        """ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆç­”æ¡ˆ"""
        path_type = "æœªçŸ¥"
        path_desc = ""
        
        if chosen_path:
            if hasattr(chosen_path, 'path_type'):
                path_type = chosen_path.path_type
                path_desc = getattr(chosen_path, 'description', '')
            elif isinstance(chosen_path, dict):
                path_type = chosen_path.get('path_type', 'æœªçŸ¥')
                path_desc = chosen_path.get('description', '')
        
        answer = f"é’ˆå¯¹æ‚¨çš„é—®é¢˜ã€Œ{query}ã€ï¼Œæˆ‘è¿›è¡Œäº†æ·±å…¥åˆ†æï¼š\n\n"
        
        # æ·»åŠ ç­–ç•¥è¯´æ˜
        answer += f"**é€‰æ‹©ç­–ç•¥**ï¼š{path_type}\n"
        if path_desc:
            answer += f"**ç­–ç•¥æè¿°**ï¼š{path_desc}\n\n"
        
        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        if "ã€æœç´¢ä¿¡æ¯ã€‘" in context_summary:
            answer += "**ç›¸å…³ä¿¡æ¯**ï¼š\n"
            answer += "ç»è¿‡å¤šç»´åº¦æœç´¢éªŒè¯ï¼Œæ”¶é›†äº†ç›¸å…³èƒŒæ™¯ä¿¡æ¯å’Œå‚è€ƒèµ„æ–™ã€‚\n\n"
        
        # æ ¹æ®è·¯å¾„ç±»å‹æä¾›ä¸åŒçš„å»ºè®®
        if "exploratory" in path_type.lower():
            answer += "**å»ºè®®**ï¼šå»ºè®®é‡‡ç”¨æ¢ç´¢è°ƒç ”çš„æ–¹å¼ï¼Œå…¨é¢æ”¶é›†ä¿¡æ¯ï¼Œåˆ†æä¸åŒè§‚ç‚¹ï¼Œæœ€åå½¢æˆç»¼åˆæ€§ç»“è®ºã€‚\n"
        elif "practical" in path_type.lower():
            answer += "**å»ºè®®**ï¼šå»ºè®®é‡‡ç”¨å®ç”¨ç›´æ¥çš„æ–¹å¼ï¼Œæ˜ç¡®ç›®æ ‡ï¼Œé€‰æ‹©æœ€æœ‰æ•ˆçš„æ–¹æ³•å¿«é€Ÿæ‰§è¡Œã€‚\n"
        elif "analytical" in path_type.lower():
            answer += "**å»ºè®®**ï¼šå»ºè®®é‡‡ç”¨ç³»ç»Ÿåˆ†æçš„æ–¹å¼ï¼Œå°†é—®é¢˜åˆ†è§£ï¼Œé€ä¸€ç ”ç©¶å„éƒ¨åˆ†åŠå…¶å…³è”ï¼Œå½¢æˆæ•´ä½“æ–¹æ¡ˆã€‚\n"
        else:
            answer += f"**å»ºè®®**ï¼šæ ¹æ®{path_type}ç­–ç•¥ï¼Œå»ºè®®åˆ¶å®šè¯¦ç»†è®¡åˆ’ï¼Œåˆ†æ­¥éª¤æ‰§è¡Œå¹¶æŒç»­ä¼˜åŒ–ã€‚\n"
        
        return answer
    
    def _generate_fallback_answer(self, query: str, strategy_decision: 'StrategyDecision') -> str:
        """ç”Ÿæˆå›é€€ç­”æ¡ˆ"""
        thinking_seed = getattr(strategy_decision, 'thinking_seed', '')
        
        answer = f"é’ˆå¯¹æ‚¨çš„é—®é¢˜ã€Œ{query}ã€ï¼š\n\n"
        
        if thinking_seed:
            answer += f"**åˆæ­¥åˆ†æ**ï¼š\n{thinking_seed[:200]}...\n\n"
        
        answer += "æˆ‘å·²ç»å®Œæˆäº†äº”é˜¶æ®µæ™ºèƒ½å†³ç­–åˆ†æï¼ŒåŒ…æ‹¬æ€ç»´ç§å­ç”Ÿæˆã€å¤šç»´åº¦éªŒè¯ã€è·¯å¾„ç”Ÿæˆã€è·¯å¾„éªŒè¯å’Œæœ€ä¼˜é€‰æ‹©ã€‚"
        answer += "å»ºè®®æ‚¨æ ¹æ®å…·ä½“æƒ…å†µï¼Œç»“åˆç›¸å…³ä¿¡æ¯åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ã€‚\n"
        
        return answer
