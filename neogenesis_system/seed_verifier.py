"""
ç§å­éªŒè¯å™¨æ¨¡å— - ä¸“é—¨è´Ÿè´£æ€ç»´ç§å­çš„éªŒè¯å’Œå¢å¼ºé€»è¾‘

æœ¬æ¨¡å—ä» NeogenesisPlanner ä¸­æå–å‡ºæ¥ï¼Œå®ç°èŒè´£å•ä¸€åŒ–ï¼š
- è´Ÿè´£é˜¶æ®µäºŒçš„ç§å­éªŒè¯å’Œå¢å¼ºé€»è¾‘
- æ™ºèƒ½è§„åˆ’éªŒè¯æœç´¢ç»´åº¦
- æ‰§è¡Œä¿¡æ¯æœç´¢å’Œç§å­å¢å¼º
- æä¾›å¯å‘å¼å›é€€æœºåˆ¶
"""

import time
import logging
import json
from typing import Optional, Dict, List, Any

# å¯¼å…¥æ•°æ®ç»“æ„
try:
    from ..shared.data_structures import (
        ThinkingSeedContext,
        SeedVerificationContext
    )
except ImportError:
    from neogenesis_system.shared.data_structures import (
        ThinkingSeedContext,
        SeedVerificationContext
    )

# å¯¼å…¥å·¥å…·ç³»ç»Ÿ
try:
    from ..tools.tool_abstraction import ToolRegistry
except ImportError:
    from neogenesis_system.tools.tool_abstraction import ToolRegistry

# å¯¼å…¥ LLM ç®¡ç†å™¨
try:
    from ..providers.llm_manager import LLMManager
except ImportError:
    try:
        from neogenesis_system.providers.llm_manager import LLMManager
    except ImportError:
        LLMManager = None

logger = logging.getLogger(__name__)


class SeedVerifier:
    """
    ç§å­éªŒè¯å™¨ç±»
    
    ä¸“é—¨è´Ÿè´£æ€ç»´ç§å­çš„éªŒè¯æ£€æŸ¥å’Œå¢å¼ºç”Ÿæˆé€»è¾‘ã€‚
    å°†åŸæœ¬åœ¨ NeogenesisPlanner ä¸­çš„é˜¶æ®µäºŒé€»è¾‘ç‹¬ç«‹å‡ºæ¥ï¼Œ
    æé«˜ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯æµ‹è¯•æ€§ã€‚
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. éªŒè¯æ€ç»´ç§å­çš„å¯è¡Œæ€§
    2. æ™ºèƒ½è§„åˆ’æœç´¢ç»´åº¦
    3. æ‰§è¡Œå¤šç»´åº¦ä¿¡æ¯æœç´¢
    4. æ•´åˆä¿¡æ¯ç”Ÿæˆå¢å¼ºç‰ˆç§å­
    """
    
    def __init__(self, 
                 tool_registry: Optional[ToolRegistry] = None,
                 llm_manager: Optional[Any] = None):
        """
        åˆå§‹åŒ–ç§å­éªŒè¯å™¨
        
        Args:
            tool_registry: å·¥å…·æ³¨å†Œè¡¨å®ä¾‹ï¼Œç”¨äºè°ƒç”¨éªŒè¯å’Œæœç´¢å·¥å…·
            llm_manager: LLMç®¡ç†å™¨å®ä¾‹ï¼Œç”¨äºç”Ÿæˆæœç´¢è§„åˆ’å’Œç§å­å¢å¼º
        """
        self.tool_registry = tool_registry
        self.llm_manager = llm_manager
        logger.info("âœ… SeedVerifier åˆå§‹åŒ–å®Œæˆ")
    
    def verify(self, 
               stage1_context: ThinkingSeedContext,
               execution_context: Optional[Dict] = None,
               streaming_output = None) -> SeedVerificationContext:
        """
        æ‰§è¡Œç§å­éªŒè¯æ£€æŸ¥ä¸å¢å¼ºç”Ÿæˆ
        
        è¿™æ˜¯é˜¶æ®µäºŒçš„æ ¸å¿ƒæ–¹æ³•ï¼Œè´Ÿè´£ï¼š
        1. éªŒè¯æ€ç»´ç§å­çš„å¯è¡Œæ€§
        2. æ™ºèƒ½è§„åˆ’æœç´¢ç»´åº¦
        3. æ‰§è¡Œå¤šç»´åº¦ä¿¡æ¯æœç´¢
        4. æ•´åˆä¿¡æ¯ç”Ÿæˆå¢å¼ºç‰ˆç§å­
        
        Args:
            stage1_context: é˜¶æ®µä¸€çš„æ€ç»´ç§å­ä¸Šä¸‹æ–‡
            execution_context: æ‰§è¡Œä¸Šä¸‹æ–‡å­—å…¸ï¼ˆå¯é€‰ï¼‰
            streaming_output: æµå¼è¾“å‡ºå¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            SeedVerificationContext: åŒ…å«éªŒè¯ç»“æœå’Œå¢å¼ºç§å­çš„ä¸Šä¸‹æ–‡å¯¹è±¡
        """
        # åˆ›å»ºéªŒè¯ä¸Šä¸‹æ–‡
        context = SeedVerificationContext(
            user_query=stage1_context.user_query,
            execution_context=execution_context
        )
        
        # æ·»åŠ è®¡æ—¶é€»è¾‘
        verification_start_time = time.time()
        
        try:
            logger.info(f"å¼€å§‹ç§å­éªŒè¯ä¸å¢å¼º: {stage1_context.thinking_seed[:50]}...")
            
            # æµå¼è¾“å‡ºï¼šé˜¶æ®µäºŒå¼€å§‹
            self._send_streaming_output(
                streaming_output,
                stage="stage2_start",
                content="ğŸ” ã€é˜¶æ®µäºŒï¼šç§å­éªŒè¯ä¸å¢å¼ºã€‘å¼€å§‹...",
                metadata={"thinking_seed_preview": stage1_context.thinking_seed[:100]}
            )
            
            # åŸºç¡€éªŒè¯
            self._send_streaming_output(
                streaming_output,
                stage="stage2_basic_verification",
                content="ğŸ“‹ æ­£åœ¨æ‰§è¡ŒåŸºç¡€éªŒè¯...",
                metadata={}
            )
            
            basic_verification_success = self._perform_basic_verification(
                stage1_context, context, streaming_output
            )
            
            if not basic_verification_success:
                logger.warning("âš ï¸ åŸºç¡€éªŒè¯æœªé€šè¿‡ï¼Œä½¿ç”¨åŸå§‹ç§å­")
                context.enhanced_thinking_seed = stage1_context.thinking_seed
                
                self._send_streaming_output(
                    streaming_output,
                    stage="stage2_verification_result",
                    content="âš ï¸ åŸºç¡€éªŒè¯æœªé€šè¿‡ï¼Œå°†ä½¿ç”¨åŸå§‹æ€ç»´ç§å­ç»§ç»­",
                    metadata={"verification_passed": False}
                )
            else:
                self._send_streaming_output(
                    streaming_output,
                    stage="stage2_verification_result",
                    content=f"âœ… åŸºç¡€éªŒè¯é€šè¿‡ï¼ˆå¯è¡Œæ€§è¯„åˆ†ï¼š{context.feasibility_score:.2f}ï¼‰",
                    metadata={
                        "verification_passed": True,
                        "feasibility_score": context.feasibility_score,
                        "verification_method": context.verification_method
                    }
                )
                
                # å¦‚æœæœ‰ LLM ç®¡ç†å™¨ï¼Œæ‰§è¡Œå®Œæ•´çš„å¢å¼ºæµç¨‹
                if self.llm_manager and self.tool_registry:
                    logger.info("ğŸ” æ‰§è¡Œå®Œæ•´çš„ç§å­éªŒè¯å’Œå¢å¼ºæµç¨‹")
                    
                    # ğŸ”¥ æ˜ç¡®åˆ†éš”åŸºç¡€éªŒè¯å’Œå¢å¼ºæµç¨‹
                    print("\n\n" + "ğŸ”·"*40, flush=True)
                    print("ğŸ”·  åŸºç¡€éªŒè¯å®Œæˆï¼Œå¼€å§‹æ™ºèƒ½å¢å¼ºæµç¨‹", flush=True)
                    print("ğŸ”·"*40 + "\n", flush=True)
                    
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_enhancement_start",
                        content="ğŸ” å¼€å§‹æ™ºèƒ½å¢å¼ºæµç¨‹...",
                        metadata={}
                    )
                    
                    # æ­¥éª¤1: è§„åˆ’éªŒè¯æœç´¢ç»´åº¦
                    print("\n" + "ğŸ”¸"*80, flush=True)
                    print("ğŸ”¸ ã€ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½è§„åˆ’æœç´¢ç»´åº¦ã€‘", flush=True)
                    print("ğŸ”¸ è¯´æ˜ï¼šåŸºäºæ€ç»´ç§å­ï¼Œæ™ºèƒ½åˆ†æéœ€è¦ä»å“ªäº›ç»´åº¦æœç´¢ä¿¡æ¯è¿›è¡ŒéªŒè¯å’Œå¢å¼º", flush=True)
                    print("ğŸ”¸"*80, flush=True)
                    
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_planning",
                        content="ğŸ“‹ æ­£åœ¨è§„åˆ’ä¿¡æ¯æœç´¢ç»´åº¦...",
                        metadata={}
                    )
                    
                    search_dimensions = self._plan_verification_search(
                        stage1_context, context, streaming_output
                    )
                    
                    print(f"\nâœ… ç»´åº¦è§„åˆ’å®Œæˆï¼šå…±è§„åˆ’ {len(search_dimensions) if search_dimensions else 0} ä¸ªæœç´¢ç»´åº¦", flush=True)
                    print("ğŸ”¸"*80 + "\n", flush=True)
                    
                    if search_dimensions:
                        logger.info(f"âœ… è§„åˆ’äº† {len(search_dimensions)} ä¸ªæœç´¢ç»´åº¦")
                        context.add_metric("search_dimensions_count", len(search_dimensions))
                        
                        # æ‰“å°è§„åˆ’çš„ç»´åº¦è¯¦æƒ… - ä½¿ç”¨æ›´é†’ç›®çš„æ ¼å¼
                        print("â”" + "â”"*78 + "â”“", flush=True)
                        print("â”ƒ  ğŸ“Œ è§„åˆ’çš„æœç´¢ç»´åº¦è¯¦æƒ…                                                   â”ƒ", flush=True)
                        print("â”—" + "â”"*78 + "â”›\n", flush=True)
                        
                        for i, dim in enumerate(search_dimensions, 1):
                            print(f"â•”â•â• ç»´åº¦ {i} â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", flush=True)
                            print(f"â•‘ åç§°ï¼š{dim.get('dimension', 'æœªå‘½å')}", flush=True)
                            print(f"â•‘ æŸ¥è¯¢ï¼š{dim.get('query', '')}", flush=True)
                            print(f"â•‘ ä¼˜å…ˆçº§ï¼š{dim.get('priority', 'medium').upper()}", flush=True)
                            if dim.get('reason'):
                                print(f"â•‘ ç†ç”±ï¼š{dim.get('reason', '')}", flush=True)
                            print(f"â•š{'â•'*74}â•\n", flush=True)
                        
                        # æ­¥éª¤2: æ‰§è¡Œå¤šç»´åº¦æœç´¢
                        print("\n" + "ğŸ”¸"*80, flush=True)
                        print("ğŸ”¸ ã€ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œå¤šç»´åº¦ä¿¡æ¯æœç´¢ã€‘", flush=True)
                        print("ğŸ”¸ è¯´æ˜ï¼šæ ¹æ®è§„åˆ’çš„ç»´åº¦ï¼Œè°ƒç”¨æœç´¢å·¥å…·è·å–æœ€æ–°ä¿¡æ¯", flush=True)
                        print("ğŸ”¸"*80, flush=True)
                        
                        search_results = self._execute_multi_dimension_search(
                            search_dimensions, context, streaming_output
                        )
                        
                        if search_results:
                            logger.info(f"âœ… æ”¶é›†äº† {len(search_results)} æ¡æœç´¢ç»“æœ")
                            context.add_metric("search_results_count", len(search_results))
                            
                            # ğŸ”¥ ä¿®å¤ï¼šä¿å­˜æœç´¢ç»“æœåˆ° context
                            # 1. æ„å»ºå¤šç»´åº¦æœç´¢ç»“æœå­—å…¸
                            multidim_dict = {}
                            all_verification_sources = []
                            
                            for result in search_results:
                                dimension = result.get('dimension', 'æœªçŸ¥ç»´åº¦')
                                content = result.get('content', {})
                                
                                # æå– results åˆ—è¡¨
                                if isinstance(content, dict) and 'results' in content:
                                    results_list = content['results']
                                    multidim_dict[dimension] = results_list
                                    
                                    # è½¬æ¢ä¸º verification_sources æ ¼å¼
                                    for item in results_list[:5]:  # æ¯ä¸ªç»´åº¦æœ€å¤šå–5æ¡
                                        if isinstance(item, dict):
                                            source_dict = {
                                                'title': item.get('title', ''),
                                                'snippet': item.get('snippet', item.get('content', '')),
                                                'url': item.get('url', ''),
                                                'dimension': dimension  # æ·»åŠ ç»´åº¦ä¿¡æ¯
                                            }
                                            all_verification_sources.append(source_dict)
                            
                            # ä¿å­˜åˆ° context
                            context.multidimensional_search_results = multidim_dict
                            context.verification_sources = all_verification_sources
                            
                            logger.info(f"   ğŸ“Š ä¿å­˜äº† {len(multidim_dict)} ä¸ªç»´åº¦çš„æœç´¢ç»“æœ")
                            logger.info(f"   ğŸ“„ ä¿å­˜äº† {len(all_verification_sources)} æ¡éªŒè¯æº")
                            
                            # å±•ç¤ºå¤šç»´åº¦æœç´¢ç»“æœ - ä½¿ç”¨é†’ç›®çš„æ ¼å¼
                            print("\n" + "â”" + "â”"*78 + "â”“", flush=True)
                            print("â”ƒ  ğŸ“š å¤šç»´åº¦æœç´¢ç»“æœæ±‡æ€»                                                   â”ƒ", flush=True)
                            print("â”—" + "â”"*78 + "â”›\n", flush=True)
                            
                            for i, result in enumerate(search_results, 1):
                                dimension = result.get('dimension', f'ç»´åº¦{i}')
                                query = result.get('query', '')
                                
                                print(f"â”Œâ”€â”€ ç»´åº¦ {i}ï¼šã€{dimension}ã€‘" + "â”€"*(60-len(dimension)-len(str(i))) + "â”", flush=True)
                                print(f"â”‚ ğŸ” æŸ¥è¯¢ï¼š{query}", flush=True)
                                print(f"â”œ{'â”€'*76}â”¤", flush=True)
                                
                                # æ˜¾ç¤ºæœç´¢å†…å®¹é¢„è§ˆ
                                content = result.get('content', {})
                                if isinstance(content, dict) and 'results' in content:
                                    results_list = content['results']
                                    print(f"â”‚ âœ… æ‰¾åˆ° {len(results_list)} æ¡ç›¸å…³ç»“æœ", flush=True)
                                    # æ˜¾ç¤ºå‰2æ¡
                                    for j, item in enumerate(results_list[:2], 1):
                                        if isinstance(item, dict):
                                            title = item.get('title', 'æ— æ ‡é¢˜')
                                            url = item.get('url', '')
                                            snippet = item.get('snippet', '')
                                            print(f"â”‚   {j}) ğŸ“„ {title[:60]}{'...' if len(title) > 60 else ''}", flush=True)
                                            print(f"â”‚      ğŸ”— {url[:65]}{'...' if len(url) > 65 else ''}", flush=True)
                                            if snippet:
                                                print(f"â”‚      ğŸ“ {snippet[:60]}{'...' if len(snippet) > 60 else ''}", flush=True)
                                elif isinstance(content, str):
                                    print(f"â”‚ ğŸ“ å†…å®¹é¢„è§ˆï¼š{content[:60]}...", flush=True)
                                else:
                                    print(f"â”‚ âš ï¸  æœç´¢ç»“æœæ ¼å¼æœªçŸ¥", flush=True)
                                
                                print(f"â””{'â”€'*76}â”˜\n", flush=True)
                            
                            print("ğŸ”¸"*80 + "\n", flush=True)
                            
                            # æ­¥éª¤3: å¢å¼ºç§å­
                            print("\n" + "ğŸ”¸"*80, flush=True)
                            print("ğŸ”¸ ã€ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­ã€‘", flush=True)
                            print("ğŸ”¸ è¯´æ˜ï¼šæ•´åˆæœç´¢ä¿¡æ¯ï¼Œç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­", flush=True)
                            print("ğŸ”¸"*80, flush=True)
                            print(f"ğŸ“Š å°†æ•´åˆ {len(search_results)} æ¡æœç´¢ç»“æœ...\n", flush=True)
                            
                            self._send_streaming_output(
                                streaming_output,
                                stage="stage2_enhancing",
                                content=f"ğŸ”„ æ­£åœ¨æ•´åˆ {len(search_results)} æ¡æœç´¢ç»“æœï¼Œç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­...",
                                metadata={"search_results_count": len(search_results)}
                            )
                            
                            enhanced_seed = self._enhance_seed(
                                stage1_context, search_results, context, streaming_output
                            )
                            
                            if enhanced_seed:
                                context.enhanced_thinking_seed = enhanced_seed
                                logger.info("âœ… æˆåŠŸç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­")
                                
                                self._send_streaming_output(
                                    streaming_output,
                                    stage="stage2_enhanced_seed",
                                    content=f"âœ… æˆåŠŸç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­\n\n{enhanced_seed}",
                                    metadata={
                                        "enhanced": True,
                                        "seed_length": len(enhanced_seed),
                                        "feasibility_score": context.feasibility_score
                                    }
                                )
                            else:
                                context.enhanced_thinking_seed = stage1_context.thinking_seed
                                logger.warning("âš ï¸ å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç§å­")
                                
                                self._send_streaming_output(
                                    streaming_output,
                                    stage="stage2_enhanced_seed",
                                    content="âš ï¸ ç§å­å¢å¼ºå¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹ç§å­",
                                    metadata={"enhanced": False}
                                )
                        else:
                            context.enhanced_thinking_seed = stage1_context.thinking_seed
                            logger.info("â„¹ï¸  æœªæ‰¾åˆ°æœç´¢ç»“æœï¼Œä½¿ç”¨åŸå§‹ç§å­")
                            
                            print("\n" + "âš ï¸ "*40, flush=True)
                            print("âš ï¸  å¤šç»´åº¦æœç´¢æœªè¿”å›æœ‰æ•ˆç»“æœ", flush=True)
                            print("âš ï¸  å°†è·³è¿‡å¢å¼ºæ­¥éª¤ï¼Œä½¿ç”¨åŸå§‹æ€ç»´ç§å­", flush=True)
                            print("âš ï¸ "*40 + "\n", flush=True)
                            
                            self._send_streaming_output(
                                streaming_output,
                                stage="stage2_enhanced_seed",
                                content="â„¹ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆæœç´¢ç»“æœï¼Œå°†ä½¿ç”¨åŸå§‹æ€ç»´ç§å­",
                                metadata={"enhanced": False, "reason": "no_search_results"}
                            )
                    else:
                        context.enhanced_thinking_seed = stage1_context.thinking_seed
                        logger.warning("âš ï¸ æœªè§„åˆ’æœç´¢ç»´åº¦ï¼Œä½¿ç”¨åŸå§‹ç§å­")
                        logger.warning("ğŸ” è¯Šæ–­ä¿¡æ¯ï¼š")
                        logger.warning(f"   - LLM Managerå¯ç”¨: {self.llm_manager is not None}")
                        logger.warning(f"   - Tool Registryå¯ç”¨: {self.tool_registry is not None}")
                        
                        print("\n" + "â”" + "â”"*78 + "â”“", flush=True)
                        print("â”ƒ âš ï¸  ç»´åº¦æœç´¢è§„åˆ’æœªæ‰§è¡Œ                                                  â”ƒ", flush=True)
                        print("â”—" + "â”"*78 + "â”›", flush=True)
                        print("ğŸ“Œ åŸå› åˆ†æï¼š", flush=True)
                        print("  â€¢ LLMæœªèƒ½æˆåŠŸè§„åˆ’å‡ºæœ‰æ•ˆçš„æœç´¢ç»´åº¦", flush=True)
                        print("  â€¢ å¯èƒ½çš„åŸå› ï¼š", flush=True)
                        print("    - LLMå“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ", flush=True)
                        print("    - LLMæœåŠ¡æš‚æ—¶ä¸å¯ç”¨", flush=True)
                        print("    - ç½‘ç»œè¿æ¥é—®é¢˜", flush=True)
                        print("\nğŸ“Œ å¤„ç†æ–¹å¼ï¼š", flush=True)
                        print("  â€¢ è·³è¿‡å¤šç»´åº¦æœç´¢å¢å¼ºæ­¥éª¤", flush=True)
                        print("  â€¢ ä½¿ç”¨åŸå§‹æ€ç»´ç§å­ï¼ˆå·²é€šè¿‡åŸºç¡€éªŒè¯ï¼‰", flush=True)
                        print("  â€¢ æµç¨‹å°†ç»§ç»­è¿›è¡Œåˆ°ä¸‹ä¸€é˜¶æ®µ", flush=True)
                        print("\nğŸ” è¯Šæ–­ä¿¡æ¯ï¼š", flush=True)
                        print(f"  â€¢ LLM Manager å¯ç”¨æ€§: {'âœ… æ˜¯' if self.llm_manager else 'âŒ å¦'}", flush=True)
                        print(f"  â€¢ Tool Registry å¯ç”¨æ€§: {'âœ… æ˜¯' if self.tool_registry else 'âŒ å¦'}", flush=True)
                        print("â”„"*80 + "\n", flush=True)
                        
                        self._send_streaming_output(
                            streaming_output,
                            stage="stage2_enhanced_seed",
                            content="â„¹ï¸ æœªè§„åˆ’æœç´¢ç»´åº¦ï¼Œå°†ä½¿ç”¨åŸå§‹æ€ç»´ç§å­",
                            metadata={"enhanced": False, "reason": "no_dimensions"}
                        )
                else:
                    # é™çº§ï¼šç›´æ¥ä½¿ç”¨åŸå§‹ç§å­
                    context.enhanced_thinking_seed = stage1_context.thinking_seed
                    logger.info("â„¹ï¸  LLMç®¡ç†å™¨æœªé…ç½®ï¼Œä½¿ç”¨åŸå§‹ç§å­")
                    
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_enhanced_seed",
                        content="â„¹ï¸ LLMç®¡ç†å™¨æœªé…ç½®ï¼Œå°†ä½¿ç”¨åŸå§‹æ€ç»´ç§å­",
                        metadata={"enhanced": False, "reason": "no_llm_manager"}
                    )
                
        except Exception as e:
            logger.error(f"   âŒ ç§å­éªŒè¯å¼‚å¸¸: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            
            # å¼‚å¸¸å›é€€
            context.verification_result = True  # ä¸é˜»æ­¢æµç¨‹ç»§ç»­
            context.feasibility_score = 0.3
            context.verification_method = "exception_fallback"
            context.verification_evidence = [f"éªŒè¯å¼‚å¸¸: {str(e)}", "ä½¿ç”¨å¼‚å¸¸å›é€€éªŒè¯"]
            context.add_error(f"éªŒè¯å¼‚å¸¸: {str(e)}")
            context.enhanced_thinking_seed = stage1_context.thinking_seed
            
            self._send_streaming_output(
                streaming_output,
                stage="stage2_error",
                content=f"âŒ ç§å­éªŒè¯è¿‡ç¨‹å‡ºç°å¼‚å¸¸ï¼š{str(e)}\nå°†ä½¿ç”¨åŸå§‹ç§å­ç»§ç»­",
                metadata={"error": str(e), "fallback": True}
            )
        
        # è®¡ç®—å¹¶è®°å½•æ‰§è¡Œæ—¶é—´
        verification_time = time.time() - verification_start_time
        context.add_metric("verification_time", verification_time)
        context.add_metric("feasibility_confidence", context.feasibility_score)
        
        logger.info(f"ç§å­éªŒè¯è€—æ—¶: {verification_time:.3f}s")
        logger.info(f"æœ€ç»ˆå¯è¡Œæ€§è¯„åˆ†: {context.feasibility_score:.3f}")
        logger.info(f"éªŒè¯æ–¹æ³•: {context.verification_method}")
        
        # æµå¼è¾“å‡ºï¼šé˜¶æ®µäºŒå®Œæˆ
        self._send_streaming_output(
            streaming_output,
            stage="stage2_complete",
            content=f"âœ… ã€é˜¶æ®µäºŒå®Œæˆã€‘éªŒè¯è€—æ—¶ {verification_time:.2f}ç§’ï¼Œå¯è¡Œæ€§è¯„åˆ†ï¼š{context.feasibility_score:.2f}",
            metadata={
                "verification_time": verification_time,
                "feasibility_score": context.feasibility_score,
                "verification_method": context.verification_method,
                "enhanced_seed": context.enhanced_thinking_seed
            }
        )
        
        return context
    
    def _perform_basic_verification(self, 
                                    stage1_context: ThinkingSeedContext,
                                    context: SeedVerificationContext,
                                    streaming_output = None) -> bool:
        """
        æ‰§è¡ŒåŸºç¡€éªŒè¯
        
        Args:
            stage1_context: é˜¶æ®µä¸€ä¸Šä¸‹æ–‡
            context: éªŒè¯ä¸Šä¸‹æ–‡
            
        Returns:
            bool: éªŒè¯æ˜¯å¦æˆåŠŸ
        """
        # æ£€æŸ¥å·¥å…·æ³¨å†Œè¡¨çŠ¶æ€
        if not self.tool_registry:
            logger.warning("   âš ï¸ å·¥å…·æ³¨å†Œè¡¨æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ç®€åŒ–éªŒè¯")
            context.verification_result = True
            context.feasibility_score = 0.6
            context.verification_method = "simplified_heuristic"
            context.verification_evidence = ["å·¥å…·æ³¨å†Œè¡¨æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨å¯å‘å¼éªŒè¯"]
            return True
            
        elif not self.tool_registry.has_tool("idea_verification"):
            logger.warning("   âš ï¸ idea_verificationå·¥å…·ä¸å¯ç”¨ï¼Œä½¿ç”¨å¯å‘å¼éªŒè¯")
            
            # å¯å‘å¼éªŒè¯é€»è¾‘
            seed_text = stage1_context.thinking_seed
            seed_length = len(seed_text) if seed_text else 0
            has_keywords = any(keyword in seed_text.lower() for keyword in 
                             ["åˆ†æ", "æ–¹æ³•", "ç­–ç•¥", "è§£å†³", "å»ºè®®", "ç³»ç»Ÿ", "ä¼˜åŒ–"]) if seed_text else False
            
            if seed_length > 30 and has_keywords:
                context.feasibility_score = 0.7
                context.verification_result = True
                context.verification_evidence = [f"ç§å­é•¿åº¦: {seed_length}å­—ç¬¦", "åŒ…å«å…³é”®åˆ†æè¯æ±‡"]
            else:
                context.feasibility_score = 0.5
                context.verification_result = True
                context.verification_evidence = [f"ç§å­é•¿åº¦: {seed_length}å­—ç¬¦", "åŸºç¡€éªŒè¯é€šè¿‡"]
            
            context.verification_method = "heuristic_analysis"
            return True
            
        else:
            # ğŸ”¥ ä¿®å¤ï¼šçœŸæ­£è°ƒç”¨ idea_verification å·¥å…·è·å–äº‹å®éªŒè¯
            logger.info("âœ… ä½¿ç”¨ idea_verification å·¥å…·è¿›è¡Œäº‹å®éªŒè¯...")
            
            self._send_streaming_output(
                streaming_output,
                stage="stage2_fact_verification",
                content="ğŸ” æ­£åœ¨è°ƒç”¨äº‹å®éªŒè¯å·¥å…·...",
                metadata={}
            )
            
            try:
                # å‡†å¤‡éªŒè¯è¾“å…¥
                verification_input = {
                    'idea_text': stage1_context.thinking_seed,
                    'context': {
                        'user_query': stage1_context.user_query,
                        '_streaming_output': streaming_output  # ä¼ é€’streaming_output
                    }
                }
                
                # ğŸ¯ çœŸæ­£è°ƒç”¨ idea_verification å·¥å…·
                logger.info(f"ğŸ“ è°ƒç”¨ idea_verification: {stage1_context.thinking_seed[:100]}...")
                verification_result = self.tool_registry.execute_tool(
                    name="idea_verification",
                    **verification_input
                )
                
                if verification_result and verification_result.success:
                    logger.info("âœ… äº‹å®éªŒè¯æˆåŠŸ")
                    
                    # æå–éªŒè¯ç»“æœ
                    result_data = verification_result.data  # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ data è€Œä¸æ˜¯ result
                    if isinstance(result_data, dict):
                        context.feasibility_score = result_data.get('feasibility_score', 0.7)
                        context.verification_result = result_data.get('verification_passed', True)
                        context.verification_evidence = result_data.get('key_findings', [])
                        context.verification_method = "idea_verification_tool"
                        
                        # ğŸ”¥ ä¿å­˜äº‹å®éªŒè¯çš„è¯¦ç»†ç»“æœ
                        context.verification_results = result_data
                        
                        # ğŸ”¥ ä¿®å¤ï¼šæå–å¹¶ä¿å­˜æœç´¢ç»“æœåˆ° verification_sources
                        search_results = result_data.get('search_results', [])
                        if search_results:
                            verification_sources = []
                            for sr in search_results[:5]:  # ä¿å­˜å‰5ä¸ªæœç´¢ç»“æœ
                                if isinstance(sr, dict):
                                    source_dict = {
                                        'title': sr.get('title', ''),
                                        'snippet': sr.get('snippet', ''),
                                        'url': sr.get('url', ''),
                                        'relevance_score': sr.get('relevance_score', 0.0)
                                    }
                                    verification_sources.append(source_dict)
                            
                            context.verification_sources = verification_sources
                            logger.info(f"   ğŸ“„ ä¿å­˜äº† {len(verification_sources)} æ¡åŸºç¡€éªŒè¯çš„æœç´¢ç»“æœ")
                        
                        # æµå¼è¾“å‡ºéªŒè¯ç»“æœæ‘˜è¦
                        findings_preview = "\n".join([f"â€¢ {finding}" for finding in context.verification_evidence[:3]])
                        self._send_streaming_output(
                            streaming_output,
                            stage="stage2_fact_verification_result",
                            content=f"âœ… äº‹å®éªŒè¯å®Œæˆ\n\nå¯è¡Œæ€§è¯„åˆ†ï¼š{context.feasibility_score:.2f}\n\nå…³é”®å‘ç°ï¼š\n{findings_preview}",
                            metadata={
                                "feasibility_score": context.feasibility_score,
                                "verification_passed": context.verification_result,
                                "evidence_count": len(context.verification_evidence)
                            }
                        )
                        
                        return True
                    else:
                        logger.warning("âš ï¸ éªŒè¯ç»“æœæ ¼å¼å¼‚å¸¸ï¼Œä½¿ç”¨ç®€åŒ–éªŒè¯")
                        context.verification_result = True
                        context.feasibility_score = 0.7
                        context.verification_method = "simplified_verification"
                        context.verification_evidence = ["éªŒè¯ç»“æœæ ¼å¼å¼‚å¸¸"]
                        return True
                else:
                    logger.warning(f"âš ï¸ idea_verification è°ƒç”¨å¤±è´¥: {verification_result.error_message if verification_result else 'Unknown error'}")
                    
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_fact_verification_failed",
                        content="âš ï¸ äº‹å®éªŒè¯å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–éªŒè¯",
                        metadata={}
                    )
                    
                    # å›é€€åˆ°ç®€åŒ–éªŒè¯
                    context.verification_result = True
                    context.feasibility_score = 0.6
                    context.verification_method = "simplified_fallback"
                    context.verification_evidence = ["idea_verificationè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–éªŒè¯"]
                    return True
                    
            except Exception as e:
                logger.error(f"âŒ äº‹å®éªŒè¯å¼‚å¸¸: {e}")
                import traceback
                logger.debug(traceback.format_exc())
                
                self._send_streaming_output(
                    streaming_output,
                    stage="stage2_fact_verification_error",
                    content=f"âŒ äº‹å®éªŒè¯å¼‚å¸¸ï¼š{str(e)}\nä½¿ç”¨ç®€åŒ–éªŒè¯",
                    metadata={"error": str(e)}
                )
                
                # å›é€€åˆ°ç®€åŒ–éªŒè¯
                context.verification_result = True
                context.feasibility_score = 0.6
                context.verification_method = "exception_fallback"
                context.verification_evidence = [f"éªŒè¯å¼‚å¸¸: {str(e)}"]
                return True
    
    def _plan_verification_search(self,
                                  stage1_context: ThinkingSeedContext,
                                  context: SeedVerificationContext,
                                  streaming_output = None) -> List[Dict[str, str]]:
        """
        æ™ºèƒ½è§„åˆ’éªŒè¯æœç´¢ç»´åº¦
        
        åŸºäºç”¨æˆ·æŸ¥è¯¢å’Œæ€ç»´ç§å­ï¼Œåˆ©ç”¨ LLM æ™ºèƒ½åˆ†æåº”è¯¥ä»å“ªäº›ç»´åº¦æœç´¢ä¿¡æ¯ï¼Œ
        ä»¥éªŒè¯å’Œå¢å¼ºæ€ç»´ç§å­ã€‚
        
        Args:
            stage1_context: é˜¶æ®µä¸€ä¸Šä¸‹æ–‡
            context: éªŒè¯ä¸Šä¸‹æ–‡
            
        Returns:
            List[Dict]: æœç´¢ç»´åº¦åˆ—è¡¨ï¼Œæ¯ä¸ªç»´åº¦åŒ…å« dimensionã€queryã€priority
        """
        try:
            logger.info("ğŸ“‹ å¼€å§‹è§„åˆ’éªŒè¯æœç´¢ç»´åº¦...")
            print("â³ æ­£åœ¨è°ƒç”¨ LLM åˆ†ææœç´¢ç»´åº¦...", flush=True)
            
            # ğŸ”¥ è·å–å½“å‰æ—¶é—´ä¿¡æ¯
            from datetime import datetime
            now = datetime.now()
            current_year = now.year
            current_month = now.month
            current_date = now.strftime('%Yå¹´%mæœˆ')
            
            # æ„å»ºæœç´¢è§„åˆ’æç¤ºè¯­
            planning_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä¿¡æ¯æœç´¢è§„åˆ’ä¸“å®¶ã€‚

ğŸ“… **å½“å‰æ—¶é—´ä¿¡æ¯**ï¼ˆè§„åˆ’æœç´¢æ—¶å¿…é¡»ä½¿ç”¨ï¼‰:
- å½“å‰å¹´ä»½: {current_year}å¹´
- å½“å‰æœˆä»½: {current_date}
- âš ï¸ é‡è¦ï¼šåœ¨æœç´¢æŸ¥è¯¢ä¸­ï¼Œå¦‚æœéœ€è¦æœ€æ–°ä¿¡æ¯ï¼Œè¯·ä½¿ç”¨ "{current_year}" è€Œä¸æ˜¯å…¶ä»–å¹´ä»½

ç”¨æˆ·é—®é¢˜ï¼š{stage1_context.user_query}

åˆå§‹æ€ç»´ç§å­ï¼š
{stage1_context.thinking_seed}

è¯·åˆ†æè¿™ä¸ªæ€ç»´ç§å­ï¼Œå¹¶è§„åˆ’åº”è¯¥ä»å“ªäº›ç»´åº¦æœç´¢æœ€æ–°ä¿¡æ¯æ¥éªŒè¯å’Œå¢å¼ºå®ƒã€‚
æ¯ä¸ªæœç´¢ç»´åº¦åº”è¯¥åŒ…å«ï¼š
1. dimension: ç»´åº¦åç§°ï¼ˆå¦‚"æŠ€æœ¯è¶‹åŠ¿"ã€"è¡Œä¸šç°çŠ¶"ã€"æœ€ä½³å®è·µ"ç­‰ï¼‰
2. query: å…·ä½“çš„æœç´¢æŸ¥è¯¢è¯­å¥
3. priority: ä¼˜å…ˆçº§ï¼ˆhigh/medium/lowï¼‰

è¯·ä»¥JSONæ ¼å¼è¿”å›æœç´¢ç»´åº¦åˆ—è¡¨ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "dimensions": [
        {{
            "dimension": "ç»´åº¦åç§°",
            "query": "æœç´¢æŸ¥è¯¢",
            "priority": "high",
            "reason": "æœç´¢ç†ç”±"
        }}
    ]
}}

è¦æ±‚ï¼š
- æœ€å¤šè§„åˆ’3-5ä¸ªæœç´¢ç»´åº¦
- æ¯ä¸ªç»´åº¦çš„æŸ¥è¯¢åº”è¯¥å…·ä½“ã€å¯æ‰§è¡Œ
- ä¼˜å…ˆé€‰æ‹©å¯¹éªŒè¯å’Œå¢å¼ºç§å­æœ€æœ‰ä»·å€¼çš„ç»´åº¦
- **æ—¶é—´å‡†ç¡®æ€§**: å¦‚æœç”¨æˆ·é—®é¢˜æˆ–ç§å­æ¶‰åŠ"æœ€æ–°"ã€"å½“å‰"ã€"ç°åœ¨"ç­‰æ—¶é—´æ¦‚å¿µï¼Œæœç´¢æŸ¥è¯¢ä¸­å¿…é¡»ä½¿ç”¨"{current_year}"å¹´ä»½
- **é¿å…è¿‡æ—¶ä¿¡æ¯**: ä¸è¦åœ¨æŸ¥è¯¢ä¸­ä½¿ç”¨{current_year-1}å¹´æˆ–æ›´æ—©çš„å¹´ä»½
"""

            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨æµå¼ç”Ÿæˆå™¨å®æ—¶è¾“å‡º
            response_content = ""
            
            if hasattr(self.llm_manager, 'call_api_streaming_generator'):
                logger.info("ğŸŒŠ ä½¿ç”¨æµå¼ç”Ÿæˆå™¨è¿›è¡Œæœç´¢è§„åˆ’...")
                
                # æµå¼è¾“å‡ºæç¤º
                self._send_streaming_output(
                    streaming_output,
                    stage="stage2_llm_planning",
                    content="ğŸ¤– æ­£åœ¨è°ƒç”¨ LLM è§„åˆ’æœç´¢ç»´åº¦ï¼ˆæµå¼è¾“å‡ºï¼‰...\n",
                    metadata={}
                )
                
                try:
                    # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨ - å®æ—¶æ˜¾ç¤ºæ¯ä¸ªtoken
                    for chunk in self.llm_manager.call_api_streaming_generator(
                        prompt=planning_prompt,
                        temperature=0.7,
                        max_tokens=1000
                    ):
                        if chunk:
                            # å®æ—¶æµå¼è¾“å‡ºæ¯ä¸ªchunk
                            self._send_streaming_output(
                                streaming_output,
                                stage="stage2_llm_planning_chunk",
                                content=chunk,
                                metadata={"is_chunk": True}
                            )
                            response_content += chunk
                    
                    # æµå¼è¾“å‡ºå®Œæˆæç¤º
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_llm_planning_complete",
                        content="\nâœ… æœç´¢è§„åˆ’ç”Ÿæˆå®Œæˆ",
                        metadata={"total_length": len(response_content)}
                    )
                    
                except Exception as stream_error:
                    logger.warning(f"âš ï¸ æµå¼ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šæ¨¡å¼: {stream_error}")
                    # å›é€€åˆ°æ™®é€šAPI
                    if hasattr(self.llm_manager, 'call_api'):
                        response_content = self.llm_manager.call_api(
                            prompt=planning_prompt,
                            temperature=0.7,
                            max_tokens=1000
                        )
                        # æå–content
                        if isinstance(response_content, dict) and 'content' in response_content:
                            response_content = response_content['content']
                        elif hasattr(response_content, 'content'):
                            response_content = response_content.content
                    else:
                        logger.warning("âš ï¸ LLMç®¡ç†å™¨ä¸æ”¯æŒ call_api æ–¹æ³•")
                        return self._get_fallback_dimensions(stage1_context)
                        
            elif hasattr(self.llm_manager, 'call_api'):
                logger.info("âš ï¸ æµå¼ç”Ÿæˆå™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨æ™®é€šAPI")
                response = self.llm_manager.call_api(
                    prompt=planning_prompt,
                    temperature=0.7,
                    max_tokens=1000
                )
                # æå–content
                if isinstance(response, dict) and 'content' in response:
                    response_content = response['content']
                elif isinstance(response, str):
                    response_content = response
                elif hasattr(response, 'content'):
                    response_content = response.content
            else:
                logger.warning("âš ï¸ LLMç®¡ç†å™¨ä¸æ”¯æŒä»»ä½•APIæ–¹æ³•")
                return self._get_fallback_dimensions(stage1_context)
            
            # è§£æå“åº” - ç°åœ¨ response_content å·²ç»æ˜¯å­—ç¬¦ä¸²äº†
            content = response_content if response_content else None
            
            if content:
                print(f"âœ… LLM å“åº”å·²æ¥æ”¶ï¼ˆé•¿åº¦: {len(content)} å­—ç¬¦ï¼‰", flush=True)
                logger.debug(f"LLMå“åº”å†…å®¹ï¼ˆå‰200å­—ç¬¦ï¼‰: {content[:200]}...")
                
                # å°è¯•æå–JSON
                import re
                print("ğŸ” æ­£åœ¨è§£æ LLM å“åº”ä¸­çš„æœç´¢ç»´åº¦...", flush=True)
                
                # æ”¹è¿›çš„JSONæå–æ­£åˆ™ï¼šæ”¯æŒå¤šè¡Œï¼Œå¤„ç†åµŒå¥—
                json_match = re.search(r'\{[^{}]*"dimensions"[^{}]*\[[^\]]*\][^{}]*\}', content, re.DOTALL)
                if not json_match:
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                    json_match = re.search(r'\{(?:[^{}]|\{[^{}]*\})*\}', content, re.DOTALL)
                
                if json_match:
                    json_str = json_match.group(0)
                    print(f"âœ… æ‰¾åˆ° JSON æ ¼å¼æ•°æ®ï¼ˆé•¿åº¦: {len(json_str)} å­—ç¬¦ï¼‰", flush=True)
                    
                    try:
                        planning_result = json.loads(json_str)
                        print("âœ… JSON è§£ææˆåŠŸ", flush=True)
                        
                        if 'dimensions' in planning_result and planning_result['dimensions']:
                            dimensions = planning_result['dimensions']
                            print(f"âœ… æˆåŠŸæå– {len(dimensions)} ä¸ªæœç´¢ç»´åº¦", flush=True)
                            logger.info(f"âœ… æˆåŠŸè§„åˆ’ {len(dimensions)} ä¸ªæœç´¢ç»´åº¦")
                            
                            # æ„å»ºç»´åº¦å±•ç¤ºä¿¡æ¯
                            dimensions_display = []
                            for i, dim in enumerate(dimensions, 1):
                                dimension_name = dim.get('dimension', '')
                                query = dim.get('query', '')
                                priority = dim.get('priority', 'medium')
                                reason = dim.get('reason', '')
                                
                                logger.info(f"  ğŸ“Œ {dimension_name}: {query}")
                                dimensions_display.append(
                                    f"{i}. ã€{dimension_name}ã€‘({priority})\n"
                                    f"   æŸ¥è¯¢ï¼š{query}\n"
                                    f"   ç†ç”±ï¼š{reason}"
                                )
                            
                            # æµå¼è¾“å‡ºï¼šå±•ç¤ºæœç´¢ç»´åº¦
                            self._send_streaming_output(
                                streaming_output,
                                stage="stage2_dimensions_planned",
                                content=f"âœ… æˆåŠŸè§„åˆ’ {len(dimensions)} ä¸ªæœç´¢ç»´åº¦ï¼š\n\n" + "\n\n".join(dimensions_display),
                                metadata={
                                    "dimensions_count": len(dimensions),
                                    "dimensions": dimensions
                                }
                            )
                            
                            return dimensions
                        else:
                            print("âš ï¸ JSON ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ dimensions å­—æ®µ", flush=True)
                            logger.warning("âš ï¸ JSONä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„dimensionså­—æ®µ")
                            print(f"   JSON å†…å®¹é¢„è§ˆ: {json_str[:200]}...", flush=True)
                    except json.JSONDecodeError as je:
                        print(f"âŒ JSON è§£æå¤±è´¥: {je}", flush=True)
                        logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥: {je}")
                        logger.debug(f"å°è¯•è§£æçš„JSON: {json_str[:200]}...")
                        print(f"   å°è¯•è§£æçš„å†…å®¹: {json_str[:150]}...", flush=True)
                else:
                    print("âš ï¸ å“åº”ä¸­æœªæ‰¾åˆ° JSON æ ¼å¼æ•°æ®", flush=True)
                    logger.warning("âš ï¸ å“åº”ä¸­æœªæ‰¾åˆ°JSONæ ¼å¼æ•°æ®")
                    logger.debug(f"å“åº”å†…å®¹: {content[:300]}...")
                    print(f"   å“åº”å†…å®¹é¢„è§ˆ: {content[:200]}...", flush=True)
            else:
                print("âš ï¸ LLM æœªè¿”å›æœ‰æ•ˆå†…å®¹", flush=True)
                logger.warning("âš ï¸ LLMæœªè¿”å›æœ‰æ•ˆå†…å®¹")
            
            # å›é€€åˆ°é»˜è®¤æœç´¢ç»´åº¦
            print("\nâš ï¸ ä½¿ç”¨å›é€€ç­–ç•¥ï¼šåŸºäºå¯å‘å¼è§„åˆ™ç”Ÿæˆé»˜è®¤æœç´¢ç»´åº¦", flush=True)
            logger.info("ğŸ“‹ ä½¿ç”¨å›é€€æœç´¢ç»´åº¦ç­–ç•¥...")
            fallback_dimensions = self._get_fallback_dimensions(stage1_context)
            
            self._send_streaming_output(
                streaming_output,
                stage="stage2_dimensions_planned",
                content=f"â„¹ï¸ ä½¿ç”¨é»˜è®¤æœç´¢ç»´åº¦ï¼ˆå…± {len(fallback_dimensions)} ä¸ªï¼‰",
                metadata={
                    "dimensions_count": len(fallback_dimensions),
                    "dimensions": fallback_dimensions,
                    "fallback": True
                }
            )
            
            return fallback_dimensions
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢è§„åˆ’å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return self._get_fallback_dimensions(stage1_context)
    
    def _get_fallback_dimensions(self, stage1_context: ThinkingSeedContext) -> List[Dict[str, str]]:
        """
        è·å–å›é€€çš„é»˜è®¤æœç´¢ç»´åº¦
        
        å½“LLMè§„åˆ’å¤±è´¥æ—¶ï¼Œä½¿ç”¨åŸºäºå¯å‘å¼è§„åˆ™çš„é»˜è®¤æœç´¢ç»´åº¦
        
        Args:
            stage1_context: é˜¶æ®µä¸€ä¸Šä¸‹æ–‡
            
        Returns:
            List[Dict]: é»˜è®¤æœç´¢ç»´åº¦åˆ—è¡¨
        """
        user_query = stage1_context.user_query
        thinking_seed = stage1_context.thinking_seed
        
        # ğŸ”¥ è·å–å½“å‰æ—¶é—´
        from datetime import datetime
        current_year = datetime.now().year
        
        # åŸºäºæŸ¥è¯¢å†…å®¹åˆ¤æ–­ç±»å‹
        query_lower = user_query.lower()
        
        # é»˜è®¤ç»´åº¦
        dimensions = []
        
        # æŠ€æœ¯/å­¦æœ¯ç±»é—®é¢˜
        if any(keyword in query_lower for keyword in ['æ˜¯ä»€ä¹ˆ', 'åŸç†', 'å¦‚ä½•', 'æ€ä¹ˆ', 'æŠ€æœ¯', 'ç®—æ³•', 'how', 'what']):
            dimensions.extend([
                {
                    "dimension": "åŸºç¡€æ¦‚å¿µ",
                    "query": f"{user_query[:50]} åŸºç¡€æ¦‚å¿µ å®šä¹‰",
                    "priority": "high",
                    "reason": "ç†è§£åŸºç¡€æ¦‚å¿µ"
                },
                {
                    "dimension": "å®é™…åº”ç”¨",
                    "query": f"{user_query[:50]} åº”ç”¨æ¡ˆä¾‹ å®è·µ",
                    "priority": "medium",
                    "reason": "äº†è§£å®é™…åº”ç”¨"
                }
            ])
        
        # æ¯”è¾ƒ/å¯¹æ¯”ç±»é—®é¢˜
        if any(keyword in query_lower for keyword in ['åŒºåˆ«', 'å¯¹æ¯”', 'æ¯”è¾ƒ', 'vs', 'versus', 'difference']):
            dimensions.extend([
                {
                    "dimension": "å¯¹æ¯”åˆ†æ",
                    "query": f"{user_query[:50]} å¯¹æ¯” æ¯”è¾ƒ",
                    "priority": "high",
                    "reason": "è¿›è¡Œå¯¹æ¯”åˆ†æ"
                }
            ])
        
        # æœ€æ–°/è¶‹åŠ¿ç±»é—®é¢˜ - ğŸ”¥ ä½¿ç”¨å½“å‰å¹´ä»½
        if any(keyword in query_lower for keyword in ['æœ€æ–°', 'è¶‹åŠ¿', 'å‘å±•', 'æœªæ¥', str(current_year), str(current_year-1), 'latest', 'trend']):
            dimensions.extend([
                {
                    "dimension": "æœ€æ–°è¿›å±•",
                    "query": f"{user_query[:50]} {current_year} æœ€æ–°",  # ğŸ”¥ åŠ¨æ€å¹´ä»½
                    "priority": "high",
                    "reason": f"è·å–{current_year}å¹´æœ€æ–°ä¿¡æ¯"
                }
            ])
        
        # å¦‚æœè¿˜æ²¡æœ‰è¶³å¤Ÿçš„ç»´åº¦ï¼Œæ·»åŠ é€šç”¨ç»´åº¦
        if len(dimensions) < 2:
            dimensions.append({
                "dimension": "ç›¸å…³ä¿¡æ¯",
                "query": f"{user_query[:60]}",
                "priority": "medium",
                "reason": "è·å–ç›¸å…³èƒŒæ™¯ä¿¡æ¯"
            })
        
        # é™åˆ¶æœ€å¤š3ä¸ªç»´åº¦
        dimensions = dimensions[:3]
        
        logger.info(f"ğŸ“‹ ç”Ÿæˆäº† {len(dimensions)} ä¸ªå›é€€æœç´¢ç»´åº¦ï¼ˆåŸºäº{current_year}å¹´ï¼‰")
        for dim in dimensions:
            logger.info(f"  - {dim['dimension']}: {dim['query']}")
        
        return dimensions
    
    def _execute_multi_dimension_search(self,
                                       search_dimensions: List[Dict[str, str]],
                                       context: SeedVerificationContext,
                                       streaming_output = None) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå¤šç»´åº¦ä¿¡æ¯æœç´¢
        
        Args:
            search_dimensions: æœç´¢ç»´åº¦åˆ—è¡¨
            context: éªŒè¯ä¸Šä¸‹æ–‡
            
        Returns:
            List[Dict]: æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            logger.info("ğŸ” å¼€å§‹æ‰§è¡Œå¤šç»´åº¦æœç´¢...")
            
            self._send_streaming_output(
                streaming_output,
                stage="stage2_search_start",
                content=f"ğŸ” å¼€å§‹æ‰§è¡Œå¤šç»´åº¦ä¿¡æ¯æœç´¢ï¼ˆå…± {len(search_dimensions)} ä¸ªç»´åº¦ï¼‰...",
                metadata={"total_dimensions": len(search_dimensions)}
            )
            
            all_results = []
            
            # æ£€æŸ¥æ˜¯å¦æœ‰web_searchå·¥å…·
            if not self.tool_registry.has_tool("web_search"):
                logger.warning("âš ï¸ web_searchå·¥å…·ä¸å¯ç”¨ï¼Œè·³è¿‡æœç´¢")
                
                self._send_streaming_output(
                    streaming_output,
                    stage="stage2_search_unavailable",
                    content="âš ï¸ æœç´¢å·¥å…·ä¸å¯ç”¨ï¼Œè·³è¿‡ä¿¡æ¯æœç´¢",
                    metadata={}
                )
                
                return []
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            sorted_dimensions = sorted(
                search_dimensions,
                key=lambda x: {'high': 3, 'medium': 2, 'low': 1}.get(x.get('priority', 'medium'), 2),
                reverse=True
            )
            
            # æ‰§è¡Œæœç´¢ï¼ˆæœ€å¤šå‰3ä¸ªç»´åº¦ï¼‰
            for i, dimension in enumerate(sorted_dimensions[:3]):
                try:
                    dimension_name = dimension.get('dimension', f'ç»´åº¦{i+1}')
                    query = dimension.get('query', '')
                    priority = dimension.get('priority', 'medium')
                    
                    if not query:
                        continue
                    
                    # é†’ç›®çš„æœç´¢å¼€å§‹æç¤º
                    print(f"\n{'â”€'*80}", flush=True)
                    print(f"ğŸ” æ­£åœ¨æœç´¢ç»´åº¦ {i+1}/{min(3, len(sorted_dimensions))}: ã€{dimension_name}ã€‘", flush=True)
                    print(f"   ä¼˜å…ˆçº§: {priority.upper()}", flush=True)
                    print(f"   æŸ¥è¯¢è¯­å¥: {query}", flush=True)
                    print(f"{'â”€'*80}", flush=True)
                    
                    logger.info(f"  ğŸ” æœç´¢ç»´åº¦ [{dimension_name}]: {query}")
                    
                    # æµå¼è¾“å‡ºï¼šå¼€å§‹æœç´¢æŸä¸ªç»´åº¦
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_searching_dimension",
                        content=f"ğŸ” æ­£åœ¨æœç´¢ã€{dimension_name}ã€‘({priority})...\næŸ¥è¯¢ï¼š{query}",
                        metadata={
                            "dimension": dimension_name,
                            "query": query,
                            "priority": priority,
                            "index": i + 1,
                            "total": min(3, len(sorted_dimensions))
                        }
                    )
                    
                    print("â³ æ­£åœ¨è°ƒç”¨æœç´¢å·¥å…·...", flush=True)
                    
                    # è°ƒç”¨æœç´¢å·¥å…·
                    search_result = self.tool_registry.execute_tool(
                        name="web_search",
                        query=query
                    )
                    
                    if search_result and search_result.success:
                        result_data = {
                            'dimension': dimension_name,
                            'query': query,
                            'content': search_result.data,  # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ data è€Œä¸æ˜¯ result
                            'metadata': search_result.metadata
                        }
                        all_results.append(result_data)
                        
                        # æå–å¹¶æ˜¾ç¤ºç»“æœæ‘˜è¦
                        result_count = 0
                        if isinstance(search_result.data, dict):
                            if 'results' in search_result.data:
                                result_count = len(search_result.data['results'])
                            result_preview = json.dumps(search_result.data, ensure_ascii=False)[:150]
                        elif isinstance(search_result.data, str):
                            result_preview = search_result.data[:150]
                        else:
                            result_preview = str(search_result.data)[:150]
                        
                        print(f"âœ… æœç´¢æˆåŠŸï¼æ‰¾åˆ° {result_count if result_count > 0 else 'è‹¥å¹²'} æ¡ç»“æœ", flush=True)
                        if result_count > 0:
                            print(f"   ç»“æœé¢„è§ˆ: {result_preview}...", flush=True)
                        
                        logger.info(f"    âœ… æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {result_count} æ¡ç»“æœ")
                        
                        # æµå¼è¾“å‡ºï¼šæœç´¢æˆåŠŸ
                        self._send_streaming_output(
                            streaming_output,
                            stage="stage2_search_result",
                            content=f"âœ… ã€{dimension_name}ã€‘æœç´¢æˆåŠŸ\næ‰¾åˆ° {result_count if result_count > 0 else 'è‹¥å¹²'} æ¡ç»“æœ\nç»“æœé¢„è§ˆï¼š{result_preview}...",
                            metadata={
                                "dimension": dimension_name,
                                "success": True,
                                "result_count": result_count,
                                "result_preview": result_preview
                            }
                        )
                    else:
                        error_msg = search_result.error_message if search_result else "æœªçŸ¥é”™è¯¯"
                        print(f"âš ï¸ æœç´¢å¤±è´¥: {error_msg}", flush=True)
                        logger.warning(f"    âš ï¸ æœç´¢å¤±è´¥æˆ–æ— ç»“æœ: {error_msg}")
                        
                        # æµå¼è¾“å‡ºï¼šæœç´¢å¤±è´¥
                        self._send_streaming_output(
                            streaming_output,
                            stage="stage2_search_result",
                            content=f"âš ï¸ ã€{dimension_name}ã€‘æœç´¢å¤±è´¥æˆ–æ— ç»“æœ\nåŸå› ï¼š{error_msg}",
                            metadata={
                                "dimension": dimension_name,
                                "success": False,
                                "error": error_msg
                            }
                        )
                        
                except Exception as e:
                    print(f"âŒ æœç´¢å¼‚å¸¸: {str(e)}", flush=True)
                    logger.error(f"    âŒ æœç´¢å¼‚å¸¸: {e}")
                    import traceback
                    logger.debug(traceback.format_exc())
                    
                    # æµå¼è¾“å‡ºï¼šæœç´¢å¼‚å¸¸
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_search_error",
                        content=f"âŒ ã€{dimension_name}ã€‘æœç´¢å¼‚å¸¸ï¼š{str(e)}",
                        metadata={
                            "dimension": dimension_name,
                            "error": str(e)
                        }
                    )
                    continue
            
            # æœç´¢å®Œæˆæ€»ç»“
            print(f"\n{'â•'*80}", flush=True)
            print(f"âœ… å¤šç»´åº¦æœç´¢å®Œæˆï¼", flush=True)
            print(f"   â€¢ æ‰§è¡Œæœç´¢ç»´åº¦æ•°: {min(3, len(sorted_dimensions))}", flush=True)
            print(f"   â€¢ æˆåŠŸè·å–ç»“æœæ•°: {len(all_results)}", flush=True)
            print(f"{'â•'*80}\n", flush=True)
            
            logger.info(f"âœ… å®Œæˆå¤šç»´åº¦æœç´¢ï¼Œå…± {len(all_results)} ä¸ªæœ‰æ•ˆç»“æœ")
            
            # æµå¼è¾“å‡ºï¼šæœç´¢å®Œæˆ
            self._send_streaming_output(
                streaming_output,
                stage="stage2_search_complete",
                content=f"âœ… å¤šç»´åº¦æœç´¢å®Œæˆï¼Œå…±è·å¾— {len(all_results)} ä¸ªæœ‰æ•ˆç»“æœ",
                metadata={
                    "total_results": len(all_results),
                    "searched_dimensions": min(3, len(sorted_dimensions))
                }
            )
            
            return all_results
            
        except Exception as e:
            logger.error(f"âŒ å¤šç»´åº¦æœç´¢å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return []
    
    def _enhance_seed(self,
                     stage1_context: ThinkingSeedContext,
                     search_results: List[Dict[str, Any]],
                     context: SeedVerificationContext,
                     streaming_output = None) -> Optional[str]:
        """
        æ‰§è¡Œç§å­å¢å¼º
        
        å°†æœç´¢åˆ°çš„ä¿¡æ¯ä¸åŸå§‹ç§å­æ•´åˆï¼Œç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­ã€‚
        
        Args:
            stage1_context: é˜¶æ®µä¸€ä¸Šä¸‹æ–‡
            search_results: æœç´¢ç»“æœåˆ—è¡¨
            context: éªŒè¯ä¸Šä¸‹æ–‡
            
        Returns:
            Optional[str]: å¢å¼ºåçš„æ€ç»´ç§å­ï¼Œå¤±è´¥åˆ™è¿”å›None
        """
        try:
            logger.info("ğŸ”„ å¼€å§‹ç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­...")
            
            self._send_streaming_output(
                streaming_output,
                stage="stage2_enhancement_processing",
                content="ğŸ”„ æ­£åœ¨æ•´åˆæœç´¢ä¿¡æ¯ï¼Œç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­...",
                metadata={"search_results_count": len(search_results)}
            )
            
            # æ„å»ºæœç´¢ç»“æœæ‘˜è¦
            search_summary = self._build_search_summary(search_results)
            
            # ğŸ”¥ è·å–å½“å‰æ—¶é—´ä¿¡æ¯
            import time as time_module
            from datetime import datetime
            now = datetime.now()
            current_year = now.year
            current_date = now.strftime('%Yå¹´%mæœˆ%dæ—¥')
            
            # æ„å»ºå¢å¼ºæç¤ºè¯­
            enhancement_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ€ç»´ç§å­å¢å¼ºä¸“å®¶ã€‚

ğŸ“… **é‡è¦æ—¶é—´ä¿¡æ¯**ï¼ˆç”Ÿæˆå¢å¼ºç§å­æ—¶å¿…é¡»å‚è€ƒï¼‰:
- å½“å‰å¹´ä»½: {current_year}å¹´
- å½“å‰æ—¥æœŸ: {current_date}
- âš ï¸ å¦‚æœæœç´¢ç»“æœæåˆ°"{current_year}å¹´"çš„ä¿¡æ¯ï¼Œå¿…é¡»ä¼˜å…ˆé‡‡çº³å’Œçªå‡º

ç”¨æˆ·é—®é¢˜ï¼š{stage1_context.user_query}

åŸå§‹æ€ç»´ç§å­ï¼š
{stage1_context.thinking_seed}

æœ€æ–°æœç´¢ä¿¡æ¯ï¼š
{search_summary}

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå¢å¼ºç‰ˆçš„æ€ç»´ç§å­ã€‚è¦æ±‚ï¼š
1. **æ—¶é—´å‡†ç¡®æ€§**ï¼šä¼˜å…ˆä½¿ç”¨{current_year}å¹´çš„æœ€æ–°ä¿¡æ¯ï¼Œé¿å…ä½¿ç”¨è¿‡æ—¶å¹´ä»½
2. ä¿ç•™åŸå§‹ç§å­çš„æ ¸å¿ƒæ€è·¯å’Œç»“æ„
3. æ•´åˆæœ€æ–°çš„æœç´¢ä¿¡æ¯ï¼Œå¢åŠ æ·±åº¦å’Œå¹¿åº¦
4. ç¡®ä¿é€»è¾‘è¿è´¯ã€è¡¨è¾¾æ¸…æ™°
5. çªå‡ºå…³é”®æ´å¯Ÿå’Œåˆ›æ–°ç‚¹
6. æ§åˆ¶åœ¨200-400å­—

âš ï¸ ç‰¹åˆ«æ³¨æ„ï¼š
- å¦‚æœç”¨æˆ·é—®"æœ€æ–°"ã€"å½“å‰"ç›¸å…³çš„é—®é¢˜ï¼Œå¿…é¡»ä»¥{current_year}å¹´ä¸ºåŸºå‡†
- å¦‚æœæœç´¢ç»“æœä¸­åŒæ—¶æœ‰{current_year-1}å¹´å’Œ{current_year}å¹´çš„ä¿¡æ¯ï¼Œä¼˜å…ˆé‡‡ç”¨{current_year}å¹´çš„
- åœ¨æè¿°è¿›å±•æ—¶ï¼Œä½¿ç”¨"{current_year}å¹´"è€Œä¸æ˜¯æ—§å¹´ä»½

è¯·ç›´æ¥è¾“å‡ºå¢å¼ºåçš„æ€ç»´ç§å­ï¼Œä¸éœ€è¦é¢å¤–çš„è§£é‡Šã€‚
"""

            self._send_streaming_output(
                streaming_output,
                stage="stage2_llm_enhancing",
                content="ğŸ¤– æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œç§å­å¢å¼ºï¼ˆæµå¼è¾“å‡ºï¼‰...\n",
                metadata={"prompt_length": len(enhancement_prompt)}
            )

            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨æµå¼ç”Ÿæˆå™¨å®æ—¶è¾“å‡º
            enhanced_seed = ""
            
            if hasattr(self.llm_manager, 'call_api_streaming_generator'):
                logger.info("ğŸŒŠ ä½¿ç”¨æµå¼ç”Ÿæˆå™¨è¿›è¡Œç§å­å¢å¼º...")
                
                try:
                    # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨ - å®æ—¶æ˜¾ç¤ºæ¯ä¸ªtoken
                    for chunk in self.llm_manager.call_api_streaming_generator(
                        prompt=enhancement_prompt,
                        temperature=0.7,
                        max_tokens=1500
                    ):
                        if chunk:
                            # å®æ—¶æµå¼è¾“å‡ºæ¯ä¸ªchunk
                            self._send_streaming_output(
                                streaming_output,
                                stage="stage2_enhancement_chunk",
                                content=chunk,
                                metadata={"is_chunk": True}
                            )
                            enhanced_seed += chunk
                    
                    # æµå¼è¾“å‡ºå®Œæˆæç¤º
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_enhancement_stream_complete",
                        content="\nâœ… ç§å­å¢å¼ºç”Ÿæˆå®Œæˆ",
                        metadata={"total_length": len(enhanced_seed)}
                    )
                    
                except Exception as stream_error:
                    logger.warning(f"âš ï¸ æµå¼ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šæ¨¡å¼: {stream_error}")
                    # å›é€€åˆ°æ™®é€šAPI
                    if hasattr(self.llm_manager, 'call_api'):
                        response = self.llm_manager.call_api(
                            prompt=enhancement_prompt,
                            temperature=0.7,
                            max_tokens=1500
                        )
                        # æå–content
                        if isinstance(response, dict) and 'content' in response:
                            enhanced_seed = response['content']
                        elif isinstance(response, str):
                            enhanced_seed = response
                        elif hasattr(response, 'content'):
                            enhanced_seed = response.content
                    else:
                        logger.warning("âš ï¸ LLMç®¡ç†å™¨ä¸æ”¯æŒ call_api æ–¹æ³•")
                        
                        self._send_streaming_output(
                            streaming_output,
                            stage="stage2_enhancement_failed",
                            content="âš ï¸ LLMç®¡ç†å™¨ä¸æ”¯æŒå¢å¼ºåŠŸèƒ½",
                            metadata={}
                        )
                        
                        return None
                        
            elif hasattr(self.llm_manager, 'call_api'):
                logger.info("âš ï¸ æµå¼ç”Ÿæˆå™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨æ™®é€šAPI")
                response = self.llm_manager.call_api(
                    prompt=enhancement_prompt,
                    temperature=0.7,
                    max_tokens=1500
                )
                # æå–content
                if isinstance(response, dict) and 'content' in response:
                    enhanced_seed = response['content']
                elif isinstance(response, str):
                    enhanced_seed = response
                elif hasattr(response, 'content'):
                    enhanced_seed = response.content
            else:
                logger.warning("âš ï¸ LLMç®¡ç†å™¨ä¸æ”¯æŒä»»ä½•APIæ–¹æ³•")
                
                self._send_streaming_output(
                    streaming_output,
                    stage="stage2_enhancement_failed",
                    content="âš ï¸ LLMç®¡ç†å™¨ä¸æ”¯æŒå¢å¼ºåŠŸèƒ½",
                    metadata={}
                )
                
                return None
            
            if enhanced_seed:
                enhanced_seed = enhanced_seed.strip()
                
                if len(enhanced_seed) > 50:
                    # æ›´æ–°å¯è¡Œæ€§è¯„åˆ†ï¼ˆå¢å¼ºåæé«˜è¯„åˆ†ï¼‰
                    old_score = context.feasibility_score
                    context.feasibility_score = min(0.9, context.feasibility_score + 0.2)
                    context.verification_method = "llm_enhanced_verification"
                    context.verification_evidence.append("æˆåŠŸæ•´åˆæœç´¢ä¿¡æ¯ç”Ÿæˆå¢å¼ºç§å­")
                    
                    # é†’ç›®çš„æˆåŠŸè¾“å‡º
                    print("\n" + "â”" + "â”"*78 + "â”“", flush=True)
                    print("â”ƒ âœ… å¢å¼ºç‰ˆæ€ç»´ç§å­ç”ŸæˆæˆåŠŸï¼                                              â”ƒ", flush=True)
                    print("â”—" + "â”"*78 + "â”›", flush=True)
                    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:", flush=True)
                    print(f"   â€¢ ç§å­é•¿åº¦: {len(enhanced_seed)} å­—ç¬¦", flush=True)
                    print(f"   â€¢ å¯è¡Œæ€§è¯„åˆ†æå‡: {old_score:.2f} â†’ {context.feasibility_score:.2f}", flush=True)
                    print(f"\nğŸ“ å¢å¼ºç§å­å†…å®¹é¢„è§ˆ:", flush=True)
                    print(f"{'â”€'*80}", flush=True)
                    print(f"{enhanced_seed[:200]}{'...' if len(enhanced_seed) > 200 else ''}", flush=True)
                    print(f"{'â”€'*80}\n", flush=True)
                    
                    logger.info(f"âœ… ç”Ÿæˆå¢å¼ºç§å­ï¼ˆé•¿åº¦: {len(enhanced_seed)}å­—ç¬¦ï¼‰")
                    logger.info(f"å¢å¼ºç§å­é¢„è§ˆ: {enhanced_seed[:100]}...")
                    
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_enhancement_success",
                        content=f"âœ… æˆåŠŸç”Ÿæˆå¢å¼ºç‰ˆæ€ç»´ç§å­\n\né•¿åº¦ï¼š{len(enhanced_seed)} å­—ç¬¦\nå¯è¡Œæ€§è¯„åˆ†æå‡ï¼š{old_score:.2f} â†’ {context.feasibility_score:.2f}",
                        metadata={
                            "seed_length": len(enhanced_seed),
                            "old_score": old_score,
                            "new_score": context.feasibility_score,
                            "enhanced_seed_preview": enhanced_seed[:200]
                        }
                    )
                    
                    return enhanced_seed
                else:
                    logger.warning("âš ï¸ ç”Ÿæˆçš„å¢å¼ºç§å­è¿‡çŸ­æˆ–ä¸ºç©º")
                    
                    self._send_streaming_output(
                        streaming_output,
                        stage="stage2_enhancement_failed",
                        content="âš ï¸ ç”Ÿæˆçš„å¢å¼ºç§å­è¿‡çŸ­æˆ–ä¸ºç©º",
                        metadata={"seed_length": len(enhanced_seed) if enhanced_seed else 0}
                    )
                    
                    return None
            else:
                logger.warning("âš ï¸ LLMæœªè¿”å›æœ‰æ•ˆå“åº”")
                
                self._send_streaming_output(
                    streaming_output,
                    stage="stage2_enhancement_failed",
                    content="âš ï¸ LLMæœªè¿”å›æœ‰æ•ˆå“åº”",
                    metadata={}
                )
                
                return None
                
        except Exception as e:
            logger.error(f"âŒ ç§å­å¢å¼ºå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None
    
    def _build_search_summary(self, search_results: List[Dict[str, Any]]) -> str:
        """
        æ„å»ºæœç´¢ç»“æœæ‘˜è¦
        
        Args:
            search_results: æœç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–çš„æœç´¢ç»“æœæ‘˜è¦
        """
        if not search_results:
            return "ï¼ˆæ— æœç´¢ç»“æœï¼‰"
        
        summary_parts = []
        for i, result in enumerate(search_results, 1):
            dimension = result.get('dimension', f'ç»´åº¦{i}')
            content = result.get('content', '')
            
            # æå–æ‘˜è¦ï¼ˆå–å‰200å­—ç¬¦ï¼‰
            if isinstance(content, dict):
                content_str = json.dumps(content, ensure_ascii=False)[:200]
            elif isinstance(content, str):
                content_str = content[:200]
            else:
                content_str = str(content)[:200]
            
            summary_parts.append(f"ã€{dimension}ã€‘\n{content_str}...")
        
        return "\n\n".join(summary_parts)
    
    def _send_streaming_output(self, 
                              streaming_output,
                              stage: str,
                              content: str,
                              metadata: Optional[Dict] = None):
        """
        å‘é€æµå¼è¾“å‡º
        
        Args:
            streaming_output: æµå¼è¾“å‡ºå¤„ç†å™¨
            stage: é˜¶æ®µæ ‡è¯†
            content: è¾“å‡ºå†…å®¹
            metadata: å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
        """
        if streaming_output and hasattr(streaming_output, 'send'):
            try:
                output_data = {
                    'stage': stage,
                    'content': content,
                    'metadata': metadata or {},
                    'timestamp': time.time()
                }
                streaming_output.send(output_data)
            except Exception as e:
                logger.debug(f"æµå¼è¾“å‡ºå‘é€å¤±è´¥: {e}")

